@Misc{Zhang2014,
  author    = {Zhang, Kunpeng and Xie, Yusheng and Yang, Yi and Sun, Aaron and Liu, Hengchang and Choudhary, Alok},
  title     = {Incorporating conditional random fields and active learning to improve sentiment identification.},
  year      = {2014},
  abstract  = {Many machine learning, statistical, and computational linguistic methods have been developed to identify sentiment of sentences in documents, yielding promising results. However, most of state-of-the-art methods focus on individual sentences and ignore the impact of context on the meaning of a sentence. In this paper, we propose a method based on conditional random fields to incorporate sentence structure and context information in addition to syntactic information for improving sentiment identification. We also investigate how human interaction affects the accuracy of sentiment labeling using limited training data. We propose and evaluate two different active learning strategies for labeling sentiment data. Our experiments with the proposed approach demonstrate a 5%-15% improvement in accuracy on Amazon customer reviews compared to existing supervised learning and rule-based methods. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {Xie, Yusheng: yxi389@eecs.northwestern.edu},
  doi       = {10.1016/j.neunet.2014.04.005},
  issn      = {1879-2782(Electronic),0893-6080(Print)},
  journal   = {Neural Networks},
  keywords  = {*Internet, *Linguistics, *Machine Learning, *Sentence Structure, *Verbal Meaning, Consumer Psychology, Emotional Content, Labeling, Semantics, Sentences, Syntax, Computational Modeling, Social Media, Sentiment Analysis},
  pages     = {60--67},
  publisher = {Elsevier Science},
  refid     = {2014-21666-001},
  volume    = {58},
}

@Misc{Paltoglou2017,
  author    = {Paltoglou, Georgios and Thelwall, Mike},
  title     = {Sensing social media: A range of approaches for sentiment analysis.},
  year      = {2017},
  abstract  = {In this chapter, we discuss a range of different approaches to solve the problem of accurately predicting the nature of private states expressed in social media. Section 6.2 will focus on machine learning solutions, i.e., solutions that require some pre-annotated data to automatically extract the underlying patterns that characterise different affective content. Section 6.3 will present the lexicon-based solutions that were investigated within the project, that is, algorithms that rely on sentiment dictionaries. Lastly, the chapter concludes with a summary and a discussion of the potential future directions of the field in Sect. 6.4. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {Paltoglou, Georgios: School of Mathematics and Computer Science, University of Wolverhampton, Wulfruna Street, Wolverhampton, United Kingdom, WV1 1LY, g.paltoglou@wlv.ac.uk},
  doi       = {10.1007/978-3-319-43639-5_6},
  issn      = {978-3-319-43637-1 (Hardcover); 978-3-319-43639-5 (Digital (undefined format))},
  journal   = {Cyberemotions: Collective emotions in cyberspace.},
  keywords  = {*Emotions, *Machine Learning, *Mental Lexicon, *Social Media, *Sentiment Analysis, Text Structure},
  pages     = {97--117},
  publisher = {Springer International Publishing},
  refid     = {2016-55885-006},
  series    = {Understanding complex systems.},
}

@Misc{Biondi2019,
  author    = {Biondi, Francesco N. and Getty, Douglas and Cooper, Joel M. and Strayer, David L.},
  title     = {Examining the effect of infotainment auditory-vocal systems’ design components on workload and usability.},
  year      = {2019},
  abstract  = {Given the promise for auditory-vocal systems to be less distracting and safer to use than their visual-manual counterparts, automotive manufacturers are introducing an increasing number of voice assistant-like interfaces in vehicles. However, recent studies suggest using auditory-vocal systems can be mentally taxing for drivers, and require long interaction times. Low accuracy and menu complexity are believed to negatively affect the usability of the system, but a systematic analysis of the role of different design components on driver workload and user experience within a real-world setting is missing. This study investigates the role of voice system design components in determining levels of driver workload with participants driving twelve on-road vehicles and interacting with on-board infotainment systems. Menu depth, delay times and system accuracy are recorded for twelve different auditory-vocal systems, and one aggregate score is assigned to each system. Total delay time and menu depth were found to be significant predictors of task duration time and mental workload. Longer delay times also had a direct effect on lower usability ratings, measured by the System Usability Scale and sentiment analysis. Delay times recorded on seven additional vehicles were used to validate the regression model for task duration. This study provides findings of primary importance for researchers and automotive manufacturers to be used in the assessment and development of in-vehicle auditory-vocal systems. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {Biondi, Francesco N.: Department of Kinesiology, University of Windsor, 2555 College Ave., Windsor, ON, Canada, N9B 3P4},
  doi       = {10.1016/j.trf.2019.02.006},
  issn      = {1873-5517(Electronic),1369-8478(Print)},
  journal   = {Transportation Research Part F: Traffic Psychology and Behaviour},
  keywords  = {*Driving Behavior, *Human Computer Interaction, *Driver Distraction, *Conversational Agents, Distractibility, Human Channel Capacity, Human Machine Systems Design, Time Estimation},
  pages     = {520--528},
  publisher = {Elsevier Science},
  refid     = {2019-25084-041},
  volume    = {62},
}

@Misc{Nazeer2021,
  author    = {Nazeer, Ishrat and Rashid, Mamoon and Gupta, Sachin Kumar and Kumar, Abhishek},
  title     = {Use of novel ensemble machine learning approach for social media sentiment analysis.},
  year      = {2021},
  abstract  = {Twitter is a platform where people express their opinions and come with regular updates. At present, it has become a source for many organizations where data will be extracted and then later analyzed for sentiments. Many machine learning algorithms are available for twitter sentiment analysis which are used for automatically predicting the sentiment of tweets. However, there are challenges that hinder machine learning classifiers to achieve better results in terms of classification. In this chapter, the authors are proposing a novel feature generation technique to provide desired features for training models. Next, the novel ensemble classification system is proposed for identifying sentiment in tweets through weighted majority rule ensemble classifier, which utilizes several commonly used statistical models like naive Bayes, random forest, and logistic regression, which are weighted according to their performance on historical data, where weights are chosen separately for each model. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Hershey, PA, US},
  doi       = {10.4018/978-1-7998-4718-2.ch002},
  issn      = {9781799847182 (Hardcover); 9781799857860 (Paperback); 9781799847199 (Digital (undefined format))},
  journal   = {Analyzing global social media consumption.},
  keywords  = {*Algorithms, *Machine Learning, *Online Social Networks, *Social Media, Sentiment Analysis},
  pages     = {16--28},
  publisher = {Information Science Reference/IGI Global},
  refid     = {2020-79095-004},
  series    = {Advances in social networking and online communities (ASNOC) book series.},
}

@Misc{Bens2019,
  author    = {Bens, Jonas},
  title     = {The ethnography of affect in discourse practice: Performing sentiment in the time machine.},
  year      = {2019},
  abstract  = {An ethnography of discourse practice investigates the workings of discourse practice events through participant observation, writing about this as 'thickly' as possible. This chapter proposes an ethnographic approach to discourse practice as it is embedded in affective dynamics. At the heart of such ethnographies is the observation of discourse practice events--most broadly defined as a specific place in the world and a specific moment in time in which people communicate in order to be heard by a public. Such events have usually been investigated with a focus on language and speech. Without abandoning the analysis of talk, the chapter makes the argument that it is crucial to strive for an ethnographic investigation that captures quite broadly the affective dimension of the events in which such talk takes place. To that end, it lays out what the author means by an ethnography of discourse practice and then argues two points on methodology. The chapter begins by discussing discourse practice events and describes as affective arrangements. It also describes discourse practice events as time machines in which sentiments become manifest, are enacted, invoked, mobilized, shaped and transformed. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  address   = {New York, NY, US},
  doi       = {10.4324/9780429424366-11},
  issn      = {9781138388796 (Hardcover); 978-0-429-42436-6 (Digital (undefined format))},
  journal   = {Analyzing affective societies: Methods and methodologies.},
  keywords  = {*Discourse Analysis, *Emotions, *Ethnography, *Language, *Oral Communication, Methodology},
  pages     = {199--213},
  publisher = {Routledge/Taylor & Francis Group},
  refid     = {2019-21155-011},
  series    = {Routledge studies in affective societies.},
}

@Misc{Calix2012,
  author    = {Calix, Ricardo A. and Javadpour, Leili and Knapp, Gerald M.},
  title     = {Detection of affective states from text and speech for real-time human-computer interaction.},
  year      = {2012},
  abstract  = {Objective: The goal of this work is to develop and test an automated system methodology that can detect emotion from text and speech features. Background: Affective human-computer interaction will be critical for the success of new systems that will be prevalent in the 21st century. Such systems will need to properly deduce human emotional state before they can determine how to best interact with people. Method: Corpora and machine learning classification models are used to train and test a methodology for emotion detection. The methodology uses a stepwise approach to detect sentiment in sentences by first filtering out neutral sentences, then distinguishing among positive, negative, and five emotion classes. Results: Results of the classification between emotion and neutral sentences achieved recall accuracies as high as 77% in the University of Illinois at Urbana-Champaign (UIUC) corpus and 61% in the Louisiana State University medical drama (LSU-MD) corpus for emotion samples. Once neutral sentences were filtered out, the methodology achieved accuracy scores for detecting negative sentences as high as 92.3%. Conclusion: Results of the feature analysis indicate that speech spectral features are better than speech prosodic features for emotion detection. Accumulated sentiment composition text features appear to be very important as well. This work contributes to the study of human communication by providing a better understanding of how language factors help to best convey human emotion and how to best automate this process. Application: Results of this study can be used to develop better automated assistive systems that interpret human language and respond to emotions through 3-D computer graphics. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {Knapp, Gerald M.: Louisiana State University, 3128 Patrick F. Taylor Hall, Baton Rouge, LA, US, 70803, gknapp@lsu.edu},
  doi       = {10.1177/0018720811425922},
  issn      = {1547-8181(Electronic),0018-7208(Print)},
  journal   = {Human Factors},
  keywords  = {*Emotional States, *Human Computer Interaction, *Speech Perception, *Text Analysis, Automated Speech Recognition, Emotions},
  pages     = {530--545},
  publisher = {Sage Publications},
  refid     = {2012-18918-005},
  volume    = {54},
}

@Misc{Gilgur2020,
  author    = {Gilgur, Alexander and Ramirez-Marquez, Jose Emmanuel},
  title     = {Using deductive reasoning to identify unhappy communities.},
  year      = {2020},
  abstract  = {The complex interplay between media and population sentiment is a well-known, yet hard to model, phenomenon. The extrema of individual sentiment (euphoria and depression) are known to be correlated with people’s social interaction, including activity in forums and social-media sites. Yet causality direction of this correlation still requires scrutiny and scientific analysis. The difficulty of such analysis comes, first and foremost, from the complexity of sentiment quantification. It is even more difficult to measure a shared sentiment of a community, due to the echo chamber effect. In addition, media analysis presents its own computational challenges, which were insurmountable until recent times, when we have been presented with unprecedented technical possibilities for quantification of community sentiment and its factors at a level of granularity never seen before. Behavioral psychology suggests that people’s behavior can be used as a measurable proxy for their sentiment. Behaviorist theory has been enhanced with the proliferation of targeted advertising and marketing science in the corporate world, and a number of phenomena connecting people’s sentiment and social behavior have been explained using behavioral psychology. In addition, advances in the theory and practice of data mining and machine learning have enabled non-empirical approaches to quantitative sociological analysis and development of new indicators of communal well-being that rely on the analysis of historical data. These considerations make it possible to investigate the interactions between media sentiment and community. This is the theme of the present submission. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Gilgur, Alexander: School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, US, 07030, alexgilgur@gmail.com},
  doi       = {10.1007/s11205-020-02452-2},
  issn      = {1573-0921(Electronic),0303-8300(Print)},
  journal   = {Social Indicators Research},
  keywords  = {*Attempted Suicide, *Community Attitudes, *News Media, *Reasoning, Prediction, Self-Injurious Behavior, Social Behavior, Social Interaction, Socioeconomic Status, Bayesian Analysis},
  pages     = {581--605},
  publisher = {Springer},
  refid     = {2020-57375-001},
  volume    = {152},
}

@Misc{Cambria2015,
  author    = {Cambria, Erik and Hussain, Amir},
  title     = {Sentic computing: A common-sense-based framework for concept-level sentiment analysis.},
  year      = {2015},
  abstract  = {This volume presents a knowledge-based approach to concept-level sentiment analysis at the crossroads between affective computing, information extraction, and commonsense reasoning, which exploits both computer and human sciences to better interpret and process social information on the Web. Concept-level sentiment analysis goes beyond a mere word-level analysis of text in order to enable a more efficient passage from (unstructured) textual information to (structured) machine-processable data, in potentially any domain. Readers will discover the following key novelties, that make this approach so unique and avant-garde, being reviewed and discussed: Sentic Computing's multi-disciplinary approach to sentiment analysis--evidenced by the concomitant use of AI, linguistics and psychology for knowledge representation and reasoning; Sentic Computing's shift from syntax to semantics--enabled by the adoption of the bag-of-concepts model instead of simply counting word co-occurrence frequencies in text; and Sentic Computing's shift from statistics to linguistics--implemented by allowing sentiments to flow from concept to concept based on the dependency relation between clauses. This volume is the first in the Series Socio-Affective Computing edited by Prof Amir Hussain and Dr Erik Cambria and will be of interest to researchers in the fields of socially intelligent, affective and multimodal human-machine interaction and systems. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {Cham, Switzerland},
  doi       = {10.1007/978-3-319-23654-4},
  issn      = {978-3-319-23653-7 (Hardcover); 978-3-319-23654-4 (Digital (undefined format))},
  journal   = {Sentic computing: A common-sense-based framework for concept-level sentiment analysis.},
  keywords  = {*Artificial Intelligence, *Emotions, *Human Computer Interaction, *Human Machine Systems Design, *Models, Concepts, Social Processes, Sentiment Analysis},
  pages     = {xxii, 176--xxii, 176},
  publisher = {Springer International Publishing},
  refid     = {2016-02101-000},
  series    = {Socio-affective computing.},
}

@Misc{Rajaram2022,
  author    = {Rajaram, Prashant},
  title     = {Modeling viewer and influencer behavior on streaming platforms.},
  year      = {2022},
  abstract  = {The video streaming industry is growing rapidly, and consumers are increasingly using ad-supported streaming services. There are important questions related to the effect of ad schedules and video elements on viewer behavior that have not been adequately studied in the marketing literature. In my dissertation, I study these topics by applying causal and/or interpretable machine learning methods on behavioral data. In the first essay, "Finding the Sweet Spot: Ad Scheduling on Streaming Media", I design an "optimal" ad schedule that balances the interest of the viewer (watching content) with that of the streaming platform (ad exposure). This is accomplished using a three-stage approach applied on a dataset of Hulu customers. In the first stage, I develop two metrics - Bingeability and Ad Tolerance - to capture the interplay between content consumption and ad exposure in a viewing session. Bingeability represents the number of completely viewed unique episodes of a show, while Ad Tolerance represents the willingness of a viewer to watch ads and subsequent content. In the second stage, I predict the value of the metrics for the next viewing session using the machine learning method - Extreme Gradient Boosting - while controlling for the non-randomness in ad delivery to a focal viewer using "instrumental variables" based on ad delivery patterns to other viewers. Using "feature importance analyses" and "partial dependence plots" I shed light on the importance and nature of the non-linear relationship with various feature sets, going beyond a purely black-box approach. Finally, in the third stage, I implement a novel constrained optimization procedure built around the causal predictions to provide an "optimal" ad-schedule for a viewer, while ensuring the level of ad exposure does not exceed her predicted Ad Tolerance. Under the optimized schedule, I find that "win-win" schedules are possible that allow for both an increase in content consumption and ad exposure. In the second essay, "Video Influencers: Unboxing the Mystique", I study the relationship between advertising content in YouTube influencer videos (across text, audio and images) and marketing outcomes (views, interaction rates and sentiment). This is accomplished with the help of novel interpretable deep-learning architectures that avoid making a trade-off between predictive ability and interpretability. Specifically, I achieve high predictive performance by avoiding ex-ante feature engineering and achieve better interpretability by eliminating spurious relationships confounded by factors unassociated with "attention" paid to video elements. The attention mechanism in the Text and Audio models along with gradient maps in the Image model allow identification of video elements on which attention is paid while forming an association with an outcome. Such an ex-post analysis allows me to find statistically significant relationships between video elements and marketing outcomes that are supplemented by a significant increase in attention to video elements. By eliminating spurious relationships, I generate hypotheses that are more likely to have causal effects when tested in a field setting. For example, I find that mentioning a brand in the first 30 seconds of a video is on average associated with a significant increase in attention to the brand but a significant decrease in sentiment expressed towards the video. Overall, my dissertation provides solutions and identifies strategies that can improve the welfare of viewers, platform owners, influencers and brand partners. Policy makers also stand to gain from understanding the power exerted by different stakeholders over viewer behavior. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4217(Print)},
  keywords  = {*Advertising, *Audiovisual Communications Media, *Machine Learning, *Marketing, *Simulation, Learning, Media Exposure},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2022-34077-141},
  volume    = {83},
}

@Misc{Sarkar2020,
  author    = {Sarkar, Kamal},
  title     = {A stacked ensemble approach to Bengali sentiment analysis.},
  year      = {2020},
  abstract  = {Sentiment analysis is a crucial step in the social media data analysis. The majority of research works on sentiment analysis focus on sentiment polarity detection which identifies whether an input text is positive, negative or neutral. In this paper, we have implemented a stacked ensemble approach to sentiment polarity detection in Bengali tweets. The basic concept of stacked generalization is to fuse the outputs of the first level base classifiers using a second-level Meta classifier in an ensemble. In our ensemble method, we have used two types of base classifiers- multinomial Naïve Bayes classifiers and SVM that make use of a diverse set of features. Our proposed approach shows an improvement over some existing Bengali sentiment analysis approaches reported in the literature. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Sarkar, Kamal: Computer Science and Engineering Department, Jadavpur University, Kolkata, India, 700032, jukamal2001@yahoo.com},
  doi       = {10.1007/978-3-030-44689-5_10},
  issn      = {978-3-030-44688-8 (Hardcover); 978-3-030-44689-5 (Digital (undefined format))},
  journal   = {Intelligent Human Computer Interaction: 11th international conference, IHCI 2019, Allahabad, India, December 12-14, 2019, proceedings.},
  keywords  = {*Machine Learning, *Social Media, Sentiment Analysis},
  pages     = {102--111},
  publisher = {Springer Nature Switzerland AG},
  refid     = {2020-89396-011},
  series    = {Lecture notes in computer science.},
}

@Misc{Liu2021,
  author    = {Liu, Bowen and Xing, Wanli and Zeng, Yifang and Wu, Yonghe},
  title     = {Quantifying the influence of achievement emotions for student learning in MOOCs.},
  year      = {2021},
  abstract  = {Massive Open Online Courses (MOOCs) have become a popular tool for worldwide learners. However, a lack of emotional interaction and support is an important reason for learners to abandon their learning and eventually results in poor learning performance. This study applied an integrative framework of achievement emotions to uncover their holistic influence on students’ learning by analyzing more than 400,000 forum posts from 13 MOOCs. Six machine-learning models were first built to automatically identify achievement emotions, including K-Nearest Neighbor, Logistic Regression, Naïve Bayes, Decision Tree, Random Forest, and Support Vector Machines. Results showed that Random Forest performed the best with a kappa of 0.83 and an ROC_AUC of 0.97. Then, multilevel modeling with the “Stepwise Build-up” strategy was used to quantify the effect of achievement emotions on students’ academic performance. Results showed that different achievement emotions influenced students’ learning differently. These findings allow MOOC platforms and instructors to provide relevant emotional feedback to students automatically or manually, thereby improving their learning in MOOCs. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Xing, Wanli: College of Education, University of Florida, 2-215, Normal Hall, Gainesville, FL, US, 32611, wanli.xing@coe.ufl.edu},
  doi       = {10.1177/0735633120967318},
  issn      = {1541-4140(Electronic),0735-6331(Print)},
  journal   = {Journal of Educational Computing Research},
  keywords  = {*Academic Achievement, *Distance Education, *Educational Programs, *Open Classroom Method, *School Learning, Emotions, Machine Learning, Simulation, Sentiment Analysis},
  pages     = {429--452},
  publisher = {Sage Publications},
  refid     = {2021-44943-003},
  volume    = {59},
}

@Misc{Lopez2021,
  author    = {Lopez, Jessica Colleen Perez},
  title     = {Autistic characters: (de)Coding embedded sentiment.},
  year      = {2021},
  abstract  = {Through the convergence of disability studies and literary cognitive studies, Autistic Characters: (de)coding embedded sentiment explores depictions of autistic characters in literature with the use of close readings and scaled readings, a computational analytics method which uses sentiment analysis to decode the sentiment embedded in texts. I investigate these characters through close readings in which I explore my positionality within the major fields of study and the embedded medical and social histories coded into neuroatypical and neurodiverse literary representations of autism. Building upon the perspectives of my positionality and these histories, I explore how the substrate of literature is coded for a neurotypical and ableist focused reading. In my continued exploration of the embedded sentiment in literary constructions, I build upon the traditional close readings of autistic characters as I expand this analysis to conduct a (de)coding by scaled readings through which I produce visual representations from net sentiment (positive minus negative), total sentiment (positive plus absolute value of negative), negative sentiment, and positive sentiment measurements. These sets of visualizations are created both by chapters and in evenly spaced 500-word intervals throughout a full-length novel. To generate these scaled readings through the digital humanities method of sentiment analysis with the lexicon "bing," I use the programming language "R" to reveal the sentiment that lies latent within the texts. The visual patterns that emerge from the scaled readings provide graphical depictions from the positive and negative sentiment which allows me to re-read the text to analyze how it is coded with patterns, providing both a precise and different reading. I then further explore the origins of the code in the sentiment lexicon "bing" that generates the "positive" and "negative" data points. In this exploration, I critically examine the accuracy of this method and problematic constructions that arise from human generated lists that are used by machine learning to gauge the sentiment of words. Yet despite inaccuracies that may arise with scaled readings in combination with the biases of the lexicons, the visual patterns provide for a method of re-reading with sentiment that has not yet been explored. A method of reading that can lead to a different understanding of how the positive and negative embedded substrate generates charged sentiments which contribute to priming narrative feelings and in turn influences receptions of autistic characters. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4217(Print)},
  keywords  = {*Autism Spectrum Disorders, *Reading, *Visual Displays, *Mental Lexicon, *Sentiment Analysis, Humanities, Machine Learning, Neurodiversity},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2021-08068-018},
  volume    = {82},
}

@Misc{Marcacini2018,
  author    = {Marcacini, Ricardo Marcondes and Rossi, Rafael Geraldeli and Matsuno, Ivone Penque and Rezende, Solange Oliveira},
  title     = {Cross-domain aspect extraction for sentiment analysis: A transductive learning approach.},
  year      = {2018},
  abstract  = {Aspect-Based Sentiment Analysis (ABSA) is a promising approach to analyze consumer reviews at a high level of detail, where the opinion about each feature of the product or service is considered. ABSA usually explores supervised inductive learning algorithms, which requires intense human effort for the labeling process. In this paper, we investigate Cross-Domain Transfer Learning approaches, in which aspects already labeled in some domains can be used to support the aspect extraction of another domain where there are no labeled aspects. Existing cross-domain transfer learning approaches learn classifiers from labeled aspects in the source domain and then apply these classifiers in the target domain, i.e., two separate stages that may cause inconsistency due to different feature spaces. To overcome this drawback, we present an innovative approach called CD-ALPHN (Cross-Domain Aspect Label Propagation through Heterogeneous Networks). First, we propose a heterogeneous network-based representation that combines different features (labeled aspects, unlabeled aspects, and linguistic features) from source and target domain as nodes in a single network. Second, we propose a label propagation algorithm for aspect extraction from heterogeneous networks, where the linguistic features are used as a bridge for this propagation. Our algorithm is based on a transductive learning process, where we explore both labeled and unlabeled aspects during the label propagation. Experimental results show that the CD-ALPHN outperforms the state-of-the-art methods in scenarios where there is a high-level of inconsistency between the source and target domains--the most common scenario in real-world applications. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {Marcacini, Ricardo Marcondes: Federal University of Mato Grosso do Sul (UFMS), Av. Ranulpho Marques Leal, 3484, MS, Tres Lagoas, Brazil, 79613-000, ricardo.marcacini@ufms.br},
  doi       = {10.1016/j.dss.2018.08.009},
  issn      = {1873-5797(Electronic),0167-9236(Print)},
  journal   = {Decision Support Systems},
  keywords  = {*Expert Systems, *Organizations, *Data Mining, *Machine Learning Algorithms, Labeling},
  pages     = {70--80},
  publisher = {Elsevier Science},
  refid     = {2018-46296-008},
  volume    = {114},
}

@Misc{Park2019,
  author    = {Park, Saerom and Lee, Jaewook and Kim, Kyoungok},
  title     = {Semi-supervised distributed representations of documents for sentiment analysis.},
  year      = {2019},
  abstract  = {Learning document representation is important in applying machine learning algorithms for sentiment analysis. Distributed representation learning models of words and documents, one of neural language models, have overcome some limits of vector space models such as bag-of-words model and have been utilized successively in many natural language processing tasks including sentiment analysis. However, because such models learn the embeddings only with a context-based objective, it is hard for embeddings to reflect the sentiment of texts. In this research, we address this problem by introducing a semi-supervised sentiment-discriminative objective using partial sentiment information of documents. Our method not only reflects the partial sentiment information, but also preserves local structures induced from original distributed representation learning objectives by considering only sentiment relationships between neighboring documents. Using real-world datasets, the proposed method has been validated by sentiment visualization and classification tasks. The visualization results of Amazon review datasets demonstrate the enhancement of the sentiment class separation when document representations of our proposed method are compared to other methods. Sentiment prediction from our representations also appears to be consistently superior to other representations in both Amazon and Yelp datasets. This work can be extended to develop effective document embeddings applied to other discriminative tasks. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {Kim, Kyoungok: Information Technology Management Programme, International Fusion School, Seoul National University of Science & Technology (SeoulTech), 232 Gongreungno, Nowon-gu, Seoul, Republic of Korea, 01811, kyoungok.kim@seoultech.ac.kr},
  doi       = {10.1016/j.neunet.2019.08.001},
  issn      = {1879-2782(Electronic),0893-6080(Print)},
  journal   = {Neural Networks},
  keywords  = {*Learning, *Models, *Natural Language, *Sentiment Analysis, *Natural Language Processing, Educational Objectives, Imagery, Machine Learning Algorithms},
  pages     = {139--150},
  publisher = {Elsevier Science},
  refid     = {2019-58066-014},
  volume    = {119},
}

@Misc{Das2012,
  author    = {Das, Dipankar and Bandyopadhyay, Sivaji},
  title     = {Sentence-level emotion and valence tagging.},
  year      = {2012},
  abstract  = {The paper proposes the tagging of sentence-level emotion and valence based on the word-level constituents on the SemEval 2007 affect sensing news corpus. The baseline system for each emotion class assigns the class label to each word, while the WordNet Affect lists updated using the SentiWordNet were also used as the lexicon-based system. Though the inclusion of morphology into the lexicon-based system improves the performance of the word-level emotion tagging, the Conditional Random Field-based machine-learning framework was employed for the word-level emotion-tagging system, and it outperforms both the baseline- and lexicon-based systems. Six separate sense scores for six emotion types are calculated from the SentiWordNet and applied to word-level emotion tagged constituents for identifying sentential emotion scores. Three emotion scoring methods followed by a post-processing technique were employed for identifying the sentence-level emotion tags. In addition to that, the best two emotion tags corresponding to the maximum obtained sense scores are assigned to the sentences, whereas the sentence-level valence is identified based on the total sense scores of the word-level emotion tags along with their polarity. Evaluation was carried out with respect to the best two emotion tags on 250 gold standard test sentences and achieved satisfactory results for sentence-level emotion and valence tagging. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  address   = {Das, Dipankar: Department of Computer Science and Engineering, Jadavpur University, Kolkata, India, dipankar.dipnil2005@gmail.com},
  doi       = {10.1007/s12559-012-9173-0},
  issn      = {1866-9964(Electronic),1866-9956(Print)},
  journal   = {Cognitive Computation},
  keywords  = {*Expert Systems, *Machine Learning, Emotions, Sentences, Affective Valence},
  pages     = {420--435},
  publisher = {Springer},
  refid     = {2012-32116-005},
  volume    = {4},
}

@Misc{Provoost2019,
  author    = {Provoost, Simon and Ruwaard, Jeroen and van Breda, Ward and Riper, Heleen and Bosse, Tibor},
  title     = {Validating automated sentiment analysis of online cognitive behavioral therapy patient texts: An exploratory study.},
  year      = {2019},
  abstract  = {Introduction: Sentiment analysis may be a useful technique to derive a user’s emotional state from free text input, allowing for more empathic automated feedback in online cognitive behavioral therapy (iCBT) interventions for psychological disorders such as depression. As guided iCBT is considered more effective than unguided iCBT, such automated feedback may help close the gap between the two. The accuracy of automated sentiment analysis is domain dependent, and it is unclear how well the technology is applicable to iCBT. This paper presents an empirical study in which automated sentiment analysis by an algorithm for the Dutch language is validated against human judgment. Methods: A total of 493 iCBT user texts were evaluated on overall sentiment and the presence of five specific emotions by an algorithm, and by 52 psychology students who evaluated 75 randomly selected texts each, providing about eight human evaluations per text. Inter-rater agreement (IRR) between algorithm and humans, and humans among each other, was analyzed by calculating the intra-class correlation under a numerical interpretation of the data, and Cohen’s kappa, and Krippendorff’s alpha under a categorical interpretation. Results: All analyses indicated moderate agreement between the algorithm and average human judgment with respect to evaluating overall sentiment, and low agreement for the specific emotions. Somewhat surprisingly, the same was the case for the IRR among human judges, which means that the algorithm performed about as well as a randomly selected human judge. Thus, considering average human judgment as a benchmark for the applicability of automated sentiment analysis, the technique can be considered for practical application. Discussion/Conclusion: The low human-human agreement on the presence of emotions may be due to the nature of the texts, it may simply be difficult for humans to agree on the presence of the selected emotions, or perhaps trained therapists would have reached more consensus. Future research may focus on validating the algorithm against a more solid benchmark, on applying the algorithm in an application in which empathic feedback is provided, for example, by an embodied conversational agent, or on improving the algorithm for the iCBT domain with a bottom-up machine learning approach. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {Provoost, Simon: s.j.provoost@vu.nl},
  doi       = {10.3389/fpsyg.2019.01065},
  issn      = {1664-1078(Electronic)},
  journal   = {Frontiers in Psychology},
  keywords  = {*Algorithms, *Cognitive Behavior Therapy, *Emotions, *Feedback, *Sentiment Analysis, Empathy, Judgment, Online Therapy},
  publisher = {Frontiers Media S.A.},
  refid     = {2019-29859-001},
  volume    = {10},
}

@Misc{Basti2015,
  author    = {Bastı, Eyup and Kuzey, Cemil and Delen, Dursun},
  title     = {Analyzing initial public offerings' short-term performance using decision trees and SVMs.},
  year      = {2015},
  abstract  = {In this study, we investigated underpricing of Turkish companies in the initial public offerings (IPOs) issued and traded on Borsa Istanbul between 2005 and 2013. The underpricing of stocks in IPOs, or essentially leaving money on the table, is considered as an important, challenging and worthy research topic in literature. Within the proposed framework, the IPO performance in the short run and the factors that affect this short run performance were analyzed. Popular machine learning methods - several decision tree models and support vector machines - were developed to investigate the major factors affecting the short-term performance of initial IPOs. A k-fold cross validation methodology was used to assess and contrast the performance of the predictive models. An information fusion-based sensitivity analysis was performed to combine the values of individual variable importance results into a common representation. The results showed that there was underpricing in the initial public offerings of Turkish companies, although it was not as high as the underpricing determined in developed markets. The market sentiment, the annual sales amounts, the total assets turnover rates, IPO stocks sales methods, the underwriting methods, the offer prices, debt ratio, and number of shares sold were among the most influential factors affecting the short term performance of initial public offerings of Turkish companies. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  address   = {Delen, Dursun: Oklahoma State University, 700 N. Greenwood Ave., #NH341, Tulsa, OK, US, 74106, dursun.delen@okstate.edu},
  doi       = {10.1016/j.dss.2015.02.011},
  issn      = {0167-9236(Print)},
  journal   = {Decision Support Systems},
  keywords  = {*Algorithms, *Decision Making, *Financial Services, Costs and Cost Analysis, Management Methods},
  pages     = {15--27},
  publisher = {Elsevier Science},
  refid     = {2015-17024-003},
  volume    = {73},
}

@Misc{Brady2022,
  author    = {Brady, William J. and McLoughlin, Killian and Crockett, M. J.},
  title     = {Theory‑driven measurement of emotion (expressions) in social media text.},
  year      = {2022},
  abstract  = {With over 3 billion users across the world, social media platforms provide researchers with an opportunity to study a massive volume of emotion expressions unfolding in real-time social interactions. As new computational tools are becoming available, social media data increasingly afford researchers the ability to study psychological questions about emotions at an unprecedented scale. This chapter provides psychologists with a practical guide for making use of advances in sentiment analysis for the purpose of measuring specific emotions in social media text, and ultimately testing hypotheses. It begins with an examination of the type of emotion related information researchers can expect to measure in social media text. Next, it presents a practical guide for the theory-driven application of supervised machine learning to measure specific emotion expressions on social media using the measurement of moral outrage expression as a case study. The chapter ends with considerations for researchers who wish to apply sentiment analysis of social media text for the purposes of psychological hypothesis testing. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {New York, NY, US},
  issn      = {978-1-4625-4843-9 (Hardcover)},
  journal   = {Handbook of language analysis in psychology.},
  keywords  = {*Discourse Analysis, *Expressed Emotion, *Social Media, *Text Messaging, *Sentiment Analysis, Hypothesis Testing, Machine Learning, Psychologists, Social Interaction},
  pages     = {377--388},
  publisher = {The Guilford Press},
  refid     = {2022-08338-019},
}

@Misc{Jothikumar2021,
  author    = {Jothikumar, R. and Vijay Anand, R. and Visu, P. and Kumar, R. and Susi, S. and Kumar K., R.},
  title     = {Sentiment analysis of tweets on the COVID-19 pandemic using machine learning techniques.},
  year      = {2021},
  abstract  = {Sentiment evaluation alludes to separate the sentiments from the characteristic language and to perceive the mentality about the exact theme. Novel corona infection, a harmful malady ailment, is spreading out of the blue through the quarter, which thought processes respiratory tract diseases that can change from gentle to extraordinary levels. Because of its quick nature of spreading and no conceived cure, it ushered in a vibe of stress and pressure. In this chapter, a framework perusing principally based procedure is utilized to discover the musings of the tweets related to COVID and its effect lockdown. The chapter examines the tweets identified with the hash tags of crown infection and lockdown. The tweets were marked fabulous, negative, or fair, and a posting of classifiers has been utilized to investigate the precision and execution. The classifiers utilized have been under the four models which incorporate decision tree, regression, helpful asset vector framework, and naïve Bayes forms. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Hershey, PA, US},
  issn      = {9781799868729 (Digital (undefined format)); 9781799868705 (Hardcover)},
  journal   = {Handbook of research on innovations and applications of AI, IoT, and cognitive technologies.},
  keywords  = {*Machine Learning, *Pandemics, *Social Media, *Sentiment Analysis, COVID-19},
  pages     = {310--320},
  publisher = {Engineering Science Reference/IGI Global},
  refid     = {2021-31713-022},
  series    = {Advances in computational intelligence and robotics (ACIR) book series.},
}

@Misc{Rolnicki2019,
  author    = {Rolnicki, Sandra J. H.},
  title     = {Applications of natural language processing to measure and assess risk in the U.S. financial system.},
  year      = {2019},
  abstract  = {Financial institutions play a critical role in maintaining the stability of U.S. financial market due to their function as intermediaries and their role as some of the market's largest publicly traded companies. Annually these firms file 10-K reports with the Securities and Exchange Commission (SEC). While there have been recent advances in performing content analysis of 10-K reports to assess the value of the information they contain (Balvers et al., 2015; Bodnaruk et al., 2015; Ertugrul et al., 2017; Lang and Stice-Lawrence, 2014; Loughran and McDonald, 2011, 2014a, 2014b, 2016; McClelland et al., 2010), researchers have been limited in their application of natural language processing (NLP) to establish a quantitative link between the content of 10-Ks and the actual outcomes for the firms, with notable exceptions of Gandhi et al. (2018) in their use of sentiment as a proxy for financial distress in U.S. banks. To fill this gap in the literature, I have applied NLP techniques, including unsupervised machine learning, to over 11,000 annual reports covering over 1,000 firms between 1994 and 2016. A hand-collected dataset of enforcement actions from Federal Banking Agencies' public websites provided over 2,000 firm-year examples for comparison against banks without enforcement actions. My results of structured topic modeling and sentiment analysis of 10-K reports yielded unique insights about the power of banks' words to provide indicators of risk, both at the individual bank level and at the collective, systemic level. Portfolio constructions based on sentiment yielded signals that predicted both the Dot-Com Bubble and the Financial Crisis, while significantly out-performing both the Standard & Poor 500 and a Bank Index of stocks. Event studies that grouped banks by sentiment consistently produced abnormal returns according to sentiment and identified patterns that reflect how the market reacts to and absorbs negative news from banks with enforcement actions. These applications could complement existing measures of risk in the U.S. financial system. Shareholders and other financial market participants, including financial firms' clients, analysts, employees and regulators will benefit from this work. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4209(Print)},
  keywords  = {*Financial Strain, *Risk Factors, *Websites, Natural Language},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2018-58618-203},
  volume    = {80},
}

@Misc{Zheng2018,
  author    = {Zheng, Yilong},
  title     = {Empirical investigations of social influences on new business models.},
  year      = {2018},
  abstract  = {This dissertation focuses on understanding the critical effects of social influences on three trending but unconventional business practices: the introduction of refurbished products as product line extension, the use of crowdsourcing platforms for conducting nonprofit prosocial behaviors, and the display of social comparison cues in missed deals to prospective shoppers on E-commerce sites. Different from past literatures, we provide new insights and findings to help understand why and how these unconventional business models can utilize social influences to create positive impact, despite many reasons to think otherwise. The first essay examines the joint effect of introducing refurbished products on existing product line, under positive network externalities and negative quality connotation coming from the potential sales of refurbished products. Results indicate the joint effect on current product line is contingent on the network standard manufactures employed. The second essay investigates the effects of competition, collaboration, and the communication on a crowdsourcing platform on real-world prosocial behaviors. More specifically, the author examines how winning or losing in the competition, participation as individual or a group, and conversations with other participants can jointly influence one's tendency to conduct upcoming prosocial behaviors. This essay presents three different ways to study these moderating effects which includes empirical modeling, sentiment analysis using machine learning techniques, and agent-based simulation. The final essay touches on an interesting perspective of online E-commerce promotion: the presentation of missed deal information in social comparison context. The researcher shows that the presentation of bypassed deal information with social comparison cues, whether intentionally or unintentionally, can exacerbated the inaction behavior if the missed deal was popular among others. However, the effect of presenting missed deal information with social comparison cues is not solely negative. By presenting upcoming complementary deals offered at a same or less attractive discount after the previous missed deal, results show the general store favorability and purchase intention can be improved significantly. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4209(Print)},
  keywords  = {*Competition, *Prosocial Behavior, *Social Influences, Cues},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2018-13258-275},
  volume    = {79},
}

@Misc{Poria2014,
  author    = {Poria, Soujanya and Cambria, Erik and Winterstein, Grégoire and Huang, Guang-Bin},
  title     = {Sentic patterns: Dependency-based rules for concept-level sentiment analysis.},
  year      = {2014},
  abstract  = {The Web is evolving through an era where the opinions of users are getting increasingly important and valuable. The distillation of knowledge from the huge amount of unstructured information on the Web can be a key factor for tasks such as social media marketing, branding, product positioning, and corporate reputation management. These online social data, however, remain hardly accessible to computers, as they are specifically meant for human consumption. The automatic analysis of online opinions involves a deep understanding of natural language text by machines, from which we are still very far. To this end, concept-level sentiment analysis aims to go beyond a mere word-level analysis of text and provide novel approaches to opinion mining and sentiment analysis that enable a more efficient passage from (unstructured) textual information to (structured) machine-processable data. A recent knowledge-based technology in this context is sentic computing, which relies on the ensemble application of common-sense computing and the psychology of emotions to infer the conceptual and affective information associated with natural language. Sentic computing, however, is limited by the richness of the knowledge base and by the fact that the bag-of-concepts model, despite more sophisticated than bag-of-words, misses out important discourse structure information that is key for properly detecting the polarity conveyed by natural language opinions. In this work, we introduce a novel paradigm to concept-level sentiment analysis that merges linguistics, common-sense computing, and machine learning for improving the accuracy of tasks such as polarity detection. By allowing sentiments to flow from concept to concept based on the dependency relation of the input sentence, in particular, we achieve a better understanding of the contextual role of each concept within the sentence and, hence, obtain a polarity detection engine that outperforms state-of-the-art statistical methods. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {Cambria, Erik: cambria@ntu.edu.sg},
  doi       = {10.1016/j.knosys.2014.05.005},
  issn      = {1872-7409(Electronic),0950-7051(Print)},
  journal   = {Knowledge-Based Systems},
  keywords  = {*Algorithms, *Artificial Intelligence, *Linguistics, *Machine Learning, *Natural Language, Concepts, Sentiment Analysis, Natural Language Processing},
  pages     = {45--63},
  publisher = {Elsevier Science},
  refid     = {2014-34186-001},
  volume    = {69},
}

@Misc{Lee2021,
  author    = {Lee, Kyungmin (Brad)},
  title     = {Essays on spatial and behavioral analytics for platform design.},
  year      = {2021},
  abstract  = {The design and operation of a two-sided platform require a variety of decisions to facilitate a match between sellers (capacity) and buyers (demand). Many platforms deploy analytic capabilities to leverage rich information, on both demand and capacity, that is available in real-time. This dissertation research explores design decisions, such as price structure and quality controls, and allied analytic capabilities in order to document their impact on platform governance. These decisions are tested in the context of ride-sharing platform by positing three fundamental challenges that must be accounted for effective design: (1) spatial distribution of capacity and demand that allows for capacity spillovers, (2) buyer's sentiment biases, and (3) seller's relocation biases. These challenges are assessed in three separate but related essays.The first essay investigates how the policies for setting surge prices should be designed under capacity spillovers. Using a data set from Uber's operations, we estimate a spatial panel model to reveal its surge pricing structure that accounts for spatial dependency. Allied counterfactual analysis illustrates the limitations of a spot pricing policy (i.e., a policy that does not account for spillovers).The second essay assesses the impact of buyer's sentiment bias, ranging from optimism to pessimism, on the platform's decision to control seller quality. Platforms face a trade-off between ensuring high-quality sellers and guaranteeing enough sellers such that wait-time is lowered. We formally characterize an optimal exclusion threshold on seller quality in the presence of sentiment bias.We also examine strategies that a platform can access to benefit from buyer's behavioral biases. Results document the impact of seller quality on a platform's profitability and social welfare.In the last essay, we focus on the seller's relocation behavior. There is a debate in the literature on whether sellers' willingness to relocate across demand zones in order to chase surging prices is rewarded in a ride-sharing platform setting. Using multiple machine learning algorithms, we classify rewarding behaviors with different pricing structures under a variety of circumstances. Results provide guidance on how to provide incentives while managing the dynamics of spatially distributed capacity. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4217(Print)},
  keywords  = {*Consumer Behavior, *Costs and Cost Analysis, *Geographical Mobility, *Policy Making, *Rewards, Pessimism, Quality Control, Test Bias},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2020-67315-258},
  volume    = {82},
}

@Misc{Bigorra2019,
  author    = {Bigorra, Anna Martí and Isaksson, Ove and Karlberg, Magnus},
  title     = {Aspect-based Kano categorization.},
  year      = {2019},
  abstract  = {Customers commonly share opinions and experiences about products via the internet by means of social media and networking sites. The generated textual data is often analysed by means of Sentiment Analysis (SA) as means to assess customer opinions on product features more efficiently than through surveys. To enable a more objective product target setting, the impact of product feature performance changes on customer satisfaction is essential. Kano et al. (1984) presented a survey-based model to classify product features based on their impact on customer satisfaction to aid designers in their product target setting. Approaches extending the Kano model rely on customer surveys as input data. In addition, existing studies classifying extracted product features from textual data (e.g. product reviews) rarely provide a clear separation in terms of Kano categories. Thus, the impact of identified product features on customer satisfaction remains unknown to product designers. This paper presents a methodology for autonomously classifying extracted aspects from textual data into Kano categories. For verification purposes, two examples using coffee machine and smartphone user reviews are presented. Results indicate that the proposed methodology efficiently provides product designers with insightful customer information through the proposed aspect categorization. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {Bigorra, Anna Martí: anna.marti.bigorra@ltu.se},
  doi       = {10.1016/j.ijinfomgt.2018.11.004},
  issn      = {1873-4707(Electronic),0268-4012(Print)},
  journal   = {International Journal of Information Management},
  keywords  = {*Consumer Attitudes, *Methodology, Sentiment Analysis},
  pages     = {163--172},
  publisher = {Elsevier Science},
  refid     = {2019-17613-014},
  volume    = {46},
}

@Misc{MacLaren2017,
  author    = {MacLaren, Rick and Tran, Van H. and Chiappe, Dan},
  title     = {Effects of motivation orientation on schoolwork enjoyment and achievement and study habits.},
  year      = {2017},
  abstract  = {The present study assessed the effect of student motivation and actions that support scholastic achievement on the performance, mental life and study habits of undergraduate students. Two hundred twenty one psychology students completed questionnaires, containing scales and essay texts, assessing performance, motivational orientation, measures of flow experiences and actions relevant to successful scholastic activities. Intrinsically-motivated participants adopted habits and states of mind that supported school work, resulting in better performance. The results of analyses of Likert scales and machine sentiment analyses of participants’ narrative essay texts suggest that intrinsically-oriented people seek out opportunities to perform actions that regulate their schoolwork situation and mental state, and modulate study activities and awareness to be in accord with their intentions, and report states of mind consistent with optimal, flow experiences, unlike non intrinsically-oriented participants. These flow experiences were reflected in participant reports of school experience, measured using machine sentiment analysis (Narayanan, 2016; Narayanan, Arora, & Bhatia, 2013). Participant optimal experiences positively impact satisfaction, and performance. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {MacLaren, Rick: c/o Dan Chiappe 1250 N Bellflower Blvd, Long Beach, CA, US, 90840, rick.maclaren@alumni.utoronto.ca},
  doi       = {10.1016/j.tsc.2017.03.003},
  issn      = {1878-0423(Electronic),1871-1871(Print)},
  journal   = {Thinking Skills and Creativity},
  keywords  = {*Academic Achievement, *School Environment, *Student Attitudes, Sentiment Analysis},
  pages     = {199--227},
  publisher = {Elsevier Science},
  refid     = {2017-28545-020},
  volume    = {24},
}

@Misc{Kagan2013,
  author    = {Kagan, Vadim and Rossini, Edward and Sapounas, Demetrios},
  title     = {Sentiment analysis for PTSD signals.},
  year      = {2013},
  abstract  = {The book provides background information on PTSD and related psychological signals; details the technology developed, the data flows, the processing and results; and a sample system implementation. More specifically the subsequent chapters cover: (1) An introduction to PTSD that will explain the notion of PTSD-related psychological signals, and will also present the categorization of PTSD symptoms, the sources and methodologies used to unify clinical and colloquial terms into a PTSD ontology, and the resulting ontology. (2) A description of the selection of data sources serving as inputs to the system for training and testing the text analysis algorithms. This section will also cover the selection criteria applied to web forums and blogs, and will explain the role the materials from the psychological library play in the project. Further, the data collection and pre-processing workflow before the data is stored in a database and submitted to the text analysis engine for processing will be described. (3) As part of the discussion on text analysis of PTSD text, a description of the general approach taken with the extraction and quantification of PTSD-related signals with an overview of the relevant natural language processing techniques, focusing on sentiment mining, and the role of the annotated corpus. Additionally, the human annotation process and tools developed for creating algorithm training and testing data sets will be outlined. (4) An overview of the SentiMetrix® SentiGrade™ scoring engine, and a description of the enhancements made to the engine and the training that was necessary to tune it for the detection of PTSD-related signals. (5) A sample system implementation integrating all the tools into a cohesive environment, implementing an automated end-to-end process, including social networking features used for collecting data from anonymous user participation. The system architecture, including the data flow and feedback loops, as well as the reports generated by the system will also be outlined. 6. Finally, the project findings are presented. These findings compare and contrast the results produced by the automated system with evaluation of the same anonymous data set by a team of clinical psychologists. The analysis presents strong supporting evidence of viability of automated detection of psychological signals associated with PTSD. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  address   = {New York, NY, US},
  doi       = {10.1007/978-1-4614-3097-1},
  issn      = {978-1-4614-3096-4 (Paperback); 978-1-4614-3097-1 (PDF)},
  journal   = {Sentiment analysis for PTSD signals.},
  keywords  = {*Automated Information Processing, *Emotional Content, *Human Machine Systems Design, *Posttraumatic Stress Disorder, *Sentiment Analysis, Data Collection, Ontology (Philosophy), Psychodynamics, Symptoms, Technology},
  pages     = {x, 81--x, 81},
  publisher = {Springer Science + Business Media},
  refid     = {2013-40929-000},
  series    = {Springer briefs in computer science.},
}

@Misc{CarrillodeAlbornoz2018,
  author    = {Carrillo-de-Albornoz, Jorge and Rodríguez Vidal, Javier and Plaza, Laura},
  title     = {Feature engineering for sentiment analysis in e-health forums.},
  year      = {2018},
  abstract  = {Introduction: Exploiting information in health-related social media services is of great interest for patients, researchers and medical companies. The challenge is, however, to provide easy, quick and relevant access to the vast amount of information that is available. One step towards facilitating information access to online health data is opinion mining. Even though the classification of patient opinions into positive and negative has been previously tackled, most works make use of machine learning methods and bags of words. Our first contribution is an extensive evaluation of different features, including lexical, syntactic, semantic, network-based, sentiment-based and word embeddings features to represent patient-authored texts for polarity classification. The second contribution of this work is the study of polar facts (i.e. objective information with polar connotations). Traditionally, the presence of polar facts has been neglected and research in polarity classification has been bounded to opinionated texts. We demonstrate the existence and importance of polar facts for the polarity classification of health information. Material and methods: We annotate a set of more than 3500 posts to online health forums of breast cancer, crohn and different allergies, respectively. Each sentence in a post is manually labeled as “experience”, “fact” or “opinion”, and as “positive”, “negative” and “neutral”. Using this data, we train different machine learning algorithms and compare traditional bags of words representations with word embeddings in combination with lexical, syntactic, semantic, network- based and emotional properties of texts to automatically classify patient-authored contents into positive, negative and neutral. Beside, we experiment with a combination of textual and semantic representations by generating concept embeddings using the UMLS Metathesaurus. Results: We reach two main results: first, we find that it is possible to predict polarity of patient-authored contents with a very high accuracy (≈ 70 percent) using word embeddings, and that this considerably outperforms more traditional representations like bags of words; and second, when dealing with medical information, negative and positive facts (i.e. objective information) are nearly as frequent as negative and positive opinions and experiences (i.e. subjective information), and their importance for polarity classification is crucial. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {Carrillo-de-Albornoz, Jorge: jcalbornoz@lsi.uned.es},
  doi       = {10.1371/journal.pone.0207996},
  issn      = {1932-6203(Electronic)},
  journal   = {PLoS ONE},
  keywords  = {*Health Behavior, *Social Media, Engineering},
  publisher = {Public Library of Science},
  refid     = {2018-61911-001},
  volume    = {13},
}

@Article{Pan2022,
  author    = {Pan, Xianglin and Hu, Bihao and Zhou, Zihao and Feng, Xiang},
  journal   = {Interactive Learning Environments},
  title     = {Are students happier the more they learn? - research on the influence of course progress on academic emotion in online learning.},
  year      = {2022},
  issn      = {1744-5191(Electronic),1049-4820(Print)},
  pages     = {No Pagination Specified--No Pagination Specified},
  abstract  = {Academic emotions of learners are important for academic achievement. For the online learning platform, it is of great value to gain insight into the academic emotion of the course in appropriate time interval from the platform. We crawled a large number of student comment texts from MOOC, and used deep learning algorithms (BERT models) to perform aspect-oriented sentiment classification on the comment texts. We conducted statistical analysis and identified keywords to explore the changes of academic emotions in the online learning environment in different aspect dimensions. The results show that academic emotions are significantly improved in the first and second period of the course schedule, and tend to be stable in the second and third period of the course schedule. From the word frequency statistics, in the dimension of the teacher, students’ concerns mainly focus on two aspects: One is whether they can acquire knowledge, the other is the characteristics of teachers; in the course dimension, students attach more importance to the learning; in the dimension of the platform, students’ negative emotions mainly focus on four aspects: certificate, learning record, prompt and subtitle. Our research aims at providing suggestions for course design, platform improvement, and teachers’ practice. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Feng, Xiang: xfeng@eec.ecnu.edu.cn},
  doi       = {10.1080/10494820.2022.2052110},
  publisher = {Taylor & Francis},
  refid     = {2022-50333-001},
}

@Misc{Gu2021,
  author    = {Gu, Tianyu},
  title     = {Analyzing unstructured data for marketing insights.},
  year      = {2021},
  abstract  = {In this dissertation, I am focused on analyzing the effects of information embedded in unstructured data on consumer decisions and firm strategies. Mining unstructured data (such as natural language and visual imagery) for insights and implications has become a key area in business research. Methodologically, I employ cutting-edge techniques in machine learning and deep learning to construct structural and sentiment measures for large-scale data and employ econometric methods to analyze their impact.The dissertation includes three projects on the effects of information that exists in different formats (text vs. image, virtual vs. reality) and on different platforms (crowdfunding, online reviews, and video games). The data techniques I employed in the analysis include convolutional neural network (CNN), long short-term memory (LSTM), gated recurrent unit (GRU), attention model, transfer learning, support vector machine (SVM), and latent Dirichlet allocation (LDA).In the first chapter, I examine the differentiation of the content of online reviews, and the strategic motivations behind the differentiation. In the second chapter, I investigate the impact of text and image in project description on the likelihood of crowdfunding success, as well as their joint effects. Finally, the third chapter investigates the impact of real-world events on consumers' likelihood of playing video games and making virtual purchases. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4217(Print)},
  keywords  = {*Computer Games, *Marketing, *Organizational Behavior, *Short Term Memory, *Artificial Neural Networks, Machine Learning, Crowdsourcing},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2020-58781-145},
  volume    = {82},
}

@Misc{Malandri2018,
  author    = {Malandri, Lorenzo and Xing, Frank Z. and Orsenigo, Carlotta and Vercellis, Carlo and Cambria, Erik},
  title     = {Public mood-driven asset allocation: The importance of financial sentiment in portfolio management.},
  year      = {2018},
  abstract  = {The study of the impact of investor sentiment on stock returns has gained increasing momentum in the past few years. It has been widely accepted that public mood is correlated with financial markets. However, only a few studies discussed how the public mood would affect one of the fundamental problems of computational finance: portfolio management. In this study, we use public financial sentiment and historical prices collected from the New York Stock Exchange (NYSE) to train multiple machine learning models for automatic wealth allocation across a set of assets. Unlike previous studies which set as target variable the asset prices in the portfolio, the variable to predict here is represented by the best asset allocation strategy ex post. Experiments performed on five portfolios show that long short-term memory networks are superior to multi-layer perceptron and random forests producing, in the period under analysis, an average increase in the revenue across the portfolios ranging between 5% (without financial mood) and 19% (with financial mood) compared to the equal-weighted portfolio. Results show that our all-in-one and end-to-end approach for automatic portfolio selection outperforms the equal-weighted portfolio. Moreover, when using long short-term memory networks, the employment of sentiment data in addition to lagged data leads to greater returns for all the five portfolios under evaluation. Finally, we find that among the employed machine learning algorithms, long short-term memory networks are better suited for learning the impact of public mood on financial time series. (PsycINFO Database Record (c) 2020 APA, all rights reserved)},
  address   = {Cambria, Erik: cambria@ntu.edu.sg},
  doi       = {10.1007/s12559-018-9609-2},
  issn      = {1866-9964(Electronic),1866-9956(Print)},
  journal   = {Cognitive Computation},
  keywords  = {*Long Term Memory, *Machine Learning, Short Term Memory},
  pages     = {1167--1176},
  publisher = {Springer},
  refid     = {2018-61131-001},
  volume    = {10},
}

@Misc{Zhou2021,
  author    = {Zhou, Xinyu and Song, Yi and Jiang, Hao and Wang, Qian and Qu, Zhiqiang and Zhou, Xiaoyu and Jit, Mark and Hou, Zhiyuan and Lin, Leesa},
  title     = {Comparison of public responses to containment measures during the initial outbreak and resurgence of COVID-19 in China: Infodemiology study.},
  year      = {2021},
  abstract  = {Background: COVID-19 cases resurged worldwide in the second half of 2020. Not much is known about the changes in public responses to containment measures from the initial outbreak to resurgence. Monitoring public responses is crucial to inform policy measures to prepare for COVID-19 resurgence. Objective: This study aimed to assess and compare public responses to containment measures during the initial outbreak and resurgence of COVID-19 in China. Methods: We curated all COVID-19-related posts from Sina Weibo (China’s version of Twitter) during the initial outbreak and resurgence of COVID-19 in Beijing, China. With a Python script, we constructed subsets of Weibo posts focusing on 3 containment measures: lockdown, the test-trace-isolate strategy, and suspension of gatherings. The Baidu open-source sentiment analysis model and latent Dirichlet allocation topic modeling, a widely used machine learning algorithm, were used to assess public engagement, sentiments, and frequently discussed topics on each containment measure. Results: A total of 8,985,221 Weibo posts were curated. In China, the containment measures evolved from a complete lockdown for the general population during the initial outbreak to a more targeted response strategy for high-risk populations during COVID-19 resurgence. Between the initial outbreak and resurgence, the average daily proportion of Weibo posts with negative sentiments decreased from 57% to 47% for the lockdown, 56% to 51% for the test-trace-isolate strategy, and 55% to 48% for the suspension of gatherings. Among the top 3 frequently discussed topics on lockdown measures, discussions on containment measures accounted for approximately 32% in both periods, but those on the second-most frequently discussed topic shifted from the expression of negative emotions (11%) to its impacts on daily life or work (26%). The public expressed a high level of panic (21%) during the initial outbreak but almost no panic (1%) during resurgence. The more targeted test-trace-isolate measure received the most support (60%) among all 3 containment measures in the initial outbreak, and its support rate approached 90% during resurgence. Conclusions: Compared to the initial outbreak, the public expressed less engagement and less negative sentiments on containment measures and were more supportive toward containment measures during resurgence. Targeted test-trace-isolate strategies were more acceptable to the public. Our results indicate that when COVID-19 resurges, more targeted test-trace-isolate strategies for high-risk populations should be promoted to balance pandemic control and its impact on daily life and the economy. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  address   = {Hou, Zhiyuan: School of Public Health, Fudan University, Mailbox 250, 138# Yixueyuan Road, Xuhui District, Shanghai, China, 200032, zyhou@fudan.edu.cn},
  doi       = {10.2196/26518},
  issn      = {1438-8871(Electronic),1439-4456(Print)},
  journal   = {Journal of Medical Internet Research},
  keywords  = {*Panic, *Responses, *Simulation, *Social Media, *COVID-19, Pandemics, Negative Emotions, Psychological Engagement},
  publisher = {JMIR Publications},
  refid     = {2021-58443-001},
  volume    = {23},
}

@Misc{Aladag2018,
  author    = {Aladağ, Ahmet Emre and Muderrisoglu, Serra and Akbas, Naz Berfu and Zahmacioglu, Oguzhan and Bingol, Haluk O.},
  title     = {Detecting suicidal ideation on forums: Proof-of-concept study.},
  year      = {2018},
  abstract  = {Background: In 2016, 44,965 people in the United States died by suicide. It is common to see people with suicidal ideation seek help or leave suicide notes on social media before attempting suicide. Many prefer to express their feelings with longer passages on forums such as Reddit and blogs. Because these expressive posts follow regular language patterns, potential suicide attempts can be prevented by detecting suicidal posts as they are written. Objective: This study aims to build a classifier that differentiates suicidal and nonsuicidal forum posts via text mining methods applied on post titles and bodies. Methods: A total of 508,398 Reddit posts longer than 100 characters and posted between 2008 and 2016 on SuicideWatch, Depression, Anxiety, and ShowerThoughts subreddits were downloaded from the publicly available Reddit dataset. Of these, 10,785 posts were randomly selected and 785 were manually annotated as suicidal or nonsuicidal. Features were extracted using term frequency-inverse document frequency, linguistic inquiry and word count, and sentiment analysis on post titles and bodies. Logistic regression, random forest, and support vector machine (SVM) classification algorithms were applied on resulting corpus and prediction performance is evaluated. Results: The logistic regression and SVM classifiers correctly identified suicidality of posts with 80% to 92% accuracy and F1 score, respectively, depending on different data compositions closely followed by random forest, compared to baseline ZeroR algorithm achieving 50% accuracy and 66% F1 score. Conclusions: This study demonstrated that it is possible to detect people with suicidal ideation on online forums with high accuracy. The logistic regression classifier in this study can potentially be embedded on blogs and forums to make the decision to offer real-time online counseling in case a suicidal post is being written. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {Aladağ, Ahmet Emre: Department of Computer Engineering, Bogazici University, Istanbul, Turkey, 34342, emre.aladag@boun.edu.tr},
  doi       = {10.2196/jmir.9840},
  issn      = {1438-8871(Electronic),1439-4456(Print)},
  journal   = {Journal of Medical Internet Research},
  keywords  = {*Suicidal Ideation, *Suicide, *Suicide Prevention, *Online Social Networks, *Suicidality, Artificial Intelligence, Machine Learning},
  publisher = {JMIR Publications},
  refid     = {2018-57167-001},
  volume    = {20},
}

@Misc{Owusu2021,
  author    = {Owusu, Abena Fosua},
  title     = {Three essays on the application of machine learning for risk governance in financial institutions.},
  year      = {2021},
  abstract  = {This dissertation consists of three essays on risk governance in financial institutions that underline the importance of risk culture and risk assessment and response for effective risk governance. According to the International Finance Corporation (IFC), risk governance focuses on applying the principles of sound corporate governance to the identification, management and communication of risks. The 2008 global financial crisis highlighted the lack of firm values, ethics and governance structure that understands, identifies and manages risks as they evolve in the financial industry. With increasingly frequent climate disasters in recent years, investors are also interested in financial firm's governance of climate-related issues they face in their Environmental, Social and Governance (ESG) investments. Hence, efforts by governments and regulators to enhance risk governance in the finance industry have addressed topics related to the risk culture of financial firms and regulatory disclosure of firms' response to risk factors that pose threats to the industry's financial stability and soundness.The first two essays of my dissertation focus on risk culture as an important element for risk governance and risk management in U.S. banks and insurance firms. The third essay identifies climate change risk as an emerging risk impacting the financial industry and explores insurance firms' assessment and adaptation to climate change risks. Due to the challenges in defining and measuring abstract concepts such as risk culture and risk response, I apply big data analytical tools, specifically textual analysis and machine learning techniques, to identify financial institutions' risk culture and response to climate change risks using information disclosed in their 10-K regulatory filings with the U.S. Securities and Exchange Commission (SEC).In the first essay, I apply text mining and unsupervised machine learning algorithms to identify the risk culture of U.S. bank holding companies using risk culture-sentiment features extracted from their 10-K annual filings. I find that the uncertainty, litigious and constraining sentiments associated with the leadership, strategy and portfolio of the banks are significant in defining the banks' risk culture. Cluster analysis of these features proposes three distinct risk culture clusters, which can be labeled as good, fair and poor. Examining the relation between risk culture and performance, I find that banks with a sound (good and fair) risk culture are characterized by high profitability ratios, bank stability, lower default risk and good governance, consistent with regulatory expectations.The second essay examines the impact of regulation on the risk culture of U.S. insurance firms to address the call for federal regulations in the insurance industry after the 2007-2008 financial crisis. By applying machine learning techniques to define insurance firms' risk culture, I assess how risk culture changes in the insurance industry over time. My findings show a positive impact of the federal Dodd-Frank regulation on risk culture in the insurance industry. I find that the risk culture of insurance firms is significantly defined by their risk strategies, decisions, and recruitment and training practices. A spatial and temporal prediction analysis of risk culture shows that, over time, large insurers who downgrade into a poor risk culture state have a higher probability of remaining in this downward trend relative to large insurers that improved their risk culture status. Similarly, I observe an improvement in risk culture of large insurers after the Dodd-Frank Act was passed, compared to non-large insurers. In the third essay, I assess and distinguish between insurance firms' response to climate change risks, and examine how their climate change risk exposures relate to their financial and governance characteristics.… (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4217(Print)},
  keywords  = {*Business, *Business Organizations, *Insurance, *Risk Factors, *Climate Change, Banking, Machine Learning, Risk Management},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2020-97492-213},
  volume    = {82},
}

@Misc{Falk2012,
  author    = {Falk, Emily B. and O'Donnell, Matthew Brook and Lieberman, Matthew D.},
  title     = {Getting the word out: Neural correlates of enthusiastic message propagation.},
  year      = {2012},
  abstract  = {What happens in the mind of a person who first hears a potentially exciting idea? We examined the neural precursors of spreading ideas with enthusiasm, and dissected enthusiasm into component processes that can be identified through automated linguistic analysis, gestalt human ratings of combined linguistic and non-verbal cues, and points of convergence/divergence between the two. We combined tools from natural language processing (NLP) with data gathered using fMRI to link the neurocognitive mechanisms that are set in motion during initial exposure to ideas and subsequent behaviors of these message communicators outside of the scanner. Participants’ neural activity was recorded as they reviewed ideas for potential television show pilots. Participants’ language from video-taped interviews collected post-scan was transcribed and given to an automated linguistic sentiment analysis (SA) classifier, which returned ratings for evaluative language (evaluative vs. descriptive) and valence (positive vs. negative). Separately, human coders rated the enthusiasm with which participants transmitted each idea. More positive sentiment ratings by the automated classifier were associated with activation in neural regions including medial prefrontal cortex; MPFC, precuneus/posterior cingulate cortex; PC/PCC, and medial temporal lobe; MTL. More evaluative, positive, descriptions were associated exclusively with neural activity in temporal-parietal junction (TPJ). Finally, human ratings indicative of more enthusiastic sentiment were associated with activation across these regions (MPFC, PC/PCC, DMPFC, TPJ, and MTL) as well as in ventral striatum (VS), inferior parietal lobule and premotor cortex. Taken together, these data demonstrate novel links between neural activity during initial idea encoding and the enthusiasm with which the ideas are subsequently delivered. This research lays the groundwork to use machine learning and neuroimaging data to study word of mouth communication and the spread of ideas in both traditional and new media environments. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  address   = {Falk, Emily B.: Institute for Social Research, 5234, 426 Thompson St., Ann Arbor, MI, US, 48104, ebfalk@umich.edu},
  doi       = {10.3389/fnhum.2012.00313},
  issn      = {1662-5161(Electronic)},
  journal   = {Frontiers in Human Neuroscience},
  keywords  = {*Enthusiasm, *Messages, *Neuroanatomy, *Neurocognition, Functional Magnetic Resonance Imaging},
  publisher = {Frontiers Media S.A.},
  refid     = {2012-33130-001},
  volume    = {6},
}

@Misc{Ortigosa2014,
  author    = {Ortigosa, Alvaro and Martín, José M. and Carro, Rosa M.},
  title     = {Sentiment analysis in facebook and its application to e-learning.},
  year      = {2014},
  abstract  = {This paper presents a new method for sentiment analysis in Facebook that, starting from messages written by users, supports: (i) to extract information about the users’ sentiment polarity (positive, neutral or negative), as transmitted in the messages they write; and (ii) to model the users’ usual sentiment polarity and to detect significant emotional changes. We have implemented this method in SentBuk, a Facebook application also presented in this paper. SentBuk retrieves messages written by users in Facebook and classifies them according to their polarity, showing the results to the users through an interactive interface. It also supports emotional change detection, friend’s emotion finding, user classification according to their messages, and statistics, among others. The classification method implemented in SentBuk follows a hybrid approach: it combines lexical-based and machine-learning techniques. The results obtained through this approach show that it is feasible to perform sentiment analysis in Facebook with high accuracy (83.27%). In the context of e-learning, it is very useful to have information about the users’ sentiments available. On one hand, this information can be used by adaptive e-learning systems to support personalized learning, by considering the user’s emotional state when recommending him/her the most suitable activities to be tackled at each time. On the other hand, the students’ sentiments towards a course can serve as feedback for teachers, especially in the case of online learning, where face-to-face contact is less frequent. The usefulness of this work in the context of e-learning, both for teachers and for adaptive systems, is described too. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {Ortigosa, Alvaro: Department of Computer Science, Universidad Autonoma de Madrid, Francisco Tomás y Valiente 11, Madrid, Spain, 28049, alvaro.ortigosa@uam.es},
  doi       = {10.1016/j.chb.2013.05.024},
  issn      = {1873-7692(Electronic),0747-5632(Print)},
  journal   = {Computers in Human Behavior},
  keywords  = {*Educational Psychology, *School Learning, *Online Social Networks, *Sentiment Analysis, Emotional States, Messages},
  pages     = {527--541},
  publisher = {Elsevier Science},
  refid     = {2013-28731-001},
  volume    = {31},
}

@Misc{Wawer2022,
  author    = {Wawer, Aleksander and Chojnicka, Izabela and Okruszek, Lukasz and Sarzynska-Wawer, Justyna},
  title     = {Single and cross-disorder detection for autism and schizophrenia.},
  year      = {2022},
  abstract  = {Detection of mental disorders from textual input is an emerging field for applied machine and deep learning methods. Here, we explore the limits of automated detection of autism spectrum disorder (ASD) and schizophrenia (SCZ). We compared the performance of: (1) dedicated diagnostic tools that involve collecting textual data, (2) automated methods applied to the data gathered by these tools, and (3) psychiatrists. Our article tests the effectiveness of several baseline approaches, such as bag of words and dictionary-based vectors, followed by a machine learning model. We employed two more refined Sentic text representations using affective features and concept-level analysis on texts. Further, we applied selected state-of-the-art deep learning methods for text representation and inference, as well as experimented with transfer and zero-shot learning. Finally, we also explored few-shot methods dedicated to low data size scenarios, which is a typical problem for the clinical setting. The best breed of automated methods outperformed human raters (psychiatrists). Cross-dataset approaches turned out to be useful (only from SCZ to ASD) despite different data types. The few-shot learning methods revealed promising results on the SCZ dataset. However, more effort is needed to explore the approaches to efficiently training models, given the very limited amounts of labeled clinical data. Psychiatry is one of the few medical fields in which the diagnosis of most disorders is based on the subjective assessment of a psychiatrist. Therefore, the introduction of objective tools supporting diagnostics seems to be pivotal. This paper is a step in this direction. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Wawer, Aleksander: Institute of Computer Science, Polish Academy of Sciences, Jana Kazimierza 5, Warszawa, Poland, 01 248, axw@ipipan.waw.pl},
  doi       = {10.1007/s12559-021-09834-9},
  issn      = {1866-9964(Electronic),1866-9956(Print)},
  journal   = {Cognitive Computation},
  keywords  = {*Autism Spectrum Disorders, *Machine Learning, *Schizophrenia, *Transfer (Learning), Sentiment Analysis},
  pages     = {461--473},
  publisher = {Springer},
  refid     = {2021-12746-001},
  volume    = {14},
}

@Misc{Choy2021,
  author    = {Choy, David F.},
  title     = {Environmental advocacy messages: Relationships between the messages that constituents send to decision makers and organizational engagement.},
  year      = {2021},
  abstract  = {Environmental advocacy organizations aim to help citizens contact their policymakers, to recruit new members, and to increase their contacts' level of engagement with organization issues. They use online petitions and form-letter services for these purposes. These services put citizens in contact with policymakers and encourage citizens to take follow-up actions, such as sending another message, referring a friend, or making a donation. While these services effectively recruit members, they marginally influence policymakers. To increase influence, organizations now ask petitioners to include personal messages in their communications. This dissertation asks if text analysis of these personal messages can help advocacy organizations further fulfill their recruitment and engagement goals. It investigates text-metrics both for predicting engagement from existing contacts and for services, such as chatbots, to suggest follow-up actions to new contacts. Methods employ rule-based text analysis tools (LIWC, VADER, Flesch Reading Ease, and Regular Expressions) to pilot the use of pronouns, sentiment, writing complexity, and the identification of personal stories as predictors of engagement. Data include over two million messages and nearly 500,000 personal messages from over 150,000 individuals supporting sustainable policies and projects. Results reveal relationships between messages and two engagement factors: (1) the number of messages that groups of contacts send and (2) payment of membership dues. Results also bolster research that highlights the importance of identifying contacts who can share stories about how environmental issues have affected them. Conclusions encourage advocacy organizations and policymakers to analyze messages to increase engagement and understand constituency support of policies and projects. Future work may integrate text analysis into membership models and advocacy services. Future work may also improve personal story classification and investigate machine-learning for identifying potential members. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4209(Print)},
  keywords  = {*Advocacy, *Membership, *Messages, *Policy Making, *Text Analysis, Decision Making, Pronouns},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2020-67311-130},
  volume    = {82},
}

@Misc{Yang2021,
  author    = {Yang, Fan},
  title     = {False textual information detection-towards building a truth machine.},
  year      = {2021},
  abstract  = {With social media growing dominant, false information, such as questionable claims and fake news, diffuses fast. Detecting false information is one of the most elusive and long-standing challenges. With social media growing dominant, falsehood can diffuse faster and broader than truth. This calls for building a ``truth machine" that automatically debunks false information. Although existing works have developed methods to prevent false information, challenges still remain. For example, previous works demand a large amount of annotated data and related evidence, underestimating the difficulty of evidence linking and the cost of manual annotation. Besides, since a large number of works rely on evidence to determine the credibility of claims, we need to carefully address situations when no evidence or noisy evidence is provided. This thesis aims to improve detecting false textual information from four aspects: 1. we first target sentiment classification because previous works show that leveraging sentiment can boost content-based rumor detection. We propose a representation learning framework that incorporates both labeled and unlabeled data. We show that our model learns robust features across domains and removes domain-specific features. 2. we develop a hierarchical model with attention mechanism so that our model reveals important insights at the paragraph level or at the sentence level. We evaluate our model on news satire detection and find that our model can effectively discover satirical cues at different levels. 3. we extend evidence-aware claim verification from supervised learning to positive-unlabeled learning. This setting requires a comparatively small number of true claims, and more claims can be unlabeled. We adopt the generative adversarial network to generate pseudo negative examples and conduct a thorough analysis of selected models. 4. we pay special attention to analyzing whether estimating entailment between evidence and claim helps not only to verify it but also to the preliminary step of retrieving the necessary evidence. We find that entailment indeed improves evidence ranking, as far as the entailment model produces reliable outputs. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  address   = {US},
  issn      = {0419-4217(Print)},
  keywords  = {*Credibility, *Learning, *Sentences, *Truth, *Social Media, Deception, Gossip, Labeling, News Media},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {ProQuest Information & Learning},
  refid     = {2021-27921-031},
  volume    = {82},
}

@Misc{Riordan2020,
  author    = {Riordan, Benjamin C. and Raubenheimer, Jacques and Ward, Rose Marie and Merrill, Jennifer E. and Winter, Taylor and Scarf, Damian},
  title     = {Monitoring the sentiment of cannabis‐related tweets in the lead up to new zealand's cannabis referendum.},
  year      = {2020},
  abstract  = {Introduction and Aims In October 2020, New Zealanders will vote on whether cannabis should be legalised for recreational use. With this in mind, the aim of the present study is to gauge the views and opinions of the New Zealand population on cannabis via tweets. To achieve this, we conducted a sentiment analysis of all historic cannabis‐related tweets and referendum‐specific tweets written in New Zealand. Design and Methods We used a Twitter‐sponsored commercial platform to access all historic cannabis‐related tweets written in New Zealand and used search terms to remove non‐cannabis‐related terms. Next, we used the platform's machine learning function to code the sentiment of tweets (i.e. positive/pro‐cannabis, negative/anti‐cannabis or neutral). Results Between July 2009 and August 2020, 304 760 cannabis‐related tweets were written in New Zealand. Overall, the tweets were predominantly positive (62.0%) and there was a higher proportion of positive tweets written in 2020 (65.3%) compared to negative or neutral tweets. Similarly, for referendum‐specific tweets, the 2020 data reveal a generally positive view of cannabis (53.5%). Discussion and Conclusions Both cannabis‐related, and referendum‐specific tweets, suggest that Twitter users in New Zealand have a generally positive view of cannabis. Given the nature of Twitter, the current method will allow us to study whether views toward cannabis change as the referendum nears and capture any late swings in pro‐ or anti‐cannabis sentiment (abcd‐lab.shinyapps.io/cannabis_sentiment/). (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {US},
  doi       = {10.1111/dar.13184},
  issn      = {1465-3362(Electronic),0959-5236(Print)},
  journal   = {Drug and Alcohol Review},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {John Wiley & Sons},
  refid     = {2020-75470-001},
}

@Misc{Mohammad2021,
  author    = {Mohammad, Saif M.},
  title     = {Sentiment analysis: Automatically detecting valence, emotions, and other affectual states from text.},
  year      = {2021},
  abstract  = {Recent advances in machine learning have led to computer systems that are humanlike in behavior. Sentiment analysis, the automatic determination of emotions in text, is allowing us to capitalize on substantial previously unattainable opportunities in commerce, public health, government policy, social sciences, and art. Further, analysis of emotions in text, from news to social media posts, is improving our understanding of not just how people convey emotions through language but also how emotions shape our behavior. This article presents a sweeping overview of sentiment analysis research that includes: the origins of the field, the rich landscape of tasks, challenges, a survey of the methods and resources used, and applications. We also discuss how, without careful fore-thought, sentiment analysis has the potential for harmful outcomes. We outline the latest lines of research in pursuit of fairness in sentiment analysis. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Mohammad, Saif M.: saif.mohammad@nrc-cnrc.gc.ca},
  doi       = {10.1016/B978-0-12-821124-3.00011-9},
  issn      = {978-0-12-821125-0 (Hardcover)},
  journal   = {Emotion measurement, 2nd ed.},
  keywords  = {*Emotional States, *Affective Valence, *Sentiment Analysis, Text Analysis},
  pages     = {323--379},
  publisher = {Elsevier},
  refid     = {2021-46839-011},
}

@Misc{Iacus2021,
  author    = {Iacus, S. M. and Porro, G.},
  title     = {Subjective well-being and social media.},
  year      = {2021},
  abstract  = {This book presents an overview of the most recent projects on the estimation of subjective well-being through social media data. In particular, it focuses on a new project, aimed at constructing a Twitter Subjective Well-Being Index, which started in 2012-almost at the same time of expansion of sentiment analysis to Twitter data-and grew slowly till the present days. The project was originally conceived at the University of Milan (Italy) and then embraced later in 2015 by the University of Insubria (Como, Italy), the University of Tokyo and the University of Waseda in Japan. The book reviews the different approaches to the estimation of well-being, from traditional macro-economic definition-both one-dimensional and multidimensional-to survey analysis and finally to big data and social networking sites (SNS) in particular. It introduces briefly the most commonly used machine learning and statistical techniques for textual analysis. It also serves two scopes: to explain how machines transforms text into meaningful statistics, and also to convey the idea that human supervision is an essential step of this process whatever technique is used. The book presents different SNS-based subjective well-being indexes that have been proposed in the literature, with a special focus on the one proposed by the authors. Among all positive aspects of SNS data, there are also some pitfalls which are quite easy to imagine, and well known to the experts in the field. The main one is that social media accounts/users/data cannot be considered statistically representative of the demographic population. The book presents a possible approach to tackle the selection bias problem by anchoring social media indexes to official statistics. It focuses on the analysis of the impact of the COVID-19 pandemic, that hit the world in 2020, on the social media indexes of subjective well-being. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  address   = {Boca Raton, FL, US},
  doi       = {10.1201/9780429401435},
  issn      = {9781138393929 (Hardcover); 978-1-032-04316-6 (Paperback); 978-0-429-40143-5 (Digital (undefined format))},
  journal   = {Subjective well-being and social media.},
  keywords  = {*Subjectivity, *Well Being, *Social Media, Biased Sampling, Machine Learning, Social Networks, Statistical Analysis, Big Data},
  pages     = {xiii, 206--xiii, 206},
  publisher = {CRC Press/Routledge/Taylor & Francis Group},
  refid     = {2021-80251-000},
}

@Misc{Liu2022,
  author    = {Liu, Tony and Meyerhoff, Jonah and Eichstaedt, Johannes C. and Karr, Chris J. and Kaiser, Susan M. and Kording, Konrad P. and Mohr, David C. and Ungar, Lyle H.},
  title     = {The relationship between text message sentiment and self-reported depression.},
  year      = {2022},
  abstract  = {Background: Personal sensing has shown promise for detecting behavioral correlates of depression, but there is little work examining personal sensing of cognitive and affective states. Digital language, particularly through personal text messages, is one source that can measure these markers. Methods: We correlated privacy-preserving sentiment analysis of text messages with self-reported depression symptom severity. We enrolled 219 U.S. adults in a 16 week longitudinal observational study. Participants installed a personal sensing app on their phones, which administered self-report PHQ-8 assessments of their depression severity, collected phone sensor data, and computed anonymized language sentiment scores from their text messages. We also trained machine learning models for predicting end-of-study self-reported depression status using on blocks of phone sensor and text features. Results: In correlation analyses, we find that degrees of depression, emotional, and personal pronoun language categories correlate most strongly with self-reported depression, validating prior literature. Our classification models which predict binary depression status achieve a leave-one-out AUC of 0.72 when only considering text features and 0.76 when combining text with other networked smartphone sensors. Limitations: Participants were recruited from a panel that over-represented women, caucasians, and individuals with self-reported depression at baseline. As language use differs across demographic factors, generalizability beyond this population may be limited. The study period also coincided with the initial COVID-19 outbreak in the United States, which may have affected smartphone sensor data quality. Conclusions: Effective depression prediction through text message sentiment, especially when combined with other personal sensors, could enable comprehensive mental health monitoring and intervention. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Liu, Tony: liutony@seas.upenn.edu},
  doi       = {10.1016/j.jad.2021.12.048},
  issn      = {1573-2517(Electronic),0165-0327(Print)},
  journal   = {Journal of Affective Disorders},
  keywords  = {*Major Depression, *Self-Report, *Text Messaging, Machine Learning},
  pages     = {7--14},
  publisher = {Elsevier Science},
  refid     = {2022-35007-003},
  volume    = {302},
}

@Misc{Chen2021,
  author    = {Chen, Yidi and Wu, Jianhui and Ma, Jinjin and Zhu, Huanya and Li, Wenju and Gan, Yiqun},
  title     = {The mediating effect of media usage on the relationship between anxiety/fear and physician-patient trust during the covid-19 pandemic.},
  year      = {2021},
  abstract  = {Abstract Objective Our study explored whether and how media usage can mediate the path from anxiety and fear to physician-patient trust. Design Study 1 was a population-based, longitudinal study using nationally representative data from 29 provinces in mainland China. The baseline sample (N = 3233) was obtained from February 1 to 9, 2020. Follow-up (N = 1380) took place during March 17 to 24, 2020. Study 2 was a machine learning-based sentiment analysis in which data were captured from Sina Weibo, a Chinese microblogging website, among the most popular official, unofficial, and health-related media accounts. The screened blogs from November to December 2019 and February to March 2020 were scored by Google APIs for positivity and magnitude. Main Outcome Measures Physician-patient trust. Results Study 1 showed fear and anxiety affected changes in physician-patient trust through media usage, the indirect effect of which was 0.14 (0.03) and the 95% CI was [0.08, 0.19]. Study 2 indicated a more positive image of physicians after the outbreak compared to before [F (2, 3537) = 3.646, p = 0.026, partial η2 =0.002]. Conclusion The negative impact of anxiety and fear on physician-patient trust was mediated by media use, which can be explained by the more positive media image during the pandemic. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  address   = {Li, Wenju:},
  doi       = {10.1080/08870446.2021.1900573},
  issn      = {1476-8321(Electronic),0887-0446(Print)},
  journal   = {Psychology & Health},
  pages     = {No Pagination Specified--No Pagination Specified},
  publisher = {Taylor & Francis},
  refid     = {2021-30979-001},
}

@Article{Datta2022,
  author    = {Datta, Samik and Chakrabarti, Satyajit},
  journal   = {Theoretical Issues in Ergonomics Science},
  title     = {Enhanced ensemble learning for aspect-based sentiment analysis on multiple application oriented datasets.},
  year      = {2022},
  issn      = {1464-536X(Electronic),1463-922X(Print)},
  pages     = {No Pagination Specified--No Pagination Specified},
  abstract  = {Abstract The main goal of this article is to develop and propose a novel ABSA method using enhanced ensemble learning (EEL) with optimal feature selection. Initially, the data from multiple applications is gathered and subjected to the preprocessing by ‘stop word removal and punctuation removal, lower case conversion and stemming’. Then, the aspect extraction is done by separating ‘noun and adjective and verb and adverb combination’. From this, the ‘Vader sentiment intensity analyzer’ is used to capture the weighted polarity feature, and then, the word2vector and ‘term frequency-inverse document frequency’ are extracted as features. The optimal feature selection using best and worst fitness-based galactic swarm optimization (BWF-GSO) is used for selecting the most significant features. With these features, ensemble learning with different classifiers like ‘recurrent neural network, support vector machine and deep belief network’ performs for handling the sentiment analysis with parameter optimization. The suggested models are helpful and generate better than the existing outcomes, according to experimental data. Through the performance analysis, the accuracy of BWF-GSO-EEL was 1.16%, 1.58%, 2.01% and 1.37% better than FF-MVO-EEL, FF-EEL, MVO-EEL and PSO-EEL, respectively. Thus, the promising performance has been observed while comparing with other algorithms. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Datta, Samik:},
  doi       = {10.1080/1463922X.2022.2099033},
  publisher = {Taylor & Francis},
  refid     = {2022-86233-001},
}

@Misc{Sun2020,
  author    = {Sun, Bing and Mao, Hongying and Yin, Chengshun},
  title     = {Male and female users’ differences in online technology community based on text mining.},
  year      = {2020},
  abstract  = {With the emergence of online communities, more and more people are participating in online technology communities to meet personalized learning needs. This study aims to investigate whether and how male and female users behave differently in online technology communities. Using text data from the Python Technology Community, through the LDA (Latent Dirichlet Allocation) model, sentiment analysis, and regression analysis, this paper reveals the different topics of male and female users in the online technology community, their sentimental tendencies and activity under different topics, and their correlation and mutual influence. The results show the following: (1) Male users tend to provide information help, while female users prefer to participate in the topic of making friends and advertising. (2) When communicating in the technology community, male and female users mostly express positive emotions, but female users express positive emotions more frequently. (3) Different emotional tendencies of male and female users under different topics have different effects on their activity in the community. The activity of female users is more susceptible to emotional orientation. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Sun, Bing: heusun@hotmail.com},
  doi       = {10.3389/fpsyg.2020.00806},
  issn      = {1664-1078(Electronic)},
  journal   = {Frontiers in Psychology},
  keywords  = {*Computer Assisted Instruction, *Human Sex Differences, *Technology, *Positive Emotions, *Online Community, Computer Software, Emotional Content, Sentiment Analysis},
  publisher = {Frontiers Media S.A.},
  refid     = {2020-41604-001},
  volume    = {11},
}

@Misc{Li2021,
  author    = {Li, Yang and Sun, Yuqing and Zhu, Nana},
  title     = {BERTtoCNN: Similarity-preserving enhanced knowledge distillation for stance detection.},
  year      = {2021},
  abstract  = {In recent years, text sentiment analysis has attracted wide attention, and promoted the rise and development of stance detection research. The purpose of stance detection is to determine the author’s stance (favor or against) towards a specific target or proposition in the text. Pre-trained language models like BERT have been proven to perform well in this task. However, in many reality scenes, they are usually very expensive in computation, because such heavy models are difficult to implement with limited resources. To improve the efficiency while ensuring the performance, we propose a knowledge distillation model BERTtoCNN, which combines the classic distillation loss and similarity-preserving loss in a joint knowledge distillation framework. On the one hand, BERTtoCNN provides an efficient distillation process to train a novel ‘student’ CNN structure from a much larger ‘teacher’ language model BERT. On the other hand, based on the similarity-preserving loss function, BERTtoCNN guides the training of a student network, so that input pairs with similar (dissimilar) activation in the teacher network have similar (dissimilar) activation in the student network. We conduct experiments and test the proposed model on the open Chinese and English stance detection datasets. The experimental results show that our model outperforms the competitive baseline methods obviously. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Li, Yang: yli@nefu.edu.cn},
  doi       = {10.1371/journal.pone.0257130},
  issn      = {1932-6203(Electronic)},
  journal   = {PLoS ONE},
  keywords  = {*Models, *Teachers, *Training, *Sentiment Analysis, Machine Learning, Artificial Neural Networks},
  publisher = {Public Library of Science},
  refid     = {2021-85779-001},
  volume    = {16},
}

@Misc{Chen2017,
  author    = {Chen, Lushi and Gong, Tao and Kosinski, Michal and Stillwell, David and Davidson, Robert L.},
  title     = {Building a profile of subjective well-being for social media users.},
  year      = {2017},
  abstract  = {Subjective well-being includes `affect' and `satisfaction with life' (SWL). This study proposes a unified approach to construct a profile of subjective well-being based on social media language in Facebook status updates. We apply sentiment analysis to generate users' affect scores, and train a random forest model to predict SWL using affect scores and other language features of the status updates. Results show that: the computer-selected features resemble the key predictors of SWL as identified in early studies; the machine-predicted SWL is moderately correlated with the self-reported SWL (r = 0.36, p r = 0.24, p < 0.01). This study provides important insights for psychological prediction using multiple, machine-assessed components and longitudinal or dense psychological assessment using social media language. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  address   = {Chen, Lushi: lushi.chen@ed.ac.uk},
  doi       = {10.1371/journal.pone.0187278},
  issn      = {1932-6203(Electronic)},
  journal   = {PLoS ONE},
  keywords  = {*Life Satisfaction, *Well Being, *Online Social Networks, Social Media},
  publisher = {Public Library of Science},
  refid     = {2018-15501-001},
  volume    = {12},
}

@Misc{Resnik2016,
  author    = {Resnik, Felice and Bellmore, Amy and Xu, Jun-Ming and Zhu, Xiaojin},
  title     = {Celebrities emerge as advocates in tweets about bullying.},
  year      = {2016},
  abstract  = {To understand the ways that social media users connect with celebrities about bullying, 1,280,151 posts that mentioned one of the top 302 celebrity users named within bullying keyword posts on Twitter between January 1, 2012 and December 31, 2012 were analyzed. Social science and computer science methods were combined to identify how individuals defined celebrities according to bullying roles and what features of celebrities and the tweets were related to the bullying roles. The results show that Twitter users defined celebrities most frequently as potential advocates against bullying. The results of a Principal Components Analysis identified an advocate/confidant role dimension and the distribution of celebrities across these dimensions were associated with celebrity type and age. A sentiment analysis revealed that the sentiments of the tweets that defined celebrities as advocates were more likely to be positive (e.g., “THANKSSSSS FOR YOUR SUPPORT”), than negative (e.g., you are MEAN). Together, the results suggest that social media is a space that holds potential for advocating against bullying versus being perceived primarily as a space where cyberbullying occurs. Knowing that social media is a context where celebrities can act as advocates, defenders, and role-models in the fight against bullying can be used to inform prevention, intervention, and advocacy programs. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  address   = {Resnik, Felice: Department of Educational Psychology, University of Wisconsin-Madison, 859 Education Sciences, 1025 West Johnson Street, Madison, WI, US, 53706, fresnik@wisc.edu},
  doi       = {10.1037/tps0000079},
  issn      = {2332-2179(Electronic),2332-2136(Print)},
  journal   = {Translational Issues in Psychological Science},
  keywords  = {*Advocacy, *Celebrities, *Bullying, *Online Social Networks, *Social Media, Cyberbullying},
  pages     = {323--334},
  publisher = {Educational Publishing Foundation},
  refid     = {2016-47442-012},
  volume    = {2},
}

@Misc{Hollis2017,
  author    = {Hollis, Geoff and Westbury, Chris and Lefsrud, Lianne},
  title     = {Extrapolating human judgments from skip-gram vector representations of word meaning.},
  year      = {2017},
  abstract  = {There is a growing body of research in psychology that attempts to extrapolate human lexical judgments from computational models of semantics. This research can be used to help develop comprehensive norm sets for experimental research, it has applications to large-scale statistical modelling of lexical access and has broad value within natural language processing and sentiment analysis. However, the value of extrapolated human judgments has recently been questioned within psychological research. Of primary concern is the fact that extrapolated judgments may not share the same pattern of statistical relationship with lexical and semantic variables as do actual human judgments; often the error component in extrapolated judgments is not psychologically inert, making such judgments problematic to use for psychological research. We present a new methodology for extrapolating human judgments that partially addresses prior concerns of validity. We use this methodology to extrapolate human judgments of valence, arousal, dominance, and concreteness for 78,286 words. We also provide resources for users to extrapolate these human judgments for three million English words and short phrases. Applications for large sets of extrapolated human judgments are demonstrated and discussed. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  address   = {Hollis, Geoff: hollis@ualberta.ca},
  doi       = {10.1080/17470218.2016.1195417},
  issn      = {1747-0226(Electronic),1747-0218(Print)},
  journal   = {The Quarterly Journal of Experimental Psychology},
  keywords  = {*Cognitive Processes, *Judgment, *Lexical Access, Semantics},
  pages     = {1603--1619},
  publisher = {Taylor & Francis},
  refid     = {2017-09302-013},
  volume    = {70},
}

@Misc{Yu2022,
  author    = {Yu, Calvin Kai-Ching},
  title     = {Automated analysis of dream sentiment--The royal road to dream dynamics?},
  year      = {2022},
  abstract  = {Valence Aware Dictionary for sEntiment Reasoning (VADER) is an automated software program for analyzing textual data based on an established lexicon and annotated lexical features. Support-vector machine (SVM) is a popular machine-learning model for solving classification problems. VADER and SVM can serve as potential alternatives to the conventional content analysis and Linguistic Inventory and Word Count analysis of dream emotions. The study presented here aimed to evaluate the overall affective valence of dreams using both the VADER and SVM methods. A total of 2,600 dreams primarily obtained from an open source--including dreams reported by American, German, Hong Kong, Peruvian, and Taiwanese people--were subjected to the 2 automated algorithms for sentiment analysis. The mean VADER and SVM sentiment scores indicate overall balanced sentiment in dream reports. Accordingly, an average dream report contains positive and negative emotions of similar intensity. Notwithstanding their different algorithms and methodological strategies, the marked consistency between the VADER and SVM scoring suggests that VADER and SVM can provide reliable, effective, yet distinct tools for dream sentiment analysis. In addition, the analysis of Chinese people’s dreams suggests that the discrepancy between dream sentiment scored by automated algorithms and subjective feelings experienced by dreamers may reveal some dynamic processes during dreaming, such as working through concerns and desensitizing feelings. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  address   = {Yu, Calvin Kai-Ching: Department of Counselling and Psychology, Hong Kong Shue Yan University, 10 Wai Tsui Crescent, Braemar Hill Road, North Point, Hong Kong, kcyu@hksyu.edu},
  doi       = {10.1037/drm0000189},
  issn      = {1573-3351(Electronic),1053-0797(Print)},
  journal   = {Dreaming},
  keywords  = {*Dream Analysis, *Dream Content, *Emotions, *Machine Learning, *Sentiment Analysis, Algorithms, Taxonomies, Negative Emotions, Positive Emotions},
  pages     = {33--51},
  publisher = {Educational Publishing Foundation},
  refid     = {2022-30918-001},
  volume    = {32},
}

@Comment{jabref-meta: databaseType:bibtex;}
