Provider: American Psychological Association
Database: PsycINFO
Content: application/x-research-info-systems

TY  - JOUR
DESCRIPTORS  - *Electrophysiology;  *Emotional States;  *Evoked Potentials; Facial Expressions
PMID  - 18835454
ID  - 2009-22047-029
T1  - Electrophysiological correlates of affective blindsight.
JF  - NeuroImage
A1  - Andino, Sara L. Gonzalez
A1  - de Peralta Menendez, Rolando Grave
A1  - Khateb, Asaid
A1  - Landis, Theodor
A1  - Pegna, Alan J.
VL  - 44
SP  - 581
EP  - 589
Y1  - 2009
CY  - Netherlands
AD  - Andino, Sara L. Gonzalez: Sara.GonzalezAndino@hcuge.ch
PB  - Elsevier Science
SN  - 1095-9572(Electronic),1053-8119(Print)
N2  - An EEG investigation was carried out in a patient with complete cortical blindness who presented affective blindsight, i.e. who performed above chance when asked to guess the emotional expressions on a series of faces. To uncover the electrophysiological mechanisms involved in this phenomenon we combined multivariate pattern recognition (MPR) with local field potential estimates provided by electric source imaging (ELECTRA). All faces, including neutral faces, elicited distinctive oscillatory EEG patterns that were correctly identified by the MPR algorithm as belonging to the class of facial expressions actually presented. Consequently, neural responses in this patient are not restricted to emotionally laden faces. Earliest non-specific differences between faces occur from 70 ms onwards in the superior temporal polysensory area (STP). Emotion-specific responses were found after 120 ms in the right anterior areas with right amygdala activation observed only later (∼200 ms). Thus, affective blindsight might be mediated by subcortical afferents to temporal areas as suggested in some studies involving non-emotional stimuli. The early activation of the STP in the patient constitutes evidence for fast activation of higher order visual areas in humans despite bilateral V1 destruction. In addition, the absence of awareness of any visual experience in this patient suggests that neither the extrastriate visual areas, nor the prefrontal cortex activation alone are sufficient for conscious perception, which might require recurrent processing within a network of several cerebral areas including V1. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Electrophysiology
KW  - *Emotional States
KW  - *Evoked Potentials
KW  - Facial Expressions
M3  - doi:10.1016/j.neuroimage.2008.09.002
DO  - 10.1016/j.neuroimage.2008.09.002
ER  -
TY  - JOUR
DESCRIPTORS  - *Facial Expressions;  *Human Channel Capacity;  *Facial Affect Recognition; Face Perception; Visual Stimulation
PMID  - 29677333
ID  - 2018-16380-001
T1  - Ensemble representation for multiple facial expressions: Evidence for a capacity limited perceptual process.
JF  - Journal of Vision
A1  - Ji, Luyan
A1  - Chen, Wenfeng
A1  - Loeys, Tom
A1  - Pourtois, Gilles
VL  - 18
Y1  - 2018
CY  - US
AD  - Ji, Luyan: Department of Experimental-Clinical and Health Psychology, Ghent University, Ghent, Belgium, Luyan.Ji@ugent.be
PB  - Assn for Research in Vision & Ophthalmology (ARVO)
SN  - 1534-7362(Electronic)
N2  - We tested the processing capacity of establishing ensemble representation for multiple facial expressions using the simultaneous–sequential paradigm. Each set consisted of 16 faces conveying a variable amount of happy and angry expressions. Participants judged on a continuous scale the perceived average emotion from each face set (Experiment 1). In the simultaneous condition, the 16 faces were presented concurrently; in the sequential condition, two sets, each containing eight faces, were presented successively. Results showed that judgments varied depending on the number of happy versus angry faces contained in the sets and were sensitive at the single trial level to the perceived mean emotion intensity (based on postexperiment ratings), providing evidence of a genuine mean representation rather than the mere use of a single face or enumeration. Experiments 2 and 3 replicated Experiment 1, but implemented a different response format (binary choices) and added masks following each display, respectively. Importantly, in all three experiments, performance was consistently better in the sequential than in the simultaneous condition, revealing a limited-capacity process. A set of control analyses ruled out the use of enumeration or mere subsampling by the participants to perform the task. Collectively, these results indicate that participants could readily extract mean emotion from multiple faces shown concurrently in a set, but this process is best conceived as being capacity limited. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Facial Expressions
KW  - *Human Channel Capacity
KW  - *Facial Affect Recognition
KW  - Face Perception
KW  - Visual Stimulation
M3  - doi:10.1167/18.3.17
DO  - 10.1167/18.3.17
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Face Perception;  *Facial Expressions;  *Schizophrenia;  *Spatial Frequency; Fear; Happiness; Vision
PMID  - 20435444
ID  - 2010-18858-017
T1  - Differential roles of low and high spatial frequency content in abnormal facial emotion perception in schizophrenia.
JF  - Schizophrenia Research
A1  - McBain, Ryan
A1  - Norton, Daniel
A1  - Chen, Yue
VL  - 122
SP  - 151
EP  - 155
Y1  - 2010
CY  - Netherlands
AD  - Chen, Yue: McLean Hospital, 115 Mill Street, Belmont, MA, US, 02478, ychen@mclean.harvard.edu
PB  - Elsevier Science
SN  - 1573-2509(Electronic),0920-9964(Print)
N2  - While schizophrenia patients are impaired at facial emotion perception, the role of basic visual processing in this deficit remains relatively unclear. We examined emotion perception when spatial frequency content of facial images was manipulated via high-pass and low-pass filtering. Unlike controls (n = 29), patients (n = 30) perceived images with low spatial frequencies as more fearful than those without this information, across emotional salience levels. Patients also perceived images with high spatial frequencies as happier. In controls, this effect was found only at low emotional salience. These results indicate that basic visual processing has an amplified modulatory effect on emotion perception in schizophrenia. (PsycINFO Database Record (c) 2017 APA, all rights reserved)
KW  - *Emotions
KW  - *Face Perception
KW  - *Facial Expressions
KW  - *Schizophrenia
KW  - *Spatial Frequency
KW  - Fear
KW  - Happiness
KW  - Vision
M3  - doi:10.1016/j.schres.2010.03.034
DO  - 10.1016/j.schres.2010.03.034
ER  -
TY  - JOUR
DESCRIPTORS  - *Conversion Disorder;  *Vision Disorders; Neurons; Visual Cortex; Functional Magnetic Resonance Imaging
PMID  - 23288388
ID  - 2013-14572-014
T1  - Deciphering the neural signature of conversion blindness.
JF  - The American Journal of Psychiatry
A1  - Becker, Benjamin
A1  - Scheele, Dirk
A1  - Moessner, Rainald
A1  - Maier, Wolfgang
A1  - Hurlemann, René
VL  - 170
SP  - 121
EP  - 122
Y1  - 2013
CY  - US
PB  - American Psychiatric Assn
SN  - 1535-7228(Electronic),0002-953X(Print)
N2  - Presents a case report of 25-year-old man who fulfilled DSM-IV criteria for visual conversion disorder after experiencing recurrent brief episodes of medically unexplained complete bilateral visual loss. The fMRI data analysis confirmed the presence of unaltered basic visual cortex responses to checkerboard stimulation during conversion blindness. A psychophysiological interactions analysis revealed enhanced functional coupling of the network with down regulated visual areas. The findings may help extend current neurocircuitry models of visual conversion disorder by proposing a symptom-related functional association of over activity in fronto-parietal regions and suppressed responses in interconnected visual areas. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Conversion Disorder
KW  - *Vision Disorders
KW  - Neurons
KW  - Visual Cortex
KW  - Functional Magnetic Resonance Imaging
M3  - doi:10.1176/appi.ajp.2012.12070905
DO  - 10.1176/appi.ajp.2012.12070905
ER  -
TY  - JOUR
DESCRIPTORS  - *Alzheimer's Disease;  *Dementia;  *Social Cognition;  *Mild Cognitive Impairment;  *Social Functioning; Amnesia
PMID  - 32979297
ID  - 2020-72967-001
T1  - Social cognition and social functioning in patients with amnestic mild cognitive impairment or Alzheimer’s dementia.
JF  - Journal of Neuropsychology
A1  - Kessels, Roy P. C.
A1  - Elferink, Maaike Waanders‐Oude
A1  - van Tilborg, Ilse
VL  - 15
SP  - 186
EP  - 203
Y1  - 2021
CY  - United Kingdom
AD  - Kessels, Roy P. C.: Donders Institute for Brain, Cognition and Behaviour, Department of Neuropsychology and Rehabilitation Psychology, Radboud University, PO Box 9104, Nijmegen, Netherlands, 6500 HE, r.kessels@donders.ru.nl
PB  - Wiley-Blackwell Publishing Ltd.
SN  - 1748-6653(Electronic),1748-6645(Print)
N2  - The aim of the present study was to examine social cognition and social functioning in a group of amnestic mild cognitive impairment (aMCI) and Alzheimer’s dementia (AD) patients. Thirty one people with aMCI, 29 individuals with AD, and 45 healthy older adults participated in the study. Facial expressions of happiness, anger, fear, disgust, and surprise presented in different intensities had to be labelled. Mentalizing was assessed using first‐order belief theory of mind (ToM) stories and everyday social functioning by the Inventory of Interpersonal Situations (IIS), completed by an informant. aMCI patients were impaired in recognizing the emotions anger, disgust, and fear, while AD patients were impaired in recognizing the emotions anger, disgust, and surprise. More importantly, no significant differences between aMCI and AD patients were found on overall emotion recognition. Both the aMCI and AD patients were impaired on the ToM task, but no differences between the aMCI and AD patients were found. On everyday social functioning, only the AD patients showed impairments. No associations between the IIS and ToM were found, but the IIS and emotion perception were significantly correlated. Regression analysis taking all potentially confounding variables into account showed that only mood, but not the social‐cognitive task performance or any other cognitive variable, predicted social functioning. aMCI and AD patients demonstrated impairments in mentalizing and facial emotion perception, and showed decrements in everyday social functioning. Informing caregivers about these deficits may help them to understand deficits in social cognition that may be present already in the MCI stage of Alzheimer’s disease. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Alzheimer's Disease
KW  - *Dementia
KW  - *Social Cognition
KW  - *Mild Cognitive Impairment
KW  - *Social Functioning
KW  - Amnesia
M3  - doi:10.1111/jnp.12223
DO  - 10.1111/jnp.12223
ER  -
TY  - JOUR
DESCRIPTORS  - *Anger;  *Facial Expressions;  *Major Depression;  *Vision Disorders;  *Emotion Recognition; Face Perception
PMID  - 24882200
ID  - 2014-23424-032
T1  - Intact anger recognition in depression despite aberrant visual facial information usage.
JF  - Journal of Affective Disorders
A1  - Clark, Cameron M.
A1  - Chiu, Carina G.
A1  - Diaz, Ruth L.
A1  - Goghari, Vina M.
VL  - 165
SP  - 196
EP  - 202
Y1  - 2014
CY  - Netherlands
AD  - Goghari, Vina M.: Department of Psychology, University of Calgary, 2500 University Dr. NW, Calgary, AB, Canada, T2N 1N4, vmgoghar@ucalgary.ca
PB  - Elsevier Science
SN  - 1573-2517(Electronic),0165-0327(Print)
N2  - [Correction Notice: An Erratum for this article was reported in Vol 168 of Journal of Affective Disorders (see record 2014-40023-011). In the original article, the figure caption accompanying figure 1 incorrectly labeled the color maps for row C. The corrected figure caption is present in the erratum.] Background: Previous literature has indicated abnormalities in facial emotion recognition abilities, as well as deficits in basic visual processes in major depression. However, the literature is unclear on a number of important factors including whether or not these abnormalities represent deficient or enhanced emotion recognition abilities compared to control populations, and the degree to which basic visual deficits might impact this process. Methods: The present study investigated emotion recognition abilities for angry versus neutral facial expressions in a sample of undergraduate students with Beck Depression Inventory-II (BDI-II) scores indicative of moderate depression (i.e. ≥ 20), compared to matched low-BDI-II score (i.e. ≤ 2) controls via the Bubbles Facial Emotion Perception Task. Results: Results indicated unimpaired behavioural performance in discriminating angry from neutral expressions in the high depressive symptoms group relative to the minimal depressive symptoms group, despite evidence of an abnormal pattern of visual facial information usage. Limitations: The generalizability of the current findings is limited by the highly structured nature of the facial emotion recognition task used, as well as the use of an analog sample undergraduates scoring high in self-rated symptoms of depression rather than a clinical sample. Conclusions: Our findings suggest that basic visual processes are involved in emotion recognition abnormalities in depression, demonstrating consistency with the emotion recognition literature in other psychopathologies (e.g. schizophrenia, autism, social anxiety). Future research should seek to replicate these findings in clinical populations with major depression, and assess the association between aberrant face gaze behaviours and symptom severity and social functioning. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Anger
KW  - *Facial Expressions
KW  - *Major Depression
KW  - *Vision Disorders
KW  - *Emotion Recognition
KW  - Face Perception
M3  - doi:10.1016/j.jad.2014.04.065
DO  - 10.1016/j.jad.2014.04.065
ER  -
TY  - JOUR
DESCRIPTORS  - *Deaf;  *Emotions;  *Face Perception; Facial Expressions
ID  - 2009-25148-021
T1  - Development of deaf children's emotion understanding.
JF  - Chinese Journal of Clinical Psychology
A1  - Zheng, Pei
A1  - Ma, Wei-na
VL  - 17
SP  - 584
EP  - 587
Y1  - 2009
CY  - China
AD  - Zheng, Pei: School of Education Science, Hangzhou Normal University, Hangzhou, China, 310018
PB  - Clinical Psychological Research Ctr
SN  - 1005-3611(Print)
N2  - Objective: To discuss the developmental trend of deaf children's emotion understanding at different levels. Methods: 119 11-18 year-old deaf children were tested by emotion understanding tasks. Results: 1. 11 and 18 years old deaf children's ability of expression recognition didn't have differences; 2. In affective perspective-taking task, there were significant differences between 11 and 12-18 years old (P P < 0.05). Conclusion: This study suggests that 12-year-old and 16-year-old may be the two key ages of the development of emotion perspective-taking and second-order emotion understanding. In these two tasks, the better their hearing ability is, the better their emotion understanding develops. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Deaf
KW  - *Emotions
KW  - *Face Perception
KW  - Facial Expressions
ER  -
TY  - JOUR
DESCRIPTORS  - *Anger;  *Facial Expressions;  *Major Depression;  *Vision Disorders;  *Emotion Recognition; Face Perception
ID  - 2014-40023-011
T1  - "Intact anger recognition in depression despite aberrant visual facial information usage": Corrigendum.
JF  - Journal of Affective Disorders
A1  - Clark, Cameron M.
A1  - Chiu, Carina G.
A1  - Diaz, Ruth L.
A1  - Goghari, Vina M.
VL  - 168
SP  - 64
EP  - 64
Y1  - 2014
CY  - Netherlands
AD  - Goghari, Vina M.: Department of Psychology, University of Calgary, 2500 University Dr. NW, Calgary, AB, Canada, T2N 1N4, vmgoghar@ucalgary.ca
PB  - Elsevier Science
SN  - 1573-2517(Electronic),0165-0327(Print)
N2  - Reports an error in "Intact anger recognition in depression despite aberrant visual facial information usage" by Cameron M. Clark, Carina G. Chiu, Ruth L. Diaz and Vina M. Goghari (Journal of Affective Disorders, 2014[Aug][20], Vol 165, 196-202). In the original article, the figure caption accompanying figure 1 incorrectly labeled the color maps for row C. The corrected figure caption is present in the erratum. (The following abstract of the original article appeared in record 2014-23424-032). Background: Previous literature has indicated abnormalities in facial emotion recognition abilities, as well as deficits in basic visual processes in major depression. However, the literature is unclear on a number of important factors including whether or not these abnormalities represent deficient or enhanced emotion recognition abilities compared to control populations, and the degree to which basic visual deficits might impact this process. Methods: The present study investigated emotion recognition abilities for angry versus neutral facial expressions in a sample of undergraduate students with Beck Depression Inventory-II (BDI-II) scores indicative of moderate depression (i.e. ≥ 20), compared to matched low-BDI-II score (i.e. ≤ 2) controls via the Bubbles Facial Emotion Perception Task. Results: Results indicated unimpaired behavioural performance in discriminating angry from neutral expressions in the high depressive symptoms group relative to the minimal depressive symptoms group, despite evidence of an abnormal pattern of visual facial information usage. Limitations: The generalizability of the current findings is limited by the highly structured nature of the facial emotion recognition task used, as well as the use of an analog sample undergraduates scoring high in self-rated symptoms of depression rather than a clinical sample. Conclusions: Our findings suggest that basic visual processes are involved in emotion recognition abnormalities in depression, demonstrating consistency with the emotion recognition literature in other psychopathologies (e.g. schizophrenia, autism, social anxiety). Future research should seek to replicate these findings in clinical populations with major depression, and assess the association between aberrant face gaze behaviours and symptom severity and social functioning. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Anger
KW  - *Facial Expressions
KW  - *Major Depression
KW  - *Vision Disorders
KW  - *Emotion Recognition
KW  - Face Perception
M3  - doi:10.1016/j.jad.2014.07.005
DO  - 10.1016/j.jad.2014.07.005
ER  -
TY  - JOUR
DESCRIPTORS  - *Facial Expressions;  *Life Span;  *Emotion Recognition; Emotions; Recognition (Learning)
PMID  - 30208425
ID  - 2018-55321-001
T1  - Tracking the recognition of static and dynamic facial expressions of emotion across the life span.
JF  - Journal of Vision
A1  - Richoz, Anne-Raphaëlle
A1  - Lao, Junpeng
A1  - Pascalis, Olivier
A1  - Caldara, Roberto
VL  - 18
Y1  - 2018
CY  - US
AD  - Richoz, Anne-Raphaëlle: Department of Psychology, University of Fribourg, Fribourg, Switzerland, Fribourg, Switzerland, anne-raphaelle.richoz@unifr.ch
PB  - Assn for Research in Vision & Ophthalmology (ARVO)
SN  - 1534-7362(Electronic)
N2  - The effective transmission and decoding of dynamic facial expressions of emotion is omnipresent and critical for adapted social interactions in everyday life. Thus, common intuition would suggest an advantage for dynamic facial expression recognition (FER) over the static snapshots routinely used in most experiments. However, although many studies reported an advantage in the recognition of dynamic over static expressions in clinical populations, results obtained from healthy participants are contrasted. To clarify this issue, we conducted a large cross-sectional study to investigate FER across the life span in order to determine if age is a critical factor to account for such discrepancies. More than 400 observers (age range 5–96) performed recognition tasks of the six basic expressions in static, dynamic, and shuffled (temporally randomized frames) conditions, normalized for the amount of energy sampled over time. We applied a Bayesian hierarchical step-linear model to capture the nonlinear relationship between age and FER for the different viewing conditions. Although replicating the typical accuracy profiles of FER, we determined the age at which peak efficiency was reached for each expression and found greater accuracy for most dynamic expressions across the life span. This advantage in the elderly population was driven by a significant decrease in performance for static images, which was twice as large as for the young adults. Our data posit the use of dynamic stimuli as being critical in the assessment of FER in the elderly population, inviting caution when drawing conclusions from the sole use of static face images to this aim. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Facial Expressions
KW  - *Life Span
KW  - *Emotion Recognition
KW  - Emotions
KW  - Recognition (Learning)
M3  - doi:10.1167/18.9.5
DO  - 10.1167/18.9.5
ER  -
TY  - JOUR
DESCRIPTORS  - *Face Perception;  *Facial Expressions;  *Schizophrenia;  *Vision Disorders;  *Emotion Recognition; Facial Features
PMID  - 28554121
ID  - 2017-34965-027
T1  - Facial decoding in schizophrenia is underpinned by basic visual processing impairments.
JF  - Psychiatry Research
A1  - Belge, Jan-Baptist
A1  - Maurage, Pierre
A1  - Mangelinckx, Camille
A1  - Leleux, Dominique
A1  - Delatte, Benoît
A1  - Constant, Eric
VL  - 255
SP  - 167
EP  - 172
Y1  - 2017
CY  - Netherlands
AD  - Constant, Eric: Universite catholique de Louvain, Cliniques Universitaires Saint Luc, Avenue Hippocrate, 10, Brussels, Belgium, B-1200, eric.constant@uclouvain.be
PB  - Elsevier Science
SN  - 1872-7123(Electronic),0165-1781(Print)
N2  - Schizophrenia is associated with a strong deficit in the decoding of emotional facial expression (EFE). Nevertheless, it is still unclear whether this deficit is specific for emotions or due to a more general impairment for any type of facial processing. This study was designed to clarify this issue. Thirty patients suffering from schizophrenia and 30 matched healthy controls performed several tasks evaluating the recognition of both changeable (i.e. eyes orientation and emotions) and stable (i.e. gender, age) facial characteristics. Accuracy and reaction times were recorded. Schizophrenic patients presented a performance deficit (accuracy and reaction times) in the perception of both changeable and stable aspects of faces, without any specific deficit for emotional decoding. Our results demonstrate a generalized face recognition deficit in schizophrenic patients, probably caused by a perceptual deficit in basic visual processing. It seems that the deficit in the decoding of emotional facial expression (EFE) is not a specific deficit of emotion processing, but is at least partly related to a generalized perceptual deficit in lower-level perceptual processing, occurring before the stage of emotion processing, and underlying more complex cognitive dysfunctions. These findings should encourage future investigations to explore the neurophysiologic background of these generalized perceptual deficits, and stimulate a clinical approach focusing on more basic visual processing. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Face Perception
KW  - *Facial Expressions
KW  - *Schizophrenia
KW  - *Vision Disorders
KW  - *Emotion Recognition
KW  - Facial Features
M3  - doi:10.1016/j.psychres.2017.04.007
DO  - 10.1016/j.psychres.2017.04.007
ER  -
TY  - JOUR
DESCRIPTORS  - *Blind;  *Fear;  *Emotion Recognition;  *Emotional Processing; Symptoms
PMID  - 29692751
ID  - 2018-17353-001
T1  - Explicit and implicit components of the emotional processing in non-organic vision loss: Behavioral evidence about the role of fear in functional blindness.
JF  - Frontiers in Psychology
A1  - Scarpina, Federica
A1  - Melzi, Lisa
A1  - Castelnuovo, Gianluca
A1  - Mauro, Alessandro
A1  - Marzoli, Stefania B.
A1  - Molinari, Enrico
VL  - 9
Y1  - 2018
CY  - Switzerland
AD  - Scarpina, Federica: federica.scarpina@gmail.com
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - Non-organic vision loss (NOVL), a functional partial or global vision loss, might be considered a manifestation of conversion disorder. The few previous studies focused on investigating the relationship between cerebral activity and subjective symptoms in NOVL; however, the emotional processing is still neglected. In the present case-controls study, we investigated the capability of two individuals diagnosed with NOVL to recognize implicitly the emotions of fear and anger; this was assessed through a facial emotion recognition task based on the redundant target effect. In addition, the level of alexithymia was measured by asking them to judge explicitly their ability to identify and describe emotions. Both individuals showed selective difficulties in recognizing the emotion of fear when their performance was contrasted with a matched control sample; they also mislabeled other emotional stimuli, judging them as fearful, when they were not. However, they did not report alexithymia when measured using a standard questionnaire. This preliminary investigation reports a mismatch between the implicit (i.e., the behavior in the experimental paradigm) and the explicit (i.e., the subjective evaluation of one’s own emotional capability) components of the emotional processing in NOVL. Moreover, fear seems to represent a critical emotion in this condition, as has been reported in other psychiatric disorders. However, possible difficulties in the emotional processing of fear would emerge only when they are inferred from an implicit behavior, instead of a subjective evaluation of one’s own emotional processing capability. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Blind
KW  - *Fear
KW  - *Emotion Recognition
KW  - *Emotional Processing
KW  - Symptoms
M3  - doi:10.3389/fpsyg.2018.00494
DO  - 10.3389/fpsyg.2018.00494
ER  -
TY  - JOUR
DESCRIPTORS  - *Cerebrovascular Accidents;  *Face Perception;  *Family;  *Recognition (Learning);  *Vision Disorders; Neurology; Neuropsychology
PMID  - 21707259
ID  - 2011-30295-004
T1  - When family looks strange and strangers look normal: A case of impaired face perception and recognition after stroke.
JF  - Neurocase
A1  - Heutink, Joost
A1  - Brouwer, Wiebo H.
A1  - Kums, Evelien
A1  - Young, Andy
A1  - Bouma, Anke
VL  - 18
SP  - 39
EP  - 49
Y1  - 2012
CY  - United Kingdom
AD  - Heutink, Joost: Department of Clinical and Developmental Neuropsychology, University of Groningen, Hanzeplein 1, Groningen, Netherlands, 9713 GZ, j.h.c.heutink@rug.nl
PB  - Taylor & Francis
SN  - 1465-3656(Electronic),1355-4794(Print)
N2  - We describe a patient (JS) with impaired recognition and distorted visual perception of faces after an ischemic stroke. Strikingly, JS reports that the faces of family members look distorted, while faces of other people look normal. After neurological and neuropsychological examination, we assessed response accuracy, response times, and skin conductance responses on a face recognition task in which photographs of close family members, celebrities and unfamiliar people were presented. JS’ performance was compared to the performance of three healthy control participants. Results indicate that three aspects of face perception appear to be impaired in JS. First, she has impaired recognition of basic emotional expressions. Second, JS has poor recognition of familiar faces in general, but recognition of close family members is disproportionally impaired compared to faces of celebrities. Third, JS perceives faces of family members as distorted. In this paper we consider whether these impairments can be interpreted in terms of previously described disorders of face perception and recent models for face perception. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Cerebrovascular Accidents
KW  - *Face Perception
KW  - *Family
KW  - *Recognition (Learning)
KW  - *Vision Disorders
KW  - Neurology
KW  - Neuropsychology
M3  - doi:10.1080/13554794.2010.547510
DO  - 10.1080/13554794.2010.547510
ER  -
TY  - CHAP
DESCRIPTORS  - *Facial Expressions;  *Pain;  *Emotion Recognition; Autism Spectrum Disorders; Machine Learning; Suffering; Intellectual Development Disorder; Coding Scheme
ID  - 2020-45055-029
T1  - Afterword: On knowing another's pain.
T2  - What the face reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS), 3rd ed.
T3  - Series in affective science.
A1  - Craig, Kenneth D.
SP  - 358
EP  - 361
Y1  - 2020
CY  - New York,  NY,  US
PB  - Oxford University Press
SN  - 9780190202941 (Hardcover); 9780190075927 (EPUB)
N2  - Like other subjective states, pain and suffering may be recognized and at least partially understood through observable expression. Pain, whether inflicted by injuries, diseases, or invasive medical procedures, typically provokes both automatic and controlled behaviors regulated by relatively independent neuroregulatory systems. Automatic reactions largely correspond to protective actions conserved during the course of evolution in biological organisms and human ancestral species and include nociceptive escape reflexes, facial expression, and some body movements. Facial Action Coding System (FACS) is valuable in providing a measure of the automatic expression of pain in adults, infants, young children, children and adults with intellectual disabilities, children with autism, people with significant neurological impairments, and older persons, including those with dementias. Facial expression is a core feature of behavior observation scales for pain in children and adults, but depictions are often vague and inaccurate, leading to low judgmental reliability and underestimation. Computer-based algorithms based on computer vision, facial action pattern recognition, and machine learning are proving adept in the automatic measurement of children's pain. FACS has provided a powerful tool for both advancing knowledge of social determinants of pain as well as clinical control. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Facial Expressions
KW  - *Pain
KW  - *Emotion Recognition
KW  - Autism Spectrum Disorders
KW  - Machine Learning
KW  - Suffering
KW  - Intellectual Development Disorder
KW  - Coding Scheme
ER  -
TY  - JOUR
DESCRIPTORS  - *Autism Spectrum Disorders;  *Computer Games;  *Emotions;  *Mobile Applications;  *Machine Learning Algorithms; Facial Expressions
PMID  - 31521254
ID  - 2019-56598-009
T1  - Labeling images with facial emotion and the potential for pediatric healthcare.
JF  - Artificial Intelligence in Medicine
A1  - Kalantarian, Haik
A1  - Jedoui, Khaled
A1  - Washington, Peter
A1  - Tariq, Qandeel
A1  - Dunlap, Kaiti
A1  - Schwartz, Jessey
A1  - Wall, Dennis P.
VL  - 98
SP  - 77
EP  - 86
Y1  - 2019
CY  - Netherlands
AD  - Wall, Dennis P.: Department of Pediatrics and Biomedical Data Science, Stanford University, Stanford, CA, US, dpwall@stanford.edu
PB  - Elsevier Science
SN  - 1873-2860(Electronic),0933-3657(Print)
N2  - Autism spectrum disorder (ASD) is a neurodevelopmental disorder characterized by repetitive behaviors, narrow interests, and deficits in social interaction and communication ability. An increasing emphasis is being placed on the development of innovative digital and mobile systems for their potential in therapeutic applications outside of clinical environments. Due to recent advances in the field of computer vision, various emotion classifiers have been developed, which have potential to play a significant role in mobile screening and therapy for developmental delays that impair emotion recognition and expression. However, these classifiers are trained on datasets of predominantly neurotypical adults and can sometimes fail to generalize to children with autism. The need to improve existing classifiers and develop new systems that overcome these limitations necessitates novel methods to crowdsource labeled emotion data from children. In this paper, we present a mobile charades-style game, Guess What?, from which we derive egocentric video with a high density of varied emotion from a 90-second game session. We then present a framework for semi-automatic labeled frame extraction from these videos using meta information from the game session coupled with classification confidence scores. Results show that 94%, 81%, 92%, and 56% of frames were automatically labeled correctly for categories disgust, neutral, surprise, and scared respectively, though performance for angry and happy did not improve significantly from the baseline. (PsycINFO Database Record (c) 2020 APA, all rights reserved)
KW  - *Autism Spectrum Disorders
KW  - *Computer Games
KW  - *Emotions
KW  - *Mobile Applications
KW  - *Machine Learning Algorithms
KW  - Facial Expressions
M3  - doi:10.1016/j.artmed.2019.06.004
DO  - 10.1016/j.artmed.2019.06.004
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Social Perception;  *Somatosensory Cortex;  *Transcranial Magnetic Stimulation; Auditory Discrimination; Facial Expressions
PMID  - 20943896
ID  - 2010-21926-020
T1  - Suppressing sensorimotor activity modulates the discrimination of auditory emotions but not speaker identity.
JF  - The Journal of Neuroscience
A1  - Banissy, Michael J.
A1  - Sauter, Disa Anna
A1  - Ward, Jamie
A1  - Warren, Jane E.
A1  - Walsh, Vincent
A1  - Scott, Sophie K.
VL  - 30
SP  - 13552
EP  - 13557
Y1  - 2010
CY  - US
AD  - Banissy, Michael J.: Institute of Cognitive Neuroscience, Department of Cognitive, Perceptual and Brain Sciences, University College London, London, United Kingdom, WC1N 3AR, m.banissy@ucl.ac.uk
PB  - Society for Neuroscience
SN  - 1529-2401(Electronic),0270-6474(Print)
N2  - Our ability to recognize the emotions of others is a crucial feature of human social cognition. Functional neuroimaging studies indicate that activity in sensorimotor cortices is evoked during the perception of emotion. In the visual domain, right somatosensory cortex activity has been shown to be critical for facial emotion recognition. However, the importance of sensorimotor representations in modalities outside of vision remains unknown. Here we use continuous theta-burst transcranial magnetic stimulation (cTBS) to investigate whether neural activity in the right postcentral gyrus (rPoG) and right lateral premotor cortex (rPM) is involved in nonverbal auditory emotion recognition. Three groups of participants completed same–different tasks on auditory stimuli, discriminating between the emotion expressed and the speakers' identities, before and following cTBS targeted at rPoG, rPM, or the vertex (control site). A task-selective deficit in auditory emotion discrimination was observed. Stimulation to rPoG and rPM resulted in a disruption of participants' abilities to discriminate emotion, but not identity, from vocal signals. These findings suggest that sensorimotor activity may be a modality-independent mechanism which aids emotion discrimination. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Emotions
KW  - *Social Perception
KW  - *Somatosensory Cortex
KW  - *Transcranial Magnetic Stimulation
KW  - Auditory Discrimination
KW  - Facial Expressions
M3  - doi:10.1523/JNEUROSCI.0786-10.2010
DO  - 10.1523/JNEUROSCI.0786-10.2010
ER  -
TY  - JOUR
DESCRIPTORS  - *Face Perception;  *Facial Expressions;  *Pandemics;  *Prosopagnosia;  *Face Masks; Happiness; COVID-19; Personal Protective Equipment
PMID  - 35728295
ID  - 2022-95463-003
T1  - New evidence of impaired expression recognition in developmental prosopagnosia.
JF  - Cortex: A Journal Devoted to the Study of the Nervous System and Behavior
A1  - Tsantani, Maria
A1  - Gray, Katie L. H.
A1  - Cook, Richard
VL  - 154
SP  - 15
EP  - 26
Y1  - 2022
CY  - France
AD  - Tsantani, Maria: Department of Psychological Sciences, Birkbeck, University of London, London, United Kingdom, WC1E 7HX, m.tsantani@bbk.ac.uk
PB  - Elsevier Masson SAS
SN  - 1973-8102(Electronic),0010-9452(Print)
N2  - Developmental prosopagnosia (DP) is a neurodevelopmental condition characterized by lifelong face recognition difficulties. To date, it remains unclear whether or not individuals with DP experience impaired recognition of facial expressions. It has been proposed that DPs may have sufficient perceptual ability to correctly interpret facial expressions when tasks are relatively easy (e.g., the stimuli are unambiguous and viewing conditions are optimal), but exhibit subtle impairments when tested under more challenging conditions. In the present study, we sought to take advantage of the COVID-19 pandemic to test this view. It is well-established that the surgical-type masks worn during the pandemic hinder the recognition and interpretation of facial emotion in typical participants. Relative to typical participants, we hypothesized that DPs may be disproportionately impaired when asked to interpret the facial emotion of people wearing face masks. We compared the ability of 34 DPs and 60 age-matched typical controls to recognize facial emotions i) when the whole face is visible, and ii) when the lower portion of the face is covered with a surgical mask. When expression stimuli were viewed without a mask, the DPs and typical controls exhibited similar levels of performance. However, when expression stimuli were shown with a mask, the DPs showed signs of subtle expression recognition deficits. The DPs were particularly prone to mislabeling masked expressions of happiness as emotion neutral. These results add to a growing body of evidence that under some conditions, DPs do exhibit subtle deficits of expression recognition. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Face Perception
KW  - *Facial Expressions
KW  - *Pandemics
KW  - *Prosopagnosia
KW  - *Face Masks
KW  - Happiness
KW  - COVID-19
KW  - Personal Protective Equipment
M3  - doi:10.1016/j.cortex.2022.05.008
DO  - 10.1016/j.cortex.2022.05.008
ER  -
TY  - JOUR
DESCRIPTORS  - *Facial Expressions;  *Schizophrenia;  *Vision;  *Emotion Recognition; Fear; Happiness; Visual Cortex
ID  - 2016-36061-006
T1  - Impaired visual cortical processing of affective facial information in schizophrenia.
JF  - Clinical Psychological Science
A1  - Maher, Stephen
A1  - Ekstrom, Tor
A1  - Chen, Yue
VL  - 4
SP  - 651
EP  - 660
Y1  - 2016
CY  - US
AD  - Chen, Yue: McLean Hospital, Harvard Medical School, MS 303, 115 Mill St., Belmont, MA, US, 02478, ychen@mclean.harvard.edu
PB  - Sage Publications
SN  - 2167-7034(Electronic),2167-7026(Print)
N2  - Facial-emotion-perception impairment in schizophrenia is currently viewed as abnormal affective processing. Facial-emotion perception also relies on visual processing. Yet visual cortical processing of facial emotion is not well understood in this disorder. We measured perceptual thresholds for detecting facial fear and happiness in patients (n = 23) and control participants (n = 23) and adjusted emotion intensity of facial stimuli (via morphing between images of neutral and emotive expressions) for each participant. We then evaluated activations of the visual cortex and amygdala during the performance of perceptually equated facial-emotion-detection tasks. Patients had significantly lower fear- and happiness-induced activations in the visual cortex and amygdala. Activations between the visual cortex and amygdala were largely correlated, but the correlations in patients occurred abnormally early in the response time course during fear perception. In schizophrenia, visual processing of facial emotion is deficient, and visual and affective processing of negative facial emotion may be prematurely associated. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Facial Expressions
KW  - *Schizophrenia
KW  - *Vision
KW  - *Emotion Recognition
KW  - Fear
KW  - Happiness
KW  - Visual Cortex
M3  - doi:10.1177/2167702615609595
DO  - 10.1177/2167702615609595
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Facial Expressions;  *Human Channel Capacity;  *Signal Detection (Perception);  *Stimulus Frequency; Cognitive Processes; Visual Perception; Visual Attention; Emotion Recognition
PMID  - 29660371
ID  - 2018-23595-006
T1  - Capacity limitations to extract the mean emotion from multiple facial expressions depend on emotion variance.
JF  - Vision Research
A1  - Ji, Luyan
A1  - Pourtois, Gilles
VL  - 145
SP  - 39
EP  - 48
Y1  - 2018
CY  - Netherlands
AD  - Ji, Luyan: Department of Experimental-Clinical and Health Psychology, Ghent University, Ghent, Belgium, 9000, Luyan.Ji@Ugent.be
PB  - Elsevier Science
SN  - 1878-5646(Electronic),0042-6989(Print)
N2  - We examined the processing capacity and the role of emotion variance in ensemble representation for multiple facial expressions shown concurrently. A standard set size manipulation was used, whereby the sets consisted of 4, 8, or 16 morphed faces each uniquely varying along a happy-angry continuum (Experiment 1) or a neutral-happy/angry continuum (Experiments 2 & 3). Across the three experiments, we reduced the amount of emotion variance in the sets to explore the boundaries of this process. Participants judged the perceived average emotion from each set on a continuous scale. We computed and compared objective and subjective difference scores, using the morph units and post-experiment ratings, respectively. Results of the subjective scores were more consistent than the objective ones across the first two experiments where the variance was relatively large, and revealed each time that increasing set size led to a poorer averaging ability, suggesting capacity limitations in establishing ensemble representations for multiple facial expressions. However, when the emotion variance in the sets was reduced in Experiment 3, both subjective and objective scores remained unaffected by set size, suggesting that the emotion averaging process was unlimited in these conditions. Collectively, these results suggest that extracting mean emotion from a set composed of multiple faces depends on both structural (attentional) and stimulus-related effects. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Emotions
KW  - *Facial Expressions
KW  - *Human Channel Capacity
KW  - *Signal Detection (Perception)
KW  - *Stimulus Frequency
KW  - Cognitive Processes
KW  - Visual Perception
KW  - Visual Attention
KW  - Emotion Recognition
M3  - doi:10.1016/j.visres.2018.03.007
DO  - 10.1016/j.visres.2018.03.007
ER  -
TY  - JOUR
DESCRIPTORS  - *Blind;  *Consciousness States;  *Visual Field;  *Blindsight; Face Perception
PMID  - 26483655
ID  - 2016-25826-001
T1  - Facial blindsight.
JF  - Frontiers in Human Neuroscience
A1  - Solcà, Marco
A1  - Guggisberg, Adrian G.
A1  - Schnider, Armin
A1  - Leemann, Béatrice
VL  - 9
Y1  - 2015
CY  - Switzerland
AD  - Solcà, Marco: Laboratory of Cognitive Neuroscience, Ecole Polytechnique Federale de Lausanne, Campus Biotech H4, Chemin des Mines 9, Geneve, Switzerland, 1202, marco.solca@epfl.ch
PB  - Frontiers Media S.A.
SN  - 1662-5161(Electronic)
N2  - Blindsight denotes unconscious residual visual capacities in the context of an inability to consciously recollect or identify visual information. It has been described for color and shape discrimination, movement or facial emotion recognition. The present study investigates a patient suffering from cortical blindness whilst maintaining select residual abilities in face detection. Our patient presented the capacity to distinguish between jumbled/normal faces, known/unknown faces or famous people’s categories although he failed to explicitly recognize or describe them. Conversely, performance was at chance level when asked to categorize non-facial stimuli. Our results provide clinical evidence for the notion that some aspects of facial processing can occur without perceptual awareness, possibly using direct tracts from the thalamus to associative visual cortex, bypassing the primary visual cortex. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Blind
KW  - *Consciousness States
KW  - *Visual Field
KW  - *Blindsight
KW  - Face Perception
M3  - doi:10.3389/fnhum.2015.00522
DO  - 10.3389/fnhum.2015.00522
ER  -
TY  - JOUR
DESCRIPTORS  - *Biological Markers;  *Bipolar Disorder;  *Neuroimaging;  *Biological Neural Networks; Onset (Disorders)
ID  - 2012-12115-001
T1  - Neuroimaging can help identify biomarkers of early onset bipolar disorder.
JF  - Klinik Psikofarmakoloji Bülteni / Bulletin of Clinical Psychopharmacology
A1  - Diler, Rasim Somer
VL  - 22
SP  - 1
EP  - 4
Y1  - 2012
CY  - Turkey
AD  - Diler, Rasim Somer: University of Pittsburgh, Western Psychiatric Institute and Clinic, BFT 539, 3811 O'Hara Street, Pittsburgh, PA, US, 15213
PB  - Kure Iletisim Grubu
SN  - 1302-9657(Electronic),1017-7833(Print)
N2  - This editorial discusses articles focused on the role of neuroimaging in identifying biomarkers of early onset bipolar disorder (BP). Findings from functional neuroimaging studies in BP adults and youth support the structural findings indicating abnormalities in subcortical and cortical neural systems involved in emotion processing, cognitive control, and emotion regulation. Studies in BP youth have reported significant deficits in response flexibility and facial expression recognition, abnormally elevated perception of threat from neutral faces, abnormally increased attention to threat faces, and misperception of faces as being angry. Accumulating studies in early onset BP are in accord with the vision of the National Institute of Medicine to identify biomarkers of psychiatric illnesses and treatment response. Apart of this, there are still have a lot to learn and are in need of longitudinal studies that will employ converging imaging techniques when studying BP and differential diagnosis, treatment response, and high-risk populations. (PsycINFO Database Record (c) 2018 APA, all rights reserved)
KW  - *Biological Markers
KW  - *Bipolar Disorder
KW  - *Neuroimaging
KW  - *Biological Neural Networks
KW  - Onset (Disorders)
M3  - doi:10.5455/bcp.20120214113908
DO  - 10.5455/bcp.20120214113908
ER  -
TY  - JOUR
DESCRIPTORS  - *Creativity;  *Habituation;  *Mind;  *Neural Plasticity;  *Neurology; Insight; Mental Disorders
ID  - 2012-20764-019
T1  - Review of  The age of insight: The quest to understand the unconscious in art, mind, and brain, from Vienna 1900 to the present.
JF  - The American Journal of Psychiatry
A1  - Ablon, J. Stuart
A1  - Levy, Raymond A.
VL  - 169
SP  - 764
EP  - 765
Y1  - 2012
CY  - US
PB  - American Psychiatric Assn
SN  - 1535-7228(Electronic),0002-953X(Print)
N2  - Reviews the book, The Age of Insight: The Quest to Understand the Unconscious in Art, Mind, and Brain, from Vienna 1900 to the Present by Eric R. Kandel (see record 2012-19558-000). Although as clinicians and psychiatrists we most often focus on how and when the mind “goes awry"—thereby leading to the expression of mental illness—the seminal work of Dr. Eric Kandel reminds us that understanding how the mind works in all its richness of memory, perception, emotion, and creativity remains as great a challenge to neuroscience and to society/humanity at large. This resonates as a central theme of Dr. Kandel’s latest book. The book skillfully intertwines gems from this golden era of artistic talent in Vienna early in the last century alongside fundamental contributions to the workings of the brain. At first glance, the work of Dr. Kandel as an expatriated fellow Viennese may seem disparate from this golden age. Yet Dr. Kandel has focused on the neuroscience of memory, habituation, and neural plasticity in explaining key human experiences. His seminal work of memory has been based on elegant experiments on the most simple of animals—the sea snail Aplysia. The early chapters in the book tell the stories of each artist, depicting key events and experiences that shaped their work. The book then details, in terse fashion, the brain processes that underlie perception as well as the psychology of vision. Classical works are skillfully juxtaposed with recent seminal publications, including most recent magnetic resonance imaging studies of the neurology and recognition of facial expressions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Creativity
KW  - *Habituation
KW  - *Mind
KW  - *Neural Plasticity
KW  - *Neurology
KW  - Insight
KW  - Mental Disorders
M3  - doi:10.1176/appi.ajp.2012.12020282
DO  - 10.1176/appi.ajp.2012.12020282
ER  -
TY  - JOUR
DESCRIPTORS  - *Eye Fixation; Social Anxiety
PMID  - 23769393
ID  - 2013-40433-009
T1  - Cone of direct gaze as a marker of social anxiety in males.
JF  - Psychiatry Research
A1  - Jun, Yae Young
A1  - Mareschal, Isabelle
A1  - Clifford, Colin W. G.
A1  - Dadds, Mark R.
VL  - 210
SP  - 193
EP  - 198
Y1  - 2013
CY  - Netherlands
AD  - Dadds, Mark R.: School of Psychology, University of New South Wales, Sydney, NSW, Australia, 2052, m.dadds@unsw.edu.au
PB  - Elsevier Science
SN  - 1872-7123(Electronic),0165-1781(Print)
N2  - The fear of being scrutinised is a core feature of social anxiety disorder and socially anxious individuals overestimate being ‘looked at’. A recent development in the vision sciences is a reliable psychophysical index of the range of eye gaze angles judged as being directed at oneself (Cone of Direct Gaze: CoDG). We tested the CoDG as a measure of “being looked at” in social anxiety. Participants were stratified into high/low social anxiety groups and asked to judge whether they were being ‘looked at’ by computerised male faces varying in eye gaze deviation and facial emotion. High socially anxious males had a wider CoDG than low socially anxious males; high and low socially anxious females did not differ. Fearful faces elicited narrower cones than neutral or angry faces; however, the effect size was small and not evident for the high socially anxious males. Measures of subjective reactions to the study, and to being looked at in general, indicated that the results may be in part due to males suffering more discomfort when being looked at. The results show that measures derived from psychophysics, in this case, the CoDG, have potential as clinical and research tools for measuring anxiety about being scrutinised. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Eye Fixation
KW  - Social Anxiety
M3  - doi:10.1016/j.psychres.2013.05.020
DO  - 10.1016/j.psychres.2013.05.020
ER  -
TY  - JOUR
DESCRIPTORS  - *Aging;  *Emotional States;  *Vision; Eye Fixation; Eye Movements; Facial Expressions; Nervous System
PMID  - 16351349
ID  - 2005-15573-003
T1  - Patterns of Visual Scanning as Predictors of Emotion Identification in Normal Aging.
JF  - Neuropsychology
A1  - Wong, Bonnie
A1  - Cronin-Golomb, Alice
A1  - Neargarder, Sandy
VL  - 19
SP  - 739
EP  - 749
Y1  - 2005
CY  - US
AD  - Cronin-Golomb, Alice: Department of Psychology, Boston University, 648 Beacon Street, 2nd Floor, Boston, MA, US, 02215, alicecg@bu.edu
PB  - American Psychological Association
SN  - 1931-1559(Electronic),0894-4105(Print)
N2  - Emotion identification appears to decline with age, and deficient visual scanning may contribute to this effect. Eye movements of 20 older adults (OAs) and 20 younger adults (YAs) with normal saccades were recorded while viewing facial expressions. OAs made fewer fixations overall, and they made a higher proportion of fixations to the lower halves of faces. Topographical distribution of fixations predicted better OA accuracy for identifying disgust than other negative emotions. Impaired OA accuracy for fear and anger was specific to vision, with normal identification of these emotions in the auditory domain. Age-related frontal-lobe atrophy may affect the integrity of the frontal eye fields, with consequent scanning abnormalities that contribute to difficulties in identifying certain emotions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Aging
KW  - *Emotional States
KW  - *Vision
KW  - Eye Fixation
KW  - Eye Movements
KW  - Facial Expressions
KW  - Nervous System
M3  - doi:10.1037/0894-4105.19.6.739
DO  - 10.1037/0894-4105.19.6.739
ER  -
TY  - JOUR
DESCRIPTORS  - *Deaf;  *Emotions;  *Face Perception;  *Facial Expressions; Social Skills
PMID  - 20349386
ID  - 2010-23529-002
T1  - Emotion recognition in children with profound and severe deafness: Do they have a deficit in perceptual processing?
JF  - Journal of Clinical and Experimental Neuropsychology
A1  - Ludlow, Amanda
A1  - Heaton, Pam
A1  - Rosset, Delphine
A1  - Hills, Peter
A1  - Deruelle, Christine
VL  - 32
SP  - 923
EP  - 928
Y1  - 2010
CY  - United Kingdom
AD  - Ludlow, Amanda: Anglia Ruskin University, East Road, Cambridge, United Kingdom, CB11PT, amanda.ludlow@anglia.ac.uk
PB  - Taylor & Francis
SN  - 1744-411X(Electronic),1380-3395(Print)
N2  - Findings from several studies have suggested that deaf children have difficulties with emotion identification and that these may impact upon social skills. The authors of these studies have typically attributed such problems to delayed language acquisition and/or opportunity to converse about personal experiences with other people (Peterson & Siegal, 1995, 1998). The current study aimed to investigate emotion identification in children with varying levels of deafness by specifically testing their ability to recognize perceptual aspects of emotions depicted in upright or inverted human and cartoon faces. The findings from the study showed that, in comparison with both chronological- and mental-age-matched controls, the deaf children were significantly worse at identifying emotions. However, like controls, their performance decreased when emotions were presented on the inverted faces, thus indexing a typical configural processing style. No differences were found across individuals with different levels of deafness or in those with and without signing family members. The results are supportive of poor emotional identification in hearing-impaired children and are discussed in relation to delays in language acquisition and intergroup differences in perceptual processing. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Deaf
KW  - *Emotions
KW  - *Face Perception
KW  - *Facial Expressions
KW  - Social Skills
M3  - doi:10.1080/13803391003596447
DO  - 10.1080/13803391003596447
ER  -
TY  - JOUR
DESCRIPTORS  - *Facial Expressions;  *Parkinson's Disease;  *Visual Contrast; Emotion Recognition
PMID  - 24484973
ID  - 2014-03664-001
T1  - Primary vision and facial emotion recognition in early Parkinson's disease.
JF  - Journal of the Neurological Sciences
A1  - Hipp, Géraldine
A1  - Diederich, Nico J.
A1  - Pieria, Vannina
A1  - Vaillant, Michel
VL  - 338
SP  - 178
EP  - 182
Y1  - 2014
CY  - Netherlands
AD  - Diederich, Nico J.: Centre Hospitalier de Luxembourg, Department of Neurology, 4, rue Barble, Luxembourg-City, Luxembourg, L-1210, diederich.nico@chl.lu
PB  - Elsevier Science
SN  - 1878-5883(Electronic),0022-510X(Print)
N2  - Background: In early stages of idiopathic Parkinson's disease (IPD), lower order vision (LOV) deficits including reduced colour and contrast discrimination have been consistently reported. Data are less conclusive concerning higher order vision (HOV) deficits, especially for facial emotion recognition (FER). However, a link between both visual levels has been hypothesized. Objective: To screen for both levels of visual impairment in early IPD. Methods: We prospectively recruited 28 IPD patients with disease duration of 1.4+/−0.8 years and 25 healthy controls. LOV was evaluated by Farnsworth-Munsell 100 Hue Test, Vis-Tech and Pelli-Robson test. HOV was examined by the Ekman 60 Faces Test and part A of the Visual Object and Space recognition test. Results: IPD patients performed worse than controls on almost all LOV tests. The most prominent difference was seen for contrast perception at the lowest spatial frequency (p = 0.0002). Concerning FER IPD patients showed reduced recognition of “sadness” (p = 0.01). “Fear” perception was correlated with perception of low contrast sensitivity in IPD patients within the lowest performance quartile. Controls showed a much stronger link between “fear” perception” and low contrast detection. Conclusion: At the early IPD stage there are marked deficits of LOV performances, while HOV performances are still intact, with the exception of reduced recognition of “sadness”. At this stage, IPD patients seem still to compensate the deficient input of low contrast sensitivity, known to be pivotal for appreciation of negative facial emotions and confirmed as such for healthy controls in this study. (PsycINFO Database Record (c) 2018 APA, all rights reserved)
KW  - *Facial Expressions
KW  - *Parkinson's Disease
KW  - *Visual Contrast
KW  - Emotion Recognition
M3  - doi:10.1016/j.jns.2013.12.047
DO  - 10.1016/j.jns.2013.12.047
ER  -
TY  - JOUR
DESCRIPTORS  - *Motivation;  *Prefrontal Cortex;  *Affective Valence;  *Biological Neural Networks; Emotion Recognition
ID  - 2013-23485-001
T1  - Beta coherence within human ventromedial prefrontal cortex precedes affective value choices.
JF  - NeuroImage
A1  - Lipsman, Nir
A1  - Kaping, Daniel
A1  - Westendorff, Stephanie
A1  - Sankar, Tejas
A1  - Lozano, Andres M.
A1  - Womelsdorf, Thilo
VL  - 85
SP  - 769
EP  - 778
Y1  - 2014
CY  - Netherlands
AD  - Womelsdorf, Thilo: Department of Biology, Centre for Vision Research, York University, 4700 Keele Street, Toronto, ON, Canada, M3J 1P3, thiwom@yorku.ca
PB  - Elsevier Science
SN  - 1095-9572(Electronic),1053-8119(Print)
N2  - Ventromedial prefrontal cortex (vmPFC) forms a core region of larger brain circuits that assign value to sensory inputs and interfaces motivational and cognitive dominated brain processes. This network function of the vmPFC could be realized by synchronizing local activity at time scales that are shared by connected brain areas, but it is unknown whether vmPFC circuitry engages in functionally specific synchronization. Here, we recorded in human subcallosal vmPFC while subjects engaged in an emotion tracking task that required the assignment of positive or negative affective value to ambiguous (happy–sad) facial expressions. We found that vmPFC engages in low beta-band (15–20 Hz) coherent activation just before subjects subjectively judged ambiguous facial expressions as conveying negative valence (‘sad’) information, but not before positive valence (‘happy’) judgments. The predictive beta coherence emerged particularly for conflicting rather than pure emotional facial cues and dissipated slowly after the choice was made. These results suggest that 15–20 Hz coherent activity within vmPFC marks a functional signature of a valuation process that informs categorical affective choices. We hypothesize that coherent beta band activation signifies functional interactions to anatomical vmPFC projection targets, raising the possibility that dysfunctional biases in affective valuation and an enhanced decision conflict in clinical depression could be indexed by alterations of beta coherent network activation. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Motivation
KW  - *Prefrontal Cortex
KW  - *Affective Valence
KW  - *Biological Neural Networks
KW  - Emotion Recognition
M3  - doi:10.1016/j.neuroimage.2013.05.104
DO  - 10.1016/j.neuroimage.2013.05.104
ER  -
TY  - JOUR
DESCRIPTORS  - *Autism Spectrum Disorders;  *Face Perception;  *Recognition (Learning);  *Vision Disorders; Emotional States; Facial Expressions
ID  - 2001-06107-010
T1  - Disordered recognition of facial identity and emotions in three Asperger type autists.
JF  - European Child & Adolescent Psychiatry
A1  - Nijokiktjien, C.
A1  - Verschoor, A.
A1  - Sonneville, L. de
A1  - Huyser, C.
A1  - Veld, V. Op het
A1  - Toorenaar, N.
VL  - 10
SP  - 79
EP  - 90
Y1  - 2001
CY  - Germany
PB  - Springer
SN  - 1435-165X(Electronic),1018-8827(Print)
N2  - Explored severe deficits in facial affect recognition in 3 boys all of whom meet the criteria of Asperger's syndrome (AS), as well as overt prosopagnosia in 1 (B, aged 10 yrs 6 mo) and covert prosopagnosia in the remaining 2 (C, aged 6 yrs 7 mo and D, aged 8 yrs 3 mo). Subject B, with a familially-based talent of being highly gifted in physics and mathematics, showed no interest in people, a quasi complete lack of comprehension of emotions, and very poor emotional reactivity. The marked neuropsychological deficits were a moderate prosopagnosia and severely disordered recognition of facial emotions, gender and age. In all 3 boys these facial processing deficits were more or less isolated, and general visuospatial functions, attention, formal language and scholastic performances were normal or even highly developed with the exception of deficient gestalt perception in B. The authors consider the deficient facial emotion perception as an important pathogenetic symptom for the autistic behaviour in the 3 boys. Prosopagnosia, the absent facial and bodily expression, and speech prosody were important but varying co-morbid disorders. The total clinical picture of nonverbal disordered communication is a complex of predominantly bilateral and/or right hemisphere cortical deficits. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Autism Spectrum Disorders
KW  - *Face Perception
KW  - *Recognition (Learning)
KW  - *Vision Disorders
KW  - Emotional States
KW  - Facial Expressions
M3  - doi:10.1007/s007870170050
DO  - 10.1007/s007870170050
ER  -
TY  - JOUR
DESCRIPTORS  - *Auditory Perception;  *Epilepsy;  *Speech Perception; Left Hemisphere; Oral Communication; Temporal Lobe; Visual Memory
ID  - 2020-90563-001
T1  - Using McGurk effect to detect speech-perceptional abnormalities in refractory epilepsy.
JF  - Epilepsy & Behavior
A1  - Keni, Ravish R.
A1  - Radhakrishnan, Ashalatha
VL  - 114
Y1  - 2021
CY  - Netherlands
AD  - Radhakrishnan, Ashalatha: R. Madhavan Nayar Center for Comprehensive Epilepsy Care, Sree Chitra Tirunal Institute for Medical Sciences and Technology, Kerala, India, 695011, drashalatha@sctimst.ac.in
PB  - Elsevier Science
SN  - 1525-5069(Electronic),1525-5050(Print)
N2  - Background: McGurk effect is a perceptual phenomenon that demonstrates an interaction between hearing and vision in speech perception. A wide range of neuropsychological deficits have been described in people with long-standing epilepsy, which affect multimodal integration in speech perception and hence refractory epilepsy patients are ideal for testing the McGurk effect. Materials and methods: We studied the McGurk effect in 50 patients diagnosed with medically refractory left or right hemispheric epilepsy based on clinical, radiological, and electrophysiological data. Results: The McGurk effect was better perceived (p = 0.006) in patients with left hemispheric epilepsy (n = 12, 71%) compared to right (n = 5, 29%). The other factors which compromised the perception of the McGurk effect were impairments in visual memory (p = 0.041), facial emotion recognition (p = 0.001), and lip-reading (p = 0.006). Perception of the McGurk effect reduced significantly (p = 0.006) when the epilepsy duration was 10 years or beyond. Conclusion: The McGurk effect can be used in refractory epilepsy patients, to detect subtle abnormalities in speech perception, before significant irreversible speech and language dysfunction become evident. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Auditory Perception
KW  - *Epilepsy
KW  - *Speech Perception
KW  - Left Hemisphere
KW  - Oral Communication
KW  - Temporal Lobe
KW  - Visual Memory
M3  - doi:10.1016/j.yebeh.2020.107600
DO  - 10.1016/j.yebeh.2020.107600
ER  -
TY  - JOUR
DESCRIPTORS  - *Cerebral Dominance;  *Emotions;  *Facial Expressions;  *Tachistoscopic Presentation;  *Visual Field; Recognition (Learning)
PMID  - 435972
ID  - 1980-22545-001
T1  - Hemispheric differences in processing emotions and faces.
JF  - Brain and Language
A1  - Ley, Robert G.
A1  - Bryden, M. P.
VL  - 7
SP  - 127
EP  - 138
Y1  - 1979
CY  - Netherlands
PB  - Elsevier Science
SN  - 1090-2155(Electronic),0093-934X(Print)
N2  - Investigated visual field differences for the recognition of emotional expression, using a tachistoscopic procedure. Cartoon line drawings of 5 adult male characters, each with 5 emotional expressions ranging from extremely positive to extremely negative, were used as stimuli. Single stimuli were presented unilaterally for 85 msec. 20 right-handed undergraduates with normal vision were asked to compare this target face to a subsequent centrally presented face and to decide whether the emotional expressions of the 2 faces, or the character represented by the 2 faces, were the same or different. Significant left visual field (LVF) superiorities for both character and emotional expression recognition were found. LVF superiority for emotional judgments was related to the degree of affective expression, but that for character recognition was not. Results are consistent with experimental and clinical literature that has indicated a right hemispheric superiority for face recognition and for processing emotional stimuli. The asymmetry for emotion recognition is interpreted as being an expression of the right hemisphere's synthetic and integrative characteristics, its holistic nature, and its use of imagic associations. (25 ref) (PsycINFO Database Record (c) 2017 APA, all rights reserved)
KW  - *Cerebral Dominance
KW  - *Emotions
KW  - *Facial Expressions
KW  - *Tachistoscopic Presentation
KW  - *Visual Field
KW  - Recognition (Learning)
M3  - doi:10.1016/0093-934X(79)90010-5
DO  - 10.1016/0093-934X(79)90010-5
ER  -
TY  - JOUR
DESCRIPTORS  - *Alzheimer's Disease;  *Brain;  *Cognitive Impairment;  *Dementia;  *Face Perception; Facial Expressions; Vision Disorders; Mild Cognitive Impairment
PMID  - 18403572
ID  - 2008-06743-007
T1  - Facial emotion recognition deficit in amnestic mild cognitive impairment and Alzheimer disease.
JF  - The American Journal of Geriatric Psychiatry
A1  - Spoletini, Ilaria
A1  - Marra, Camilla
A1  - Di Iulio, Fulvia
A1  - Gianni, Walter
A1  - Sancesario, Giuseppe
A1  - Giubilei, Franco
A1  - Trequattrini, Alberto
A1  - Bria, Pietro
A1  - Caltagirone, Carlo
A1  - Spalletta, Gianfranco
VL  - 16
SP  - 389
EP  - 398
Y1  - 2008
CY  - US
AD  - Spalletta, Gianfranco: IRCCS Santa Lucia Foundation, Laboratory of Clinical and Behavioural Neurology, Via Ardeatina, 306, Rome, Italy, 00179, g.spalletta@hsantalucia.it
PB  - Lippincott Williams & Wilkins
SN  - 1545-7214(Electronic),1064-7481(Print)
N2  - Objectives: A deficit in facial emotion recognition was described in patients with Alzheimer disease (AD). However, this issue has been underexplored in subjects with amnestic mild cognitive impairment (a-MCI). Thus, the authors aimed to determine whether a deficit in facial emotion recognition is present in a-MCI phase and whether this is intensity dependent. A secondary aim was to investigate relationships between facial emotion recognition and cognitive performances. Design: Case-control study. Setting: Memory clinic. Participants: Fifty a-MCI patients, 50 mild AD patients, and 50 comparison subjects (COM) were enrolled. Measurements: Information about facial emotion recognition was obtained from Penn Emotion Recognition Test. The Mental Deterioration Battery was used to measure cognitive impairment. Results: Mild AD patients were more impaired in the recognition of almost all emotional stimuli of all intensities than a-MCI and COM subjects. However, there was an increased progression only in low-intensity facial emotion recognition deficit from COM to a-MCI to mild AD patients. In particular, a-MCI subjects differed significantly from COM in low-intensity fearful face recognition performance. This deficit in a-MCI patients was explained by the short-term verbal memory impairment, whereas the same deficit in mild AD patients was explained by the long-term verbal memory impairment. Conclusions: Emotion recognition progresses from a deficit in low-intensity fearful facial recognition in a-MCI phase to a deficit in all intensities and emotions in mild AD. This could be an effect of the progressive degeneration of brain structures modulating emotional processing. An early detection of emotional impairment in MCI phases of dementia may have clinical implications. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Alzheimer's Disease
KW  - *Brain
KW  - *Cognitive Impairment
KW  - *Dementia
KW  - *Face Perception
KW  - Facial Expressions
KW  - Vision Disorders
KW  - Mild Cognitive Impairment
M3  - doi:10.1097/JGP.0b013e318165dbce
DO  - 10.1097/JGP.0b013e318165dbce
ER  -
TY  - JOUR
DESCRIPTORS  - *Face Perception;  *Facial Expressions;  *Kinesthetic Perception; Recognition (Learning)
PMID  - 29710303
ID  - 2018-18200-001
T1  - Perceptual integration of kinematic components in the recognition of emotional facial expressions.
JF  - Journal of Vision
A1  - Chiovetto, Enrico
A1  - Curio, Cristóbal
A1  - Endres, Dominik
A1  - Giese, Martin
VL  - 18
Y1  - 2018
CY  - US
AD  - Chiovetto, Enrico: Section Computational Sensomotorics, Department Cognitive Neurology, University Clinic Tubigen, Tubigen, Germany, enrico.chiovetto@uni-tuebingen.de
PB  - Assn for Research in Vision & Ophthalmology (ARVO)
SN  - 1534-7362(Electronic)
N2  - According to a long-standing hypothesis in motor control, complex body motion is organized in terms of movement primitives, reducing massively the dimensionality of the underlying control problems. For body movements, this low-dimensional organization has been convincingly demonstrated by the learning of low-dimensional representations from kinematic and EMG data. In contrast, the effective dimensionality of dynamic facial expressions is unknown, and dominant analysis approaches have been based on heuristically defined facial ‘‘action units,’’ which reflect contributions of individual face muscles. We determined the effective dimensionality of dynamic facial expressions by learning of a low-dimensional model from 11 facial expressions. We found an amazingly low dimensionality with only two movement primitives being sufficient to simulate these dynamic expressions with high accuracy. This low dimensionality is confirmed statistically, by Bayesian model comparison of models with different numbers of primitives, and by a psychophysical experiment that demonstrates that expressions, simulated with only two primitives, are indistinguishable from natural ones. In addition, we find statistically optimal integration of the emotion information specified by these primitives in visual perception. Taken together, our results indicate that facial expressions might be controlled by a very small number of independent control units, permitting very low-dimensional parametrization of the associated facial expression. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Face Perception
KW  - *Facial Expressions
KW  - *Kinesthetic Perception
KW  - Recognition (Learning)
M3  - doi:10.1167/18.4.13
DO  - 10.1167/18.4.13
ER  -
TY  - JOUR
DESCRIPTORS  - *Acoustics;  *Classification (Cognitive Process);  *Emotions;  *Music Perception; Pitch (Frequency)
PMID  - 30047757
ID  - 2018-35135-001
T1  - Musical emotions in congenital amusia: Impaired recognition, but preserved emotional intensity.
JF  - Neuropsychology
A1  - Lévêque, Yohana
A1  - Teyssier, Perrine
A1  - Bouchet, Patrick
A1  - Bigand, Emmanuel
A1  - Caclin, Anne
A1  - Tillmann, Barbara
VL  - 32
SP  - 880
EP  - 894
Y1  - 2018
CY  - US
AD  - Lévêque, Yohana: Centre de Recherche en Neurosciences de Lyon, INSERM U1028, CNRS, UMR5292, University Lyon 1, Equipe Dynamique Cerebrale et Cognition, Centre Hospitalier Le Vinatier, (Bat. 452), 95, Bd Pinel, Bron, France, 69500, yohana.leveque@inserm.fr
PB  - American Psychological Association
SN  - 1931-1559(Electronic),0894-4105(Print)
N2  - Objective: To further our understanding of the role of perceptual processes in musical emotions, we investigated individuals with congenital amusia, a neurodevelopmental disorder that alters pitch processing. Method: Amusic and matched control participants were studied for emotion recognition and emotion intensity ratings of both musical excerpts and faces. Results: Emotion recognition was found to be impaired in amusic participants relative to controls for the musical stimuli only. This impairment suggests that perceptual deficits in music processing reduce amusics’ access to a verbal and conscious representation of musical emotions. Nevertheless, amusics’ performance for emotion recognition was above chance level, and multidimensional scaling (MDS) analyses revealed that their categorization of musical pieces was based on similar representation spaces of emotions as for control participants. The emotion intensity ratings, nonverbal and possibly more implicit than the categorization task, seemed to be intact in amusic participants. Conclusions: These findings reveal that pitch deficits can hinder the recognition of emotions conveyed by musical pieces, while also highlighting the (at least partial) dissociation between emotion recognition and emotion intensity evaluation. Our study thus sheds light on the complex interactions between perceptual and emotional networks in the brain, by showing that impaired central auditory processing partially alters musical emotion processing. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Acoustics
KW  - *Classification (Cognitive Process)
KW  - *Emotions
KW  - *Music Perception
KW  - Pitch (Frequency)
M3  - doi:10.1037/neu0000461
DO  - 10.1037/neu0000461
ER  -
TY  - JOUR
DESCRIPTORS  - *Alexithymia;  *Facial Expressions; Emotion Recognition
PMID  - 25938612
ID  - 2015-19436-001
T1  - A new look at emotion perception: Concepts speed and shape facial emotion recognition.
JF  - Emotion
A1  - Nook, Erik C.
A1  - Lindquist, Kristen A.
A1  - Zaki, Jamil
VL  - 15
SP  - 569
EP  - 578
Y1  - 2015
CY  - US
AD  - Nook, Erik C.: Department of Psychology, Stanford University, 450 Serra Mall, Stanford, CA, US, 94305, erik.nook@gmail.com
PB  - American Psychological Association
SN  - 1931-1516(Electronic),1528-3542(Print)
N2  - Decades ago, the “New Look” movement challenged how scientists thought about vision by suggesting that conceptual processes shape visual perceptions. Currently, affective scientists are likewise debating the role of concepts in emotion perception. Here, we utilized a repetition-priming paradigm in conjunction with signal detection and individual difference analyses to examine how providing emotion labels—which correspond to discrete emotion concepts—affects emotion recognition. In Study 1, pairing emotional faces with emotion labels (e.g., “sad”) increased individuals’ speed and sensitivity in recognizing emotions. Additionally, individuals with alexithymia—who have difficulty labeling their own emotions—struggled to recognize emotions based on visual cues alone, but not when emotion labels were provided. Study 2 replicated these findings and further demonstrated that emotion concepts can shape perceptions of facial expressions. Together, these results suggest that emotion perception involves conceptual processing. We discuss the implications of these findings for affective, social, and clinical psychology. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Alexithymia
KW  - *Facial Expressions
KW  - Emotion Recognition
M3  - doi:10.1037/a0039166
DO  - 10.1037/a0039166
ER  -