Provider: American Psychological Association
Database: PsycINFO
Content: application/x-research-info-systems

TY  - CHAP
DESCRIPTORS  - *Computers;  *Games;  *Human Computer Interaction;  *Robotics; Emotions
ID  - 2014-43075-034
T1  - Emotion in games.
T2  - The Oxford handbook of affective computing.
T3  - Oxford library of psychology.
A1  - Yannakakis, Georgios N.
A1  - Paiva, Ana
SP  - 459
EP  - 471
Y1  - 2015
CY  - New York,  NY,  US
PB  - Oxford University Press
SN  - 978-0-19-994223-7 (Hardcover)
N2  - Emotion has been investigated from various perspectives and across several domains within human-computer interaction (HCI) including intelligent tutoring systems, interactive web applications, social media, and human-robot interaction. One of the most promising and also challenging applications of affective computing research is within computer games. This chapter focuses on the study of emotion in the computer games domain, reviews seminal work at the crossroads of game technology, game design, and affective computing, and details the key phases for efficient affect-based interaction in games. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Computers
KW  - *Games
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - Emotions
M3  - doi:10.1093/oxfordhb/9780199942237.001.0001
DO  - 10.1093/oxfordhb/9780199942237.001.0001
ER  -
TY  - CHAP
DESCRIPTORS  - *Cognition;  *Emotions;  *Models; Robotics
ID  - 2014-04196-006
T1  - Robotic emotions: Cognitive models and the search for the upset robot.
T2  - Emotional expression: The brain and the face, Vol. 4
T3  - Studies in brain, face and emotion.
A1  - Montoya, Daniel
SP  - 197
EP  - 213
Y1  - 2013
CY  - Porto,  Portugal
PB  - Edições Universidade Fernando Pessoa
SN  - 978-989-643-117-4 (Digital (undefined format))
N2  - The study of emotions in humans has been greatly advanced by new developments in robotic applications. In a previous chapter (Montoya, Baker-Oglesbee, & Bhattacharya, 2011) we reviewed the evidence regarding human emotional response to robots, a response that included behavioral and neural elements. In this chapter, we look at the other side of the equation by describing some of the current models of emotion-generation in artificial systems and detail some of the challenges and the solutions that have been proposed. We succinctly review some of the recent cognitive models utilizing humanoid robots such as iCub and Nao with the underlying assumption that applications based on human development and embodied agents will have the greater chances to succeed. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Cognition
KW  - *Emotions
KW  - *Models
KW  - Robotics
ER  -
TY  - JOUR
DESCRIPTORS  - *Anxiety Disorders;  *Artificial Intelligence;  *Drug Therapy; Psychotherapy
PMID  - 35126211
ID  - 2022-30251-001
T1  - Efficacy of artificial intelligence-assisted psychotherapy in patients with anxiety disorders: A prospective, national multicenter randomized controlled trial protocol.
JF  - Frontiers in Psychiatry
A1  - Su, Shanshan
A1  - Wang, Yuan
A1  - Jiang, Wenhui
A1  - Zhao, Wenqing
A1  - Gao, Rui
A1  - Wu, Yanru
A1  - Tao, Jing
A1  - Su, Yousong
A1  - Zhang, Jie
A1  - Li, Kangzheng
A1  - Zhang, Zhuojun
A1  - Zhao, Min
A1  - Wang, Zhen
A1  - Luo, Yanli
A1  - Huang, Xiao
A1  - Wang, Lanlan
A1  - Wang, Xiaoping
A1  - Li, Yi
A1  - Jia, Qiufang
A1  - Wang, Lianzi
A1  - Li, Huafang
A1  - Huang, Jingjing
A1  - Qiu, Jianyin
A1  - Xu, Yifeng
VL  - 12
Y1  - 2022
CY  - Switzerland
AD  - Qiu, Jianyin: jianyin_qiu@163.com
PB  - Frontiers Media S.A.
SN  - 1664-0640(Electronic)
N2  - Background: Anxiety disorders have the highest prevalence of all psychiatric disorders in China. Medication and psychotherapy are two main treatment approaches for this group of disorders, and when used in combinations are significantly more beneficial than medication alone. The resources are insufficient. The availability of psychotherapy is low due to the limited resources. Artificial intelligence (AI)-assisted psychotherapy offers an opportunity to develop an efficient and standardized psychotherapy model and improve the availability of psychotherapy, which is key to improve the clinical efficacy of anxiety disorder treatments. Objectives: The present protocol aims to determine whether medication plus AI-assisted psychotherapy has greater efficacy than medication alone in the treatment of anxiety disorders. Methods: We will recruit patients in eight hospitals in China. Seven hundred and eight patients with anxiety disorders will be randomly allocated on a 1:1 basis to either medication plus AI-assisted psychotherapy group, or medication alone group. We have built an AI psychotherapy robot named XIAO AN. In this study we will deliver psychotherapy to patients in the medication plus AI-assisted psychotherapy group. Patients will be assessed at baseline and at the end of week 2, 4, 8, and 12. Follow-up assessments will be conducted at 3 and 6 months posttreatment. The primary outcome is change of Hamilton Anxiety Rating Scale (HAMA) score from baseline the end of 12-week treatment. A secondary efficacy outcome will be improvement in treatment at an early stage (score reduction in HAMA ≥25% after 2 weeks of treatment). Other measurements include Hamilton Depression Scale, Clinical Global Impression, Treatment Emergent Symptom Scale, Social Disability Screening Schedule, Insomnia Severity Index and so on. Scales will be assessed by independent raters who are blind to treatment allocation and analyses will be conducted by a statistician who is also blind to treatment allocation. Discussion: This will be the first multicentered randomized controlled single-blind trial in China to assess the efficacy of medication plus AI-assisted psychotherapy compared with medication alone for anxiety disorders. The study has the potential to address the limitations of the limited availability of psychotherapy, and to augment the efficacy of the treatment of anxiety disorders in China. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Anxiety Disorders
KW  - *Artificial Intelligence
KW  - *Drug Therapy
KW  - Psychotherapy
M3  - doi:10.3389/fpsyt.2021.799917
DO  - 10.3389/fpsyt.2021.799917
ER  -
TY  - THES
DESCRIPTORS  - *Computers;  *Facial Expressions;  *Human Computer Interaction;  *Emotion Recognition;  *Affective Computing; Probability; Robotics; Electronic Learning
ID  - 2022-70650-282
T1  - Incorporating emotion recognition in co-adaptive systems.
A1  - Al-Omair, Osamah M.
VL  - 83
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - US
PB  - ProQuest Information & Learning
SN  - 0419-4217(Print)
N2  - The collaboration between human and computer systems has grown astronomically over the past few years. The ability of software systems adapting to human's input is critical in the symbiosis of human-system co-adaptation, where human and software-based systems work together in a close partnership to achieve synergetic goals. However, it is not always clear what kinds of human's input should be considered to enhance the effectiveness of human and system co-adaptation. To address this issue, this research describes an approach that focuses on incorporating human emotion to improve human-computer co-adaption. The key idea is to provide a formal framework that incorporates human emotions as a foundation for explainability into co-adaptive systems, especially, how software systems recognize human emotions and adapt the system's behaviors accordingly. Detecting and recognizing optimum human emotion is a first step towards human and computer symbiosis. As the first step of this research, we conduct a comparative review for a number of technologies and methods for emotion recognition. Specifically, testing the detection accuracy of facial expression recognition of different cloud-services, algorithms, and methods.Secondly, we study the application of emotion recognition within the areas of e-learning, robotics, and explainable artificial intelligence (XAI). We propose a formal framework that incorporates human emotions into an adaptive e-learning system, to create a more personalized learning experience for higher quality of learning outcomes. In addition, we propose a framework for a co-adaptive Emotional Support Robot. This human-centric framework adopts a reinforced learning approach where the system assesses its own emotional re-actions.Finally, we present a formal probabilistic framework that incorporates emotion recognition for explanations and predicting human performance in a co-adaptive scenario. We illustrate the operability of our framework using a Decision Support System with a human operator supervising the system's decisions. We model our approach using a Stock Prediction Engine that was developed in our research lab to predict the price direction of a stock. We use probabilistic model checking to determine how complex an explanation needs to be based on how confused the human is for the purpose of improving the system's overall utility. In addition, we conduct a web-based human experiment to measure the effectiveness of incorporating emotions in improving the outcome of a co-adaptive system. Our study shows that considering human emotions in co-adaptive systems' explanation is one of the important factors for improving the overall systems performance and utility functions. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Computers
KW  - *Facial Expressions
KW  - *Human Computer Interaction
KW  - *Emotion Recognition
KW  - *Affective Computing
KW  - Probability
KW  - Robotics
KW  - Electronic Learning
ER  -
TY  - CHAP
DESCRIPTORS  - *Decision Making;  *Robotics;  *Positive Emotions; Memory; Negative Emotions
ID  - 2017-00889-072
T1  - On realizing emotional memories.
T2  - Psychology and mental health: Concepts, methodologies, tools, and applications, Vols. 1-3
A1  - Singh, Saurabh K.
A1  - Jha, Shashi Shekhar
A1  - Nair, Shivashankar B.
SP  - 1652
EP  - 1689
Y1  - 2016
CY  - Hershey,  PA,  US
PB  - Information Science Reference/IGI Global
SN  - 1-522-50159-2 (Hardcover); 978-1-522-50159-6 (Hardcover); 978-1-522-50160-2 (Digital (undefined format))
N2  - Emotion and memory have been two intermingled areas in psychological research. Although researchers are still fairly clueless on how human emotions or memory work, several attempts have been made to copy the dynamics of these two entities in the realm of robotics. This chapter describes one such attempt to capture the dynamics of human emotional memories and model the same for use in a real robot. Emotional memories are created at extreme emotional states, namely, very positive or happy events or very negative ones. The positive ones result in the formation of positive memories while the negative ones form the negative counterparts. The robotic system seeks the positive ones while it tries to avoid the negative ones. Such memories aid the system in making the right decisions, especially when situations similar to the one which caused their generation, repeat in the future. This chapter introduces the manner in which a multi-agent emotion engine churns out the emotions which in turn generate emotional memories. Results obtained from simulations and those from using a real situated robot described herein, validate the working of these memories. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Decision Making
KW  - *Robotics
KW  - *Positive Emotions
KW  - Memory
KW  - Negative Emotions
M3  - doi:10.4018/978-1-5225-0159-6.ch072
DO  - 10.4018/978-1-5225-0159-6.ch072
ER  -
TY  - THES
DESCRIPTORS  - *Adaptive Behavior;  *Learning;  *Measurement;  *Physiology;  *Well Being; Adaptation; Adjustment; Intelligence
ID  - 2022-56507-121
T1  - Investigation into the creation of an ambient intelligent physiology measurement environment to facilitate modelling of the human wellbeing.
A1  - Mewafy, Sherif El Sayed Mohamed Mohamed
VL  - 83
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - US
PB  - ProQuest Information & Learning
SN  - 0419-4217(Print)
N2  - The elderly population worldwide has an increasing expectation of wellbeing and life expectancy. The monitoring of the majority of elderly people on an individual basis, in a medical sense, will not be a viable proposition in the future due to the projected numbers of individuals requiring such activity. The expectation is that the infrastructure available will not be adequate to meet all the anticipated requirements and subsequently people will have to live at home with inadequate care. A new global objective that aims towards enhancing the quality of life of the elderly is being supported by extensive research. This research has been taking place in the field of ambient intelligence (AmI), considering factors including more comfort, improved health, enhanced security for the elderly, and facilitating the living in their homes longer. Prior research has shown a need for accelerated expansion in the ambient intelligence domain. To that end this work presents a novel learning technique for intelligent agents that can be used in Ambient Intelligent Environments (AIEs).The main objective of this work is to add knowledge to the AmI domain and to explore the practical applications within this research field. The added knowledge is accomplished through the development of an ambient intelligent health care environment that allows a practical assessment of the human well-being to take place. This is achieved by transforming the elderly living environment into an intelligent pseudo robot within which they reside to better understand the human wellbeing.The system developed aims to provide evidence that a level of automated care is both possible and practical. This care is for those with chronic physical or mental disabilities who have difficulty in their interactions with standardised living spaces. The novel integrated hardware and software architecture provides personalised environmental monitoring. It also provides control facilities based on the patient's physical and emotional wellness in their home.Entitled Health Adaptive Online Emotion Fuzzy Agent (HAOEFA), the system provides a non-invasive, self-learning, intelligent controlling system that constantly adapts to the requirements of an individual. The system has the ability to model and learn the user behaviour in order to control the environment on their behalf. This is achieved with respect to the changing environmental conditions as well as the user's health and emotional states being detected. A change of emotion can have a direct impact on the system's control taking place in the environment. Thus HAOEFA combines an emotion recognition system within a fuzzy logic learning and adaptation based controller. The emotion recogniser detects the occupant's emotions upon the changes of the physiological data being monitored. In addition to acting as an output to the occupant's physiological changes, the detected emotion also acts as input to the whole situation being observed by HAOEFA. This allows HAOEFA to control the Glam i-HomeCare on the user's behalf with respect to their emotional status.The system developed incorporates real-time, continuous adaptations to facilitate any changes to the occupant's behaviour within the environment. It also allows the rules to be adapted and extended online, assisting a life-long learning technique as the environmental conditions change and the user behaviour adjusts with it. HAOEFA uses the fuzzy c-means clustering methodology for extracting membership functions (MFs) before building its set of fuzzy rules. These MFs together with the rules base constitute a major part of the proposed system. It has the ability to learn and model the individual human behaviour with respect to their emotional status.Following the provided literature review and the presentation of Fuzzy logic MFs (see section 3.3). (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Adaptive Behavior
KW  - *Learning
KW  - *Measurement
KW  - *Physiology
KW  - *Well Being
KW  - Adaptation
KW  - Adjustment
KW  - Intelligence
ER  -
TY  - CHAP
DESCRIPTORS  - *Emotional Responses;  *Face Perception;  *Neurosciences; Robotics
ID  - 2011-30587-002
T1  - What the robot sees, what the human feels: Robotic face detection and the human emotional response.
T2  - Emotional expression: The brain and the face, Vol. 3
T3  - Studies in brain, face, and emotion.
A1  - Montoya, Daniel
A1  - Baker-Oglesbee, Alissa
A1  - Bhattacharya, Sambit
SP  - 43
EP  - 71
Y1  - 2011
CY  - Porto,  Portugal
AD  - Montoya, Daniel: dmontoya@uncfsu.edu
PB  - Edições Universidade Fernando Pessoa
SN  - 978-989-643-084-9 (Paperback)
N2  - New developments in robotics have brought humans and robots interacting in human environments. Research has focused its attention on the development of human-like virtual displays and robotics, while parallel lines of research have focused on the study of human responses to robotic agents with special emphasis in human’s emotional reaction. This chapter explores the intersection between robotics and neurosciences with special emphasis in human-robot interactions (HRI). We briefly present recent innovations in the context of robotic face detection and recognition as well as human physiological and cognitive response to the presence of artificial agents. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Emotional Responses
KW  - *Face Perception
KW  - *Neurosciences
KW  - Robotics
ER  -
TY  - THES
DESCRIPTORS  - *Childhood Development;  *Judgment;  *Morality; Robotics
ID  - 2016-42148-015
T1  - Children's conceptions of the moral standing of a humanoid robot of the here and now.
A1  - Shen, Solace
VL  - 77
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2016
CY  - US
PB  - ProQuest Information & Learning
SN  - 0419-4217(Print)
N2  - Sophisticated humanoid robots have recently moved from the laboratory and research settings to the home environment. Some models are now marketed to families with children, and are designed to engage children in increasingly social and potentially moral interactions. The purpose of this study is to investigate---when children interact with a commercially available humanoid robot and witness a human causing a harm to the robot---whether children conceptualize the robot as being an entity that deserves moral consideration: what is referred to in this study as having moral standing. Participants included 120 children in 2 age groups (8-9 and 14-15). To assess the effects of the robot's physical embodiment on participants' conceptions of the robot's moral standing, 30 participants from each age group (gender balanced) were randomly assigned to 1 of 2 conditions and interacted with either a humanoid robot or an analogous virtual agent. In each condition, the interaction culminated in a confederate hitting the robot/virtual agent with a book. Each participant was then engaged in a semi-structured interview that ascertained their judgments and reasoning regarding the robot/virtual agent and three comparison entities. Results show that the majority of the participants judged the confederate hitting the robot as a violation of moral obligation, and many brought the concept of artificial emotion to bear in their reasoning. Participants were significantly more likely to judge it a violation of moral obligation to hit the robot than the virtual agent. Moreover, the 8- to 9-year-olds were significantly more likely than the 14- to 15-year-olds to judge it a violation of moral obligation to hit either the robot or the virtual agent. Finally, participants' conceptions of the robot's moral standing largely showed a unique composition of moral features when compared to those of the comparison entities. Discussion addresses the broader implications of these findings and future directions for research are offered. (PsycINFO Database Record (c) 2017 APA, all rights reserved)
KW  - *Childhood Development
KW  - *Judgment
KW  - *Morality
KW  - Robotics
ER  -
TY  - JOUR
PMID  - 35389323
ID  - 2022-53720-001
T1  - People’s dispositional cooperative tendencies towards robots are unaffected by robots’ negative emotional displays in prisoner’s dilemma games.
JF  - Cognition and Emotion
A1  - Hsieh, Te-Yi
A1  - Cross, Emily S.
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - United Kingdom
AD  - Cross, Emily S.: e.cross@westernsydney.edu.au
PB  - Taylor & Francis
SN  - 1464-0600(Electronic),0269-9931(Print)
N2  - Abstract The study explores the impact of robots’ emotional displays on people’s tendency to cooperate with a robot opponent in prisoner’s dilemma games. Participants played iterated prisoner’s dilemma games with a non-expressive robot (as a measure of cooperative baseline), followed by an angry, and a sad robot, in turn. Based on the Emotion as Social Information model, we expected participants with higher cooperative predispositions to cooperate less when a robot displayed anger, and cooperate more when the robot displayed sadness. Contrarily, according to this model, participants with lower cooperative predispositions should cooperate more with an angry robot and less with a sad robot. The results of 60 participants failed to support the predictions. Only the participants’ cooperative predispositions significantly predicted their cooperative tendencies during gameplay. Participants who cooperated more in the baseline measure also cooperated more with the robots displaying sadness and anger. In exploratory analyses, we found that participants who accurately recognised the robots’ sad and angry displays tended to cooperate less with them overall. The study highlights the impact of personal factors in human–robot cooperation, and how these factors might surpass the influence of bottom-up emotional displays by the robots in the present experimental scenario. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
M3  - doi:10.1080/02699931.2022.2054781
DO  - 10.1080/02699931.2022.2054781
ER  -
TY  - JOUR
DESCRIPTORS  - *Fear;  *Pandemics;  *Psychosocial Factors;  *Robotics;  *Coronavirus; COVID-19; Physical Distancing
PMID  - 33071853
ID  - 2020-76187-001
T1  - The psychosocial fuzziness of fear in the coronavirus (COVID-19) era and the role of robots.
JF  - Frontiers in Psychology
A1  - Marchetti, Antonella
A1  - Di Dio, Cinzia
A1  - Massaro, Davide
A1  - Manzi, Federico
VL  - 11
Y1  - 2020
CY  - Switzerland
AD  - Manzi, Federico: federico.manzi@unicatt.it
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - The article reflects on the psychosocial fuzziness of fear in the coronavirus (COVID-19) era and the role of robots. In reading the new relational dynamics hypothesized in the present work, from which the robot is spared, COVID-19 pandemics added novelty to the physiognomy of fear, which (unlike anxiety) is an emotion linked to objects and situational antecedents, and which may therefore be affected by the nature of its objects at the level of subjective experiences, behavioral reactions, as well as coping strategies. These theoretical suggestions may enrich knowledge from an interdisciplinary perspective, such as robotics and psychology, providing important starting points for future research by emphasizing which psychological components should be investigated in people interacting with robots. An example is the perception of in-group/out-group, as well as the components of fear that, in our opinion, are mitigated toward robots in the specific COVID-19 situation, which forces us to adapt to the inclusion of new social agents devoted to care assistance. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Fear
KW  - *Pandemics
KW  - *Psychosocial Factors
KW  - *Robotics
KW  - *Coronavirus
KW  - COVID-19
KW  - Physical Distancing
M3  - doi:10.3389/fpsyg.2020.02245
DO  - 10.3389/fpsyg.2020.02245
ER  -
TY  - CHAP
DESCRIPTORS  - *Cognitive Ability;  *Cognitive Processes;  *Emotions; Intelligence
ID  - 2014-19965-022
T1  - Body and emotion.
T2  - The Routledge handbook of embodied cognition.
T3  - Routledge handbooks in philosophy.
A1  - Maiese, Michelle
SP  - 231
EP  - 239
Y1  - 2014
CY  - New York,  NY,  US
PB  - Routledge/Taylor & Francis Group
SN  - 978-0-415-62361-2 (Hardcover); 978-1-315-77584-5 (PDF)
N2  - My claim that emotions are essentially embodied, enactive appraisals has important implications for artificial intelligence (AI). Much of the work being done in AI begins with the notion that it is possible to formulate "explicitly specifiable rules of thought" that govern the move from one cognitive state to another and then program these rules into a computer. Early work in AI and robotics often involved robots operating in mostly static environments that to some extent had been designed specifically for them. In the real world, however, things change. To be truly "intelligent," a robot must be able to cope and adjust its plan of action, and thus be truly dynamic and immediately sensitive to change. However, the robot should not have to replan as a result of every change to its surroundings, but instead only in response to changes that are relevant to its goals. It seems clear that this ability to detect relevance is a crucial aspect of human intelligence, but it is unclear how to get a robot to accomplish this simply by following an algorithm. Programming many thousands of facts into the computer hardly helps, since effective agency requires that the computer determine which facts are relevant to its proposed action. Even if the computer had a straight forward set of relevance rules, it is unclear that it could apply these rules successfully in any efficient way. What is relevant is constantly changing, based on the interplay between various aspects of the environment, situational factors, and the robot's particular abilities. Changing any one factor can change the relevance of some other factor. Carried out by a computer system manipulating formal symbols, all this rule-following would take too long and would be too cognitively "expensive". Moreover, it seems that "in order to identify the possibly relevant facts in the current situation one would need a frame for recognizing," but this would result in a "regress of frames for recognizing relevant frames for recognizing relevant facts". Without an immediate, intuitive means of detecting relevance, robots could respond only to fixed features of their surroundings. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Cognitive Ability
KW  - *Cognitive Processes
KW  - *Emotions
KW  - Intelligence
ER  -
TY  - BOOK
DESCRIPTORS  - *Robotics;  *Technology;  *Human Robot Interaction; Caregivers; Cognitive Ability; Emotions; Machine Learning; Surgery; Autonomy; Caregiving
ID  - 2019-72311-000
T1  - Living with robots: Emerging issues on the psychological and social implications of robotics.
T2  - Living with robots: Emerging issues on the psychological and social implications of robotics.
A2  - Pak, Richard
A2  - de Visser, Ewart J.
A2  - Rovira, Ericka
SP  - xiv, 204
EP  - xiv, 204
Y1  - 2020
CY  - San Diego,  CA,  US
PB  - Elsevier Academic Press
SN  - 9780128153673 (Paperback)
N2  - This book focuses on the issues that come to bear when humans interact and collaborate with robots. It dives deeply into critical factors that impact how individuals interact with robots at home, work and play. It includes topics ranging from robot anthropomorphic design, degree of autonomy, trust, individual differences and machine learning. While other books focus on engineering capabilities or the highly conceptual, philosophical issues of human-robot interaction, this resource tackles the human elements at play in these interactions, which are essential if humans and robots are to coexist and collaborate effectively. Authored by key psychology robotics researchers, the book limits its focus to specifically those robots who are intended to interact with people, including technology such as drones, self-driving cars, and humanoid robots. Forward-looking, the book examines robots not as the novelty they used to be, but rather the practical idea of robots participating in our everyday lives. It explores how individual differences in cognitive abilities and personality influence human-robot interaction and examines the human response to robot autonomy Includes tools and methods for the measurement of social emotion with robots. The book also delves into a broad range of domains—military, caregiving, toys, surgery, and more. It anticipates the issues we will encountering with robots in the next ten years. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Robotics
KW  - *Technology
KW  - *Human Robot Interaction
KW  - Caregivers
KW  - Cognitive Ability
KW  - Emotions
KW  - Machine Learning
KW  - Surgery
KW  - Autonomy
KW  - Caregiving
ER  -
TY  - CHAP
DESCRIPTORS  - *Childhood Development;  *Emotional Responses; Facial Expressions
ID  - 2016-06464-003
T1  - Emotion on board.
T2  - Emotion in language: Theory – research – application.
T3  - Consciousness and emotion book series.
A1  - Nadel, Jacqueline
A1  - Han, Bora
SP  - 49
EP  - 67
Y1  - 2015
CY  - Amsterdam,  Netherlands
PB  - John Benjamins Publishing Company
SN  - 978-90-272-4160-3 (Hardcover); 978-90-272-6765-8 (Digital (undefined format))
N2  - Emotion is on board from first. Fetal facial expressions change strikingly fast, thus indicating that they are actively practiced before birth. What for? Are we wired to express our emotions and to resonate to others’? Blank faces or non contingent faces cause disturbance early on life. When mother does not respond contingently to her 2-month-old, the infant mood turns to negative expression. Children with autism, even low-functioning ones, try to reconnect with a still person. Children track preferentially core expressive features, even if those features are generated by a robot. Our EEG studies with adults indicate that emotion is captured regardless of the vehicle (human or robotic stimuli). This suggests that emotional development leads to decipher emotional signals beyond faces. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Childhood Development
KW  - *Emotional Responses
KW  - Facial Expressions
M3  - doi:10.1075/ceb.10.03nad
DO  - 10.1075/ceb.10.03nad
ER  -
TY  - JOUR
DESCRIPTORS  - *Habits;  *Mathematical Modeling;  *Perceptual Motor Processes; Simulation
PMID  - 25941482
ID  - 2015-35773-001
T1  - "Modeling habits as self-sustaining patterns of sensorimotor behavior": Corrigendum.
JF  - Frontiers in Human Neuroscience
A1  - Egbert, Matthew D.
A1  - Barandiaran, Xabier E.
VL  - 9
Y1  - 2015
CY  - Switzerland
AD  - Egbert, Matthew D.: Embodied Emotion, Cognition and (Inter-)Action Lab, School of Computer Science, University of Hertfordshire, College Lane, Hatfield, HRT, United Kingdom, AL10 9AB, mde@matthewegbert.com
PB  - Frontiers Media S.A.
SN  - 1662-5161(Electronic)
N2  - Reports an error in "Modeling habits as self-sustaining patterns of sensorimotor behavior" by Matthew D. Egbert and Xabier E. Barandiaran (Frontiers in Human Neuroscience, 2014[Aug][8], Vol 8[590]). In the original article, Equation 8 is incorrectly written. The correction equation is present in the erratum. (The following abstract of the original article appeared in record 2014-52023-001). In the recent history of psychology and cognitive neuroscience, the notion of habit has been reduced to a stimulus-triggered response probability correlation. In this paper we use a computational model to present an alternative theoretical view (with some philosophical implications), where habits are seen as self-maintaining patterns of behavior that share properties in common with self-maintaining biological processes, and that inhabit a complex ecological context, including the presence and influence of other habits. Far from mechanical automatisms, this organismic and self-organizing concept of habit can overcome the dominating atomistic and statistical conceptions, and the high temporal resolution effects of situatedness, embodiment and sensorimotor loops emerge as playing a more central, subtle and complex role in the organization of behavior. The model is based on a novel “iterant deformable sensorimotor medium (IDSM),” designed such that trajectories taken through sensorimotor-space increase the likelihood that in the future, similar trajectories will be taken. We couple the IDSM to sensors and motors of a simulated robot, and show that under certain conditions, the IDSM conditions, the IDSM forms self-maintaining patterns of activity that operate across the IDSM, the robot’s body, and the environment. We present various environments and the resulting habits that form in them. The model acts as an abstraction of habits at a much needed sensorimotor “meso-scale” between microscopic neuron-based models and macroscopic descriptions of behavior. Finally, we discuss how this model and extensions of it can help us understand aspects of behavioral self-organization, historicity and autonomy that remain out of the scope of contemporary representationalist frameworks. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Habits
KW  - *Mathematical Modeling
KW  - *Perceptual Motor Processes
KW  - Simulation
M3  - doi:10.3389/fnhum.2015.00209
DO  - 10.3389/fnhum.2015.00209
ER  -
TY  - THES
DESCRIPTORS  - *Curiosity;  *Emotions;  *Learning;  *Openness to Experience;  *Older Adulthood; Age Differences; Happiness; Motivation
ID  - 2022-34092-052
T1  - Do we become more or less curious with age? Examining the roles of age and personal relevance.
A1  - Chu, Li
VL  - 83
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - US
PB  - ProQuest Information & Learning
SN  - 0419-4217(Print)
N2  - According to socioemotional selectivity theory (Carstensen, 1995), people tend to prioritize emotionally meaningful goals over information-seeking goals in later adulthood. However, being curious and motivated to learn is becoming more essential for older adults today than ever before because there are more situations in which older adults have to adapt to novelties (e.g., new life style and novel technologies). Thus, it would be important to understand the association between age and different types of curiosity (e.g., trait versus state) and potential factors that contribute to this association. Through three manuscripts, this thesis aimed to provide more in-depth understanding of the association between age and trait curiosity (Manuscript 1), examine the moderating role of personal relevance in the association between age and state curiosity toward novelties (Manuscript 2) and evaluate the affective experience of state curiosity for younger and older adults (Manuscript 3). In Manuscript 1 (Chu, Tsai, & Fung, 2020), the association between age and trait curiosity was examined. Specifically, this study investigated the underlying mechanisms for age-related declines in intellectual curiosity. A moderated serial multiple mediation model revealed that the association between age and intellectual curiosity was mediated by future time perspective and perceived importance of curiosity. Manuscript 2 utilized a pre- and post-test experimental design and a survey to investigate the relationship between age and different types of curiosity, and the role of personal relevance in this relationship. In general, older adults showed a lower level of trait curiosity than did younger adults, but patterns of age differences in state curiosity were less consistent across the two studies reported in this manuscript. Moreover, older adults who perceived increased personal relevance after interacting with a robot were significantly more curious than older adults who did not perceived increased relevance, but this pattern was not found in younger adults. Finally, Manuscript 3 included a survey study and a time-sampling study to investigate the affective experience of being curious among younger and older adults. The multilevel modelling results illustrated a positive relationship between state curiosity and momentary happiness for both younger and older adults. Yet, momentary anxiousness was positively associated with curiosity of younger adults only but not for older adults. Moreover, a significant three-way interaction between age group, happiness and anxiousness was found, suggesting that older adults were more likely to perceive curiosity as a mixed emotional experience and younger adults were more likely to perceive curiosity as an either-happy-oranxious experience. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Curiosity
KW  - *Emotions
KW  - *Learning
KW  - *Openness to Experience
KW  - *Older Adulthood
KW  - Age Differences
KW  - Happiness
KW  - Motivation
ER  -
TY  - JOUR
DESCRIPTORS  - *Human Sex Differences;  *Pleasure;  *Tactual Perception;  *Negative Emotions; Animal Sex Differences; Experimental Methods; Surveys; Velocity
ID  - 2022-55224-001
T1  - Understanding sex differences in affective touch: Sensory pleasantness, social comfort, and precursive experiences.
JF  - Physiology & Behavior
A1  - Schirmer, Annett
A1  - Cham, Clare
A1  - Zhao, Zihao
A1  - Lai, Oscar
A1  - Lo, Clive
A1  - Croy, Ilona
VL  - 250
SP  - 1
EP  - 11
Y1  - 2022
CY  - Netherlands
AD  - Schirmer, Annett: dr.annettschirmer@gmail.com
PB  - Elsevier Science
SN  - 1873-507X(Electronic),0031-9384(Print)
N2  - Although previous research revealed sex differences in affective touch, the implicated processes and the manner in which men and women differ have been left uncertain. Here we addressed this issue in two studies examining sensory pleasure, interpersonal comfort, and touch motivators. Study 1 comprised a series of lab-based experiments in which a robot stroked 214 participants (half female) at five different velocities modulating the activity of C-tactile afferents thought to support tactile pleasantness. Average pleasantness ratings followed velocity with the typical inverted u-shape similarly in both sexes. In Study 2, 260 participants (half female) completed an online survey. Here, women were more likely than men to express touch comfort with less familiar or unknown individuals, had a greater preference for touch with other women, and felt more comfortable giving and receiving touch to the forearm. Additionally, when describing how their own experiences might motivate others to touch them affectively, women produced more negative descriptions than men. Together, these results show that, while the sexes compare in a touch's sensory pleasantness, they differ in their preceding affective experiences and how they value touch at a higher-order social level. This agrees with extant research on negative affect and stress and suggests that affective touch may be a more relevant coping mechanism for women than for men. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Human Sex Differences
KW  - *Pleasure
KW  - *Tactual Perception
KW  - *Negative Emotions
KW  - Animal Sex Differences
KW  - Experimental Methods
KW  - Surveys
KW  - Velocity
M3  - doi:10.1016/j.physbeh.2022.113797
DO  - 10.1016/j.physbeh.2022.113797
ER  -
TY  - JOUR
DESCRIPTORS  - *Artificial Intelligence;  *Human Computer Interaction; Emotional Responses
PMID  - 30057561
ID  - 2018-36037-001
T1  - Biologically inspired emotional expressions for artificial agents.
JF  - Frontiers in Psychology
A1  - Korcsok, Beáta
A1  - Konok, Veronika
A1  - Persa, György
A1  - Faragó, Tamás
A1  - Niitsuma, Mihoko
A1  - Miklósi, Ádám
A1  - Korondi, Péter
A1  - Baranyi, Péter
A1  - Gácsi, Márta
VL  - 9
Y1  - 2018
CY  - Switzerland
AD  - Korcsok, Beáta: korcsok@mogi.bme.hu
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - A special area of human-machine interaction, the expression of emotions gains importance with the continuous development of artificial agents such as social robots or interactive mobile applications. We developed a prototype version of an abstract emotion visualization agent to express five basic emotions and a neutral state. In contrast to well-known symbolic characters (e.g., smileys) these displays follow general biological and ethological rules. We conducted a multiple questionnaire study on the assessment of the displays with Hungarian and Japanese subjects. In most cases participants were successful in recognizing the displayed emotions. Fear and sadness were most easily confused with each other while both the Hungarian and Japanese participants recognized the anger display most correctly. We suggest that the implemented biological approach can be a viable complement to the emotion expressions of some artificial agents, for example mobile devices. (PsycINFO Database Record (c) 2020 APA, all rights reserved)
KW  - *Artificial Intelligence
KW  - *Human Computer Interaction
KW  - Emotional Responses
M3  - doi:10.3389/fpsyg.2018.01191
DO  - 10.3389/fpsyg.2018.01191
ER  -
TY  - JOUR
DESCRIPTORS  - *Attribution;  *Robotics;  *Social Interaction;  *Human Robot Interaction; Emotions; Rabbits
ID  - 2011-14806-004
T1  - Empirical results on determinants of acceptance and emotion attribution in confrontation with a robot rabbit.
JF  - Applied Artificial Intelligence
A1  - Eimler, Sabrina C.
A1  - Krämer, Nicole C.
A1  - von der Pütten, Astrid M.
VL  - 25
SP  - 503
EP  - 529
Y1  - 2011
CY  - United Kingdom
AD  - Eimler, Sabrina C.: University of Duisburg–Essen, Forsthausweg 2, Duisburg, Germany, 47048, sabrina.elmer@uni-due.de
PB  - Taylor & Francis
SN  - 1087-6545(Electronic),0883-9514(Print)
N2  - As robots increasingly enter people’s everyday lives, it becomes ever more important to explore the conditions and determinants of acceptance of human interactions with these devices. Moreover, a positive feeling associated with the interaction with robots is a precondition for the user’s willingness to engage in further interactions and establish long-term relationships. This article presents empirical results from two studies that focus on the user’s perception of the robot rabbit Nabaztag, a small WiFi-enabled device with movable ears, integrated RFID reader functionality, and speech-synthesis capability. In the first study, 53 participants were confronted with a range of the Nabaztag’s functionality, and, using RFID cards, they interacted with the rabbit. The analysis of people’s answers concerning Perceived Ease of Use and Perceived Usefulness as well as hedonic and pragmatic aspects, showed gender-accorded differences regarding the evaluation of the device. Neither the degree of familiarity with computers nor the fact of whether technical disfunctionality occurred during the trial influenced the evaluation of the robot, while ownership of a robotic toy let people evaluate the Nabaztag more positively. The second study took a more detailed observance of the effect of the rabbit’s expression by its ears. In a within-subjects setting, a German (N = 100) and a U.S. American sample (N = 111) were asked to rate the rabbit’s current emotional status from pictures that showed the rabbit with a variety of six different ear positions. Results indicate that people infer specific emotional states from the robot rabbit’s different ear positions. Also illustrated is that observers’ attribution of feelings to the rabbit depends on their cultural backgrounds. Implications and questions for future research are discussed. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Attribution
KW  - *Robotics
KW  - *Social Interaction
KW  - *Human Robot Interaction
KW  - Emotions
KW  - Rabbits
M3  - doi:10.1080/08839514.2011.587154
DO  - 10.1080/08839514.2011.587154
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotional Control;  *Mind; Robotics
PMID  - 21687441
ID  - 2017-41550-001
T1  - The other half of the embodied mind.
JF  - Frontiers in Psychology
A1  - Parisi, Domenico
VL  - 2
Y1  - 2011
CY  - Switzerland
AD  - Parisi, Domenico: Laboratory of Artificial Life and Robotics, Institute of Cognitive Sciences and Technologies, National Research Council, Viale Marx 15, Rome, Italy, 00137, domenico.parisi@istc.cnr.it
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - Embodied theories of mind tend to be theories of the cognitive half of the mind and to ignore its emotional half while a complete theory of the mind should account for both halves. Robots are a new way of expressing theories of the mind which are less ambiguous and more capable to generate specific and non-controversial predictions than verbally expressed theories. We outline a simple robotic model of emotional states as states of a sub-part of the neural network controlling the robot's behavior which has specific properties and which allows the robot to make faster and more correct motivational decisions, and we describe possible extensions of the model to account for social emotional states and for the expression of emotions that, unlike those of current “emotional” robots, are really “felt” by the robot in that they play a well-identified functional role in the robot's behavior. (PsycINFO Database Record (c) 2018 APA, all rights reserved)
KW  - *Emotional Control
KW  - *Mind
KW  - Robotics
M3  - doi:10.3389/fpsyg.2011.00069
DO  - 10.3389/fpsyg.2011.00069
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotional States;  *Mathematical Modeling;  *Neural Networks;  *Robotics;  *Human Robot Interaction; Facial Expressions; Learning
PMID  - 26548943
ID  - 2015-51027-001
T1  - Multimodal emotional state recognition using sequence-dependent deep hierarchical features.
JF  - Neural Networks
A1  - Barros, Pablo
A1  - Jirak, Doreen
A1  - Weber, Cornelius
A1  - Wermter, Stefan
VL  - 72
SP  - 140
EP  - 151
Y1  - 2015
CY  - Netherlands
AD  - Barros, Pablo: Department of Informatics, University of Hamburg, Vogt-Koelln-Strasse 30, Hamburg, Germany, 22527, barros@informatik.uni-hamburg.de
PB  - Elsevier Science
SN  - 1879-2782(Electronic),0893-6080(Print)
N2  - Emotional state recognition has become an important topic for human–robot interaction in the past years. By determining emotion expressions, robots can identify important variables of human behavior and use these to communicate in a more human-like fashion and thereby extend the interaction possibilities. Human emotions are multimodal and spontaneous, which makes them hard to be recognized by robots. Each modality has its own restrictions and constraints which, together with the non-structured behavior of spontaneous expressions, create several difficulties for the approaches present in the literature, which are based on several explicit feature extraction techniques and manual modality fusion. Our model uses a hierarchical feature representation to deal with spontaneous emotions, and learns how to integrate multiple modalities for non-verbal emotion recognition, making it suitable to be used in an HRI scenario. Our experiments show that a significant improvement of recognition accuracy is achieved when we use hierarchical features and multimodal information, and our model improves the accuracy of state-of-the-art approaches from 82.5% reported in the literature to 91.3% for a benchmark dataset on spontaneous emotion expressions. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Emotional States
KW  - *Mathematical Modeling
KW  - *Neural Networks
KW  - *Robotics
KW  - *Human Robot Interaction
KW  - Facial Expressions
KW  - Learning
M3  - doi:10.1016/j.neunet.2015.09.009
DO  - 10.1016/j.neunet.2015.09.009
ER  -
TY  - BOOK
DESCRIPTORS  - *Artificial Intelligence;  *Expert Systems;  *Robotics; Cognition; Doubt
ID  - 2015-24110-000
T1  - Handbook of research on synthesizing human emotion in intelligent systems and robotics.
T2  - Handbook of research on synthesizing human emotion in intelligent systems and robotics.
T3  - Advances in computational intelligence and robotics (ACIR) book series.
A2  - Vallverdú, Jordi
SP  - xxv, 469
EP  - xxv, 469
Y1  - 2015
CY  - Hershey,  PA,  US
PB  - Information Science Reference/IGI Global
SN  - 978-1-4666-7278-9 (Hardcover); 978-1-4666-7279-6 (Digital (undefined format))
N2  - The emotional flavour of all the spheres of human activities is a matter of fact, beyond any reasonable doubt for everyone interested on human cognition. Besides, emotional aspects can be also found as non-linguistic utterances that define the social domain of human life. From our bodies to social groups, emotions act as ways to regulate and model these exchanges. Emotions and feelings are basic regulators of human activity. In fact, they are the base of our interaction with the world: through pleasure, pain, hunger or fear, we create intentional dispositions, acting like homeostatic controls over our actions. From the basic emotions to complex ones, humans share a common nature to give sense to the world. Recent decades of scientific research on neurophysiology have shown how emotions are not simply a part of human activity, but a fundamental one. Emotional states had been historically banned in the territory of human rationality (Descartes and his “res cogitans” was the last and most convincing proponent of this approach). And evolutionary approaches to consciousness or studies of emotions have shown that the origin of consciousness, lying in the structure of the nervous system (which enables the data feedback loops, the cause of the emergence of consciousness) might be emotion (rather than perception) and that experienced sensations (i.e. qualia) inherently require someone to experience them. On the other hand, there are several kinds of studies of emotions in synthetic environments, such as affective computing or sociable robots. Some authors have also tried to develop computational models of artificial emotions or have drawn attention to the interesting phenomenon of emotions within artificial environments. For the previous reason, this book covers an important area: how to recognize, model and implement emotions, from natural domains to artificial ones. Human-Robot Interaction (henceforth, HRI), for example, is one of the hottest topics in contemporary research: there is a necessity for a better understanding of how both can collaborate and share spaces and actions. The potential readers of this publication can be classified under two main groups: active researchers (those implied actually into artificial emotions as well as related fields like AI, computing, robotics, philosophy, psychology, and so forth) and university students on these or general grades, because this book will not only provide an excellent frame for future researchers but tries at the same time to stimulate young and brilliant students towards the field of synthetic emotions. This publication also provides a solid conceptual frame for scientists and an opportunity for thinkers to develop new research lines for the future of the topic. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Artificial Intelligence
KW  - *Expert Systems
KW  - *Robotics
KW  - Cognition
KW  - Doubt
M3  - doi:10.4018/978-1-4666-7278-9
DO  - 10.4018/978-1-4666-7278-9
ER  -
TY  - CHAP
DESCRIPTORS  - *Decision Making;  *Emotional Control;  *Intelligent Agents; Memory
ID  - 2015-24110-005
T1  - On realizing emotional memories.
T2  - Handbook of research on synthesizing human emotion in intelligent systems and robotics.
T3  - Advances in computational intelligence and robotics (ACIR) book series.
A1  - Singh, Saurabh K.
A1  - Jha, Shashi Shekhar
A1  - Nair, Shivashankar B.
SP  - 116
EP  - 151
Y1  - 2015
CY  - Hershey,  PA,  US
PB  - Information Science Reference/IGI Global
SN  - 978-1-4666-7278-9 (Hardcover); 978-1-4666-7279-6 (Digital (undefined format))
N2  - Emotion and memory have been two intermingled areas in psychological research. Although researchers are still fairly clueless on how human emotions or memory work, several attempts have been made to copy the dynamics of these two entities in the realm of robotics. This chapter describes one such attempt to capture the dynamics of human emotional memories and model the same for use in a real robot. Emotional memories are created at extreme emotional states, namely, very positive or happy events or very negative ones. The positive ones result in the formation of positive memories while the negative ones form the negative counterparts. The robotic system seeks the positive ones while it tries to avoid the negative ones. Such memories aid the system in making the right decisions, especially when situations similar to the one which caused their generation, repeat in the future. This chapter introduces the manner in which a multi-agent emotion engine churns out the emotions which in turn generate emotional memories. Results obtained from simulations and those from using a real situated robot described herein, validate the working of these memories. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Decision Making
KW  - *Emotional Control
KW  - *Intelligent Agents
KW  - Memory
M3  - doi:10.4018/978-1-4666-7278-9.ch005
DO  - 10.4018/978-1-4666-7278-9.ch005
ER  -
TY  - CHAP
DESCRIPTORS  - *Cognition;  *Emotions;  *Robotics;  *Social Interaction; Human Robot Interaction
ID  - 2015-24110-007
T1  - Socially embodied human-robot interaction: Addressing human emotions with theories of embodied cognition.
T2  - Handbook of research on synthesizing human emotion in intelligent systems and robotics.
T3  - Advances in computational intelligence and robotics (ACIR) book series.
A1  - Lindblom, J.
A1  - Alenljung, B.
SP  - 169
EP  - 190
Y1  - 2015
CY  - Hershey,  PA,  US
PB  - Information Science Reference/IGI Global
SN  - 978-1-4666-7278-9 (Hardcover); 978-1-4666-7279-6 (Digital (undefined format))
N2  - A fundamental challenge of human interaction with socially interactive robots, compared to other interactive products, comes from them being embodied. The embodied nature of social robots questions to what degree humans can interact ‘naturally’ with robots, and what impact the interaction quality has on the user experience (UX). UX is fundamentally about emotions that arise and form in humans through the use of technology in a particular situation. This chapter aims to contribute to the field of human-robot interaction (HRI) by addressing, in further detail, the role and relevance of embodied cognition for human social interaction, and consequently what role embodiment can play in HRI, especially for socially interactive robots. Furthermore, some challenges for socially embodied interaction between humans and socially interactive robots are outlined and possible directions for future research are presented. It is concluded that the body is of crucial importance in understanding emotion and cognition in general, and, in particular, for a positive user experience to emerge when interacting with socially interactive robots. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Cognition
KW  - *Emotions
KW  - *Robotics
KW  - *Social Interaction
KW  - Human Robot Interaction
M3  - doi:10.4018/978-1-4666-7278-9.ch007
DO  - 10.4018/978-1-4666-7278-9.ch007
ER  -
TY  - CHAP
DESCRIPTORS  - *Emotional States;  *Intention;  *Robotics; Engineering
ID  - 2015-24110-012
T1  - Intention and body-mood engineering via proactive robot moves in HRI.
T2  - Handbook of research on synthesizing human emotion in intelligent systems and robotics.
T3  - Advances in computational intelligence and robotics (ACIR) book series.
A1  - Görür, O. Can
A1  - Erkmen, Aydan M.
SP  - 255
EP  - 282
Y1  - 2015
CY  - Hershey,  PA,  US
PB  - Information Science Reference/IGI Global
SN  - 978-1-4666-7278-9 (Hardcover); 978-1-4666-7279-6 (Digital (undefined format))
N2  - This chapter focuses on emotion and intention engineering by socially interacting robots that induce desired emotions/intentions in humans. The authors provide all phases that pave this road, supported by overviews of leading works in the literature. The chapter is partitioned into intention estimation, human body-mood detection through external-focused attention, path planning through mood induction and reshaping intention. Moreover, the authors present their novel concept, with implementation, of reshaping current human intention into a desired one, using contextual motions of mobile robots. Current human intention has to be deviated towards the new desired one by destabilizing the obstinance of human intention, inducing positive mood and making the “robot gain curiosity of human”. Deviations are generated as sequences of transient intentions tracing intention trajectories. The authors use elastic networks to generate, in two modes of body mood: “confident” and “suspicious”, transient intentions directed towards the desired one, choosing among intentional robot moves previously learned by HMM. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Emotional States
KW  - *Intention
KW  - *Robotics
KW  - Engineering
M3  - doi:10.4018/978-1-4666-7278-9.ch012
DO  - 10.4018/978-1-4666-7278-9.ch012
ER  -
TY  - CHAP
DESCRIPTORS  - *Caregivers;  *Constructivism;  *Emotional Intelligence; Robotics
ID  - 2015-24110-015
T1  - Developing robot emotions through interaction with caregivers.
T2  - Handbook of research on synthesizing human emotion in intelligent systems and robotics.
T3  - Advances in computational intelligence and robotics (ACIR) book series.
A1  - Lim, Angelica
A1  - Okuno, Hiroshi G.
SP  - 316
EP  - 337
Y1  - 2015
CY  - Hershey,  PA,  US
PB  - Information Science Reference/IGI Global
SN  - 978-1-4666-7278-9 (Hardcover); 978-1-4666-7279-6 (Digital (undefined format))
N2  - In this chapter, the authors explore social constructivist theories of emotion, which suggest that emotional behaviors are developed through experience, rather than innate. The authors’ approach to artificial emotions follows this paradigm, stemming from a relatively young field called developmental or ‘epigenetic’ robotics. The chapter describes the design and implementation of a robot called MEI (multimodal emotional intelligence) with an emotion development system. MEI synchronizes to humans through voice and movement dynamics, based on mirror mechanism-like entrainment. Via typical caregiver interactions, MEI associates these dynamics with its physical feeling, e.g. distress (low battery or excessive motor heat) or flourishing (homeostasis). Our experimental results show that emotion clusters developed through robot-directed motherese (“baby talk”) are similar to adult happiness and sadness, giving evidence to constructivist theories. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Caregivers
KW  - *Constructivism
KW  - *Emotional Intelligence
KW  - Robotics
M3  - doi:10.4018/978-1-4666-7278-9.ch015
DO  - 10.4018/978-1-4666-7278-9.ch015
ER  -
TY  - CHAP
DESCRIPTORS  - *Experience Level;  *Robotics; Social Interaction
ID  - 2015-24110-017
T1  - User experience of socially interactive robots: Its role and relevance.
T2  - Handbook of research on synthesizing human emotion in intelligent systems and robotics.
T3  - Advances in computational intelligence and robotics (ACIR) book series.
A1  - Alenljung, B.
A1  - Lindblom, J.
SP  - 352
EP  - 364
Y1  - 2015
CY  - Hershey,  PA,  US
PB  - Information Science Reference/IGI Global
SN  - 978-1-4666-7278-9 (Hardcover); 978-1-4666-7279-6 (Digital (undefined format))
N2  - Socially interactive robots are expected to have an increasing importance in everyday life for a growing number of people, but negative user experience (UX) can entail reluctance to use robots. Positive user experience underpins proliferation of socially interactive robots. Therefore, it is essential for robot developers to put serious efforts to attain social robots that the users experience as positive. In current human-robot interaction (HRI) research, user experience is reckoned to be important and is used as an argument for stating that something is positive. However, the notion of user experience is noticeably often taken for granted and is neither described nor problematized. By recognizing the complexity of user experience the intended contributions can be even more valuable. Another trend in HRI research is to focus on user experience evaluation and examination of user experience. The current research paths of user experience of socially interactive robots are not enough. This chapter suggests that additional research directions are needed in order accomplish long-term, wide-spread success of socially interactive robots. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Experience Level
KW  - *Robotics
KW  - Social Interaction
M3  - doi:10.4018/978-1-4666-7278-9.ch017
DO  - 10.4018/978-1-4666-7278-9.ch017
ER  -
TY  - CHAP
DESCRIPTORS  - *Apparatus;  *Human Computer Interaction;  *Robotics;  *Human Robot Interaction; Collaboration; Decision Making
ID  - 2014-35586-032
T1  - Just doesn’t look right: Exploring the impact of humanoid robot integration into Explosive Ordnance Disposal teams.
T2  - Handbook of research on technoself: Identity in a technological society, Volumes 1-2
A1  - Carpenter, Julie
SP  - 609
EP  - 636
Y1  - 2013
CY  - Hershey,  PA,  US
PB  - Information Science Reference/IGI Global
SN  - 978-1-4666-2211-1 (Hardcover); 978-1-4666-2212-8 (Digital (undefined format))
N2  - This chapter provides a critical analysis of the potential short- and long-term cultural, emotional, and ethical outcomes facing Explosive Ordnance Disposal (EOD) specialists working closely with anthropomorphic robots in daily team situations as viewed through the interdisciplinary lens of Human-Robot Interaction (HRI) research. Effective small group communication and decision-making is especially critical for EOD teams. Communication failures cause immediate safety concerns, potential physical and psychological harm to EOD team members, and similar repercussions for any individuals in close physical proximity of the Unexploded Ordnance (UXO). The complexity of EOD Team duties, coupled with the inherent limitations of human performance, make it gravely important that technicians have tools that aid rather than hamper team goals. The U.S. Military is seeking a refinement of EOD robot design, including the incorporation of some humanlike characteristics such as biped design, upright walking ability, and responsiveness to human voice and gesture commands. These characteristics can be arguably useful for robots to move in human spaces, learn in a humanlike way, dexterously disarm munitions, and communicate efficiently with human users. But while humanoid design may move the role of the robot to one that becomes potentially more effective in some environments, it may complicate emotional and ethical issues in terms of how human team members view the robot – as an extension of self, an external tool, a team member, a pet, or other entity. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Apparatus
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Human Robot Interaction
KW  - Collaboration
KW  - Decision Making
M3  - doi:10.4018/978-1-4666-2211-1.ch032
DO  - 10.4018/978-1-4666-2211-1.ch032
ER  -
TY  - JOUR
DESCRIPTORS  - *Attribution;  *Prosocial Behavior;  *Robotics;  *Sharing (Social Behavior);  *Anthropomorphism; Emotional States; Emotions; Positive Emotions
ID  - 2022-56137-001
T1  - You, robot? The role of anthropomorphic emotion attributions in children’s sharing with a robot.
JF  - International Journal of Child-Computer Interaction
A1  - Nijssen, Sari R. R.
A1  - Müller, Barbara C. N.
A1  - Bosse, Tibor
A1  - Paulus, Markus
VL  - 30
Y1  - 2021
CY  - Netherlands
AD  - Nijssen, Sari R. R.: Behavioural Science Institute, Radboud University Nijmegen, P.O. Box 9104, Nijmegen, Netherlands, 6500 HE, S.Nijssen@psych.ru.nl
PB  - Elsevier Science
SN  - 2212-8697(Electronic),2212-8689(Print)
N2  - Sharing helps children form and maintain relationships with other children. Yet, children born today interact not only with other children, but increasingly with robots as well. Little is known on whether and how children treat robots as recipients of prosocial acts. We thus investigated children’s sharing behavior towards robots. Specifically, we assessed the effect of anthropomorphic appearance and affective state attributions. Children (4–9 years old; n = 120) were introduced to robots that varied in the extent to which they looked human-like. Children’s perceptions of the robots’ affective states were manipulated by explicitly demonstrating one robot as having feelings and the other one not. Subsequently, children’s sharing behavior towards and feelings about sharing with these robots were measured. Results indicate that there was no effect of anthropomorphic appearance on sharing behavior. However, importantly, children in both age groups shared more resources with a robot that they attributed with affective states, and expressed more positive emotional judgments about sharing with that robot as well. An exploratory mediation analysis further revealed that children’s positive feelings about sharing guided their actual sharing behavior with robots. In sum, children show more pro-social behavior when they believe a robot can feel. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Attribution
KW  - *Prosocial Behavior
KW  - *Robotics
KW  - *Sharing (Social Behavior)
KW  - *Anthropomorphism
KW  - Emotional States
KW  - Emotions
KW  - Positive Emotions
M3  - doi:10.1016/j.ijcci.2021.100319
DO  - 10.1016/j.ijcci.2021.100319
ER  -
TY  - CHAP
DESCRIPTORS  - *Human Computer Interaction;  *Nonverbal Communication;  *Verbal Communication;  *Emotion Recognition;  *Human Robot Interaction; Gestures
ID  - 2013-44492-008
T1  - The role of context in affective behavior understanding.
T2  - Social emotions in nature and artifact.
T3  - Oxford series on cognitive models and architecture.
A1  - Morency, Louis-Philippe
SP  - 128
EP  - 142
Y1  - 2014
CY  - New York,  NY,  US
PB  - Oxford University Press
SN  - 978-0-19-538764-3 (Hardcover)
N2  - This chapter argues that it is possible to significantly improve state-of-the art recognition techniques by exploiting regularities in how people communicate. People do not provide affective feedback at random. Rather, they react to the current topic, previous utterances, and the speaker's current verbal and nonverbal behavior. For example, listeners are far more likely to nod or shake if the speaker has just asked them a question, and incorporating such dialogue context can improve recognition performance during human-robot interaction. More generally, speakers and listeners coproduce a range of lexical, prosodic, and nonverbal patterns. Our goal is to automatically discover these patterns using only easily observable features of human face-to-face interaction (e.g., prosodic features and eye gaze), and exploit them to improve recognition accuracy. This chapter shows that the recognition of affective gestures can be improved by considering the behaviors of other participants in the conversation. Specifically, it shows that the multimodal context from the current speaker can improve the visual recognition of listener gestures. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Human Computer Interaction
KW  - *Nonverbal Communication
KW  - *Verbal Communication
KW  - *Emotion Recognition
KW  - *Human Robot Interaction
KW  - Gestures
ER  -
TY  - JOUR
ID  - 2021-90181-001
T1  - Emotion and memory model for social robots: A reinforcement learning based behaviour selection.
JF  - Behaviour & Information Technology
A1  - Ahmad, Muneeb Imtiaz
A1  - Gao, Yuan
A1  - Alnajjar, Fady
A1  - Shahid, Suleman
A1  - Mubin, Omar
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2021
CY  - United Kingdom
AD  - Ahmad, Muneeb Imtiaz: muneeb.ahmad@westernsydney.edu.au
PB  - Taylor & Francis
SN  - 1362-3001(Electronic),0144-929X(Print)
N2  -  In this paper, we propose a reinforcement learning (RL) mechanism for social robots to select an action based on users’ learning performance and social engagement. We applied this behavior selection mechanism to extend the emotion and memory model, which allows a robot to create a memory account of the user’s emotional events and adapt its behavior based on the developed memory. We evaluated the model in a vocabulary-learning task at a school during a children’s game involving robot interaction to see if the model results in maintaining engagement and improving vocabulary learning across the four different interaction sessions. Generally, we observed positive findings based on child vocabulary learning and sustaining social engagement during all sessions. Compared to the trends of a previous study, we observed a higher level of social engagement across sessions in terms of the duration of the user gaze toward the robot. For vocabulary retention, we saw similar trends in general but also showing high vocabulary retention across some sessions. The findings indicate the benefits of applying RL techniques that have a reward system based on multi-modal user signals or cues. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
M3  - doi:10.1080/0144929X.2021.1977389
DO  - 10.1080/0144929X.2021.1977389
ER  -
TY  - CHAP
DESCRIPTORS  - *Human Computer Interaction;  *Psychology;  *Technology; Decision Making; Emotions; Robotics
ID  - 2014-32529-008
T1  - Psychological aspects of technology interacting with humans.
T2  - The handbook of the psychology of communication technology.
T3  - Handbooks in communication and media.
A1  - Hoorn, Johan F.
SP  - 176
EP  - 201
Y1  - 2015
CY  - Hoboken,  NJ,  US
PB  - Wiley Blackwell
SN  - 978-1-118-41336-4 (Hardcover); 978-1-118-42652-4 (Digital (undefined format))
N2  - This chapter describes a large number of sometimes complex studies that in unison have led to the production of a reliable, serviceable sometimes stern but fair care robot. The initial summary of studies is necessary to understand what the smart, sensitive, creative, and moral humanoid that interacts with its human user is actually based upon: Its core is driven by the model called Perceiving and Experiencing Fictional Characters (PEFiC), the interactive variant of which (I-PEFiC) received a module to make affective decisions (ADM). An integration of I-PEFICADM with prevailing emotion models led to the Silicon Coppélia model. Silicon Coppélia, then, was extended by a system for moral reasoning (Moral Coppélia) and is now in the process to become creative (ACASIA) and have an understanding of reality in contrast to fiction (Epistemics of the Virtual). (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Human Computer Interaction
KW  - *Psychology
KW  - *Technology
KW  - Decision Making
KW  - Emotions
KW  - Robotics
M3  - doi:10.1002/9781118426456.ch8
DO  - 10.1002/9781118426456.ch8
ER  -
TY  - BOOK
DESCRIPTORS  - *Emotions;  *Interdisciplinary Research; Species Differences
ID  - 2012-29710-000
T1  - Emotions of animals and humans: Comparative perspectives.
T2  - Emotions of animals and humans: Comparative perspectives.
T3  - The science of the mind.
A2  - Watanabe, Shigeru
A2  - Kuczaj, Stan
SP  - xiii, 283
EP  - xiii, 283
Y1  - 2013
CY  - New York,  NY,  US
AD  - Watanabe, Shigeru: Department of Psychology, Keio University, 2-15-45 Mita, Minato-ku, Tokyo, Japan, 108-8345
PB  - Springer Science + Business Media
SN  - 978-4-431-54123-3 (PDF); 978-4-431-54122-6 (Hardcover)
N2  - Emotions of Animals and Humans: Comparative Perspectives takes a multidisciplinary approach to emotion, with contributions from biologists, psychologists, neuroscientists, robot engineers, and artists. A wide range of emotional phenomena is discussed, including the notion that humans' sophisticated sensibility, as evidenced by our aesthetic appreciation of the arts, is based at least in part on a basic emotional sensibility that is found in young children and perhaps even some non-human animal species. As a result, this book comprises a unique comparative perspective on the study of emotion. A number of chapters consider emotions in a variety of animal groups, including fish, birds, and mammals. Other chapters expand the scope of the book to humans and robots. Specific topics covered in these chapters run the gamut from lower-level emotional activity, such as emotional expression, to higher-level emotional activity, such as altruism, love, and aesthetics. Taken as a whole, the book presents manifold perspectives on emotion and provides a solid foundation for future multidisciplinary research on the nature of emotions. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Emotions
KW  - *Interdisciplinary Research
KW  - Species Differences
ER  -
TY  - CHAP
DESCRIPTORS  - *Childhood Development;  *Cybernetics;  *Theory of Mind;  *Cognitive Neuroscience; Emotional Development; Robotics; Social Cognition; Mentalization
ID  - 2012-29710-009
T1  - The development of mentalizing and emotion in human children.
T2  - Emotions of animals and humans: Comparative perspectives.
T3  - The science of the mind.
A1  - Itakura, Shoji
A1  - Moriguchi, Yusuke
A1  - Morita, Tomoyo
SP  - 207
EP  - 222
Y1  - 2013
CY  - New York,  NY,  US
AD  - Itakura, Shoji: Department of Psychology, Graduate School of Letters, Kyoto University, Yoshida-honmachi, Sakyo-Ku, Kyoto, Japan, 6068501, sitakura@bun.kyoto-u.ac.jp
PB  - Springer Science + Business Media
SN  - 978-4-431-54123-3 (PDF); 978-4-431-54122-6 (Hardcover)
N2  - For human infants, agents—defined as other humans—are the fundamental units of their social world. Agents provide very special stimuli to infants. Researchers of object-person differentiation have proposed a set of rules that infants probably use during their interaction with people as opposed to objects. This chapter reviews investigations into how children understand and detect both human and nonhuman agents and communicate with them, starting with a definition of mentalizing and summary of the course of its development. A study is presented on infant imitation of a robot's action and a false-belief task with robots, proposing a new research domain called "developmental cybernetics," which studies the interaction between children and robots. It has been predicted that in ordinary twenty-first-century households, robotics technology will be as common as refrigerators and dishwashers. Therefore, exploring developmental cybernetics is important. Finally, two more studies from the perspective of cognitive neuroscience are presented, with a discussion on the usefulness of the neurocognitive approach in understanding the development of mentalizing, alongside two studies concerned with this issue. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Childhood Development
KW  - *Cybernetics
KW  - *Theory of Mind
KW  - *Cognitive Neuroscience
KW  - Emotional Development
KW  - Robotics
KW  - Social Cognition
KW  - Mentalization
ER  -
TY  - CHAP
DESCRIPTORS  - *Artificial Intelligence;  *Emotions;  *Human Machine Systems;  *Industrial and Organizational Psychology;  *Shame; Cognitive Ability; Morality
ID  - 2022-06586-025
T1  - Artificial shame in the fourth industrial revolution.
T2  - Shame 4.0: Investigating an emotion in digital worlds and the Fourth Industrial Revolution.
A1  - Oosthuizen, Rudolf M.
SP  - 537
EP  - 554
Y1  - 2021
CY  - Cham,  Switzerland
AD  - Oosthuizen, Rudolf M.: Department of Industrial and Organisational Psychology, University of South Africa, Pretoria, South Africa, oosthrm@unisa.ac.za
PB  - Springer Nature Switzerland AG
SN  - 978-3-030-59526-5 (Hardcover); 978-3-030-59527-2 (Digital (undefined format))
N2  - Futurists predict that a third of jobs that exist today could be taken by smart technology, artificial intelligence, human–robot interaction and algorithms. Robots will handle 52% of current work tasks by 2025—almost twice as many as they currently do. According to the World Economic Forum (2018), rapid changes in machines and algorithms, or computer processes, could create 133 million new roles in place of the 75 million that will be displaced between now and 2022. The Fourth Industrial Revolution is coming, and it is changing almost all aspects of human life, including the cultural context. The objective of the chapter is to present a critical review of shame for artificial cognitive systems, which must or may not be able to interact with human beings in the context of the Fourth Industrial Revolution. However, emotional architectures have been focused on more basic models of emotions, and shame has been neglected in most of research cases by researchers of robotics, computer sciences or artificial intelligence (Vallverdú, 2014). Shame in artificial devices, as well as the culture of future human–machine interactions, is investigated (Brougham & Haar, 2018; Samani, Koh, Saadatian, & Polydorou, 2012). (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Artificial Intelligence
KW  - *Emotions
KW  - *Human Machine Systems
KW  - *Industrial and Organizational Psychology
KW  - *Shame
KW  - Cognitive Ability
KW  - Morality
M3  - doi:10.1007/978-3-030-59527-2_25
DO  - 10.1007/978-3-030-59527-2_25
ER  -
TY  - JOUR
ID  - 2022-79315-001
T1  - Spatio-temporal properties of amused, embarrassed, and pained smiles.
JF  - Journal of Nonverbal Behavior
A1  - Namba, Shushi
A1  - Sato, Wataru
A1  - Matsui, Hiroshi
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - Germany
AD  - Namba, Shushi: shushi.namba@riken.jp
PB  - Springer
SN  - 1573-3653(Electronic),0191-5886(Print)
N2  - Smiles are universal but nuanced facial expressions that are most frequently used in face-to-face communications, typically indicating amusement but sometimes conveying negative emotions such as embarrassment and pain. Although previous studies have suggested that spatial and temporal properties could differ among these various types of smiles, no study has thoroughly analyzed these properties. This study aimed to clarify the spatiotemporal properties of smiles conveying amusement, embarrassment, and pain using a spontaneous facial behavior database. The results regarding spatial patterns revealed that pained smiles showed less eye constriction and more overall facial tension than amused smiles; no spatial differences were identified between embarrassed and amused smiles. Regarding temporal properties, embarrassed and pained smiles remained in a state of higher facial tension than amused smiles. Moreover, embarrassed smiles showed a more gradual change from tension states to the smile state than amused smiles, and pained smiles had lower probabilities of staying in or transitioning to the smile state compared to amused smiles. By comparing the spatiotemporal properties of these three smile types, this study revealed that the probability of transitioning between discrete states could help distinguish amused, embarrassed, and pained smiles. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
M3  - doi:10.1007/s10919-022-00404-7
DO  - 10.1007/s10919-022-00404-7
ER  -
TY  - CHAP
DESCRIPTORS  - *Amygdala;  *Animal Foraging Behavior;  *Fear; Rats
ID  - 2016-38564-005
T1  - Foraging in the face of fear: Novel strategies for evaluating amygdala functions in rats.
T2  - Living without an amygdala.
A1  - Kim, Jeansok J.
A1  - Choi, June-Seek
A1  - Lee, Hongjoo J.
SP  - 129
EP  - 148
Y1  - 2016
CY  - New York,  NY,  US
PB  - The Guilford Press
SN  - 978-1-4625-2594-2 (Hardcover); 978-1-4625-2595-9 (PDF)
N2  - Fear is a defensive mechanism that plays an important role in our lives: It activates organized bodily-behavioral responses that help minimize our exposure to risks. This chapter presents a novel ethobehavioral paradigm to explore foraging behavior in laboratory rats in quantifiable "approach food-avoid predator" situations that simulate the environments in which the adaptive functions of fear evolved. Specifically, animals seeking food in a seminaturalistic apparatus, consisting of a nest and an open area, encountered a "predatory" robot executing a programmed set of threatening actions. All rats instinctively and robustly reacted to the looming robot by fleeing into the safety of the nest and freezing (fear responses). Afterward, the animals emerged from the nest and cautiously approached the food until the surging robot reevoked fear responses. With repeated encounters, however, the success of seizing the food correlated positively with the food-to-robot distance, suggesting that rats use a spatial (or distance) gradient of fear from the locus of the threat. Further experiments revealed that the amygdala bidirectionally regulates rats' foraging behavior in risky environments. Researching fear from functional, mechanistic, and phylogenetic perspectives will likely provide a deeper understanding of this fundamental emotion. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Amygdala
KW  - *Animal Foraging Behavior
KW  - *Fear
KW  - Rats
ER  -
TY  - JOUR
ID  - 2022-31114-001
T1  - How can we best use technology to teach children to regulate emotions? Efficacy of the cognitive reappraisal strategy based on robot versus cartoons versus written statements in regulating test anxiety.
JF  - Journal of Rational-Emotive & Cognitive-Behavior Therapy
A1  - David, Oana A.
A1  - David, Daniel
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - Germany
AD  - David, Oana A.: oanadavid@psychology.ro
PB  - Springer
SN  - 1573-6563(Electronic),0894-9085(Print)
N2  - Test anxiety has a high prevalence in children and is associated with lower academic performance. The main purpose of the current paper was to investigate the efficacy of using technology based tools, in the form of a robotic agent and cartoons, for teaching school aged children functional cognitive reappraisal emotion-regulation strategies for managing test anxiety. Sixty-nine elementary school aged children participated in the current study. Test anxiety was induced and then the children were allocated to the roboRETMAN, the PsyPills (written reappraisal statements), and the wait-list conditions. In the second stage, children in the wait-list received the RETmagic cartoons. Children reported on their anxiety, positive emotions, rational and irrational beliefs. Results show a higher efficacy for the roboRETMAN compared to wait-list in helping children manage their test anxiety, improving their positive emotions and reducing irrational cognitions. This study brings important contributions to the field, given that there is no research done so far investigating most effective means for delivering emotion-regulation strategies in children. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
M3  - doi:10.1007/s10942-021-00440-0
DO  - 10.1007/s10942-021-00440-0
ER  -
TY  - JOUR
DESCRIPTORS  - *Empathy;  *Robotics;  *Human Robot Interaction; Testing; Action Potentials
ID  - 2014-51455-001
T1  - Testing empathy with robots: A model in four dimensions and sixteen items.
JF  - International Journal of Social Robotics
A1  - Tisseron, Serge
A1  - Tordo, Frédéric
A1  - Baddoura, Ritta
VL  - 7
SP  - 97
EP  - 102
Y1  - 2015
CY  - Germany
AD  - Baddoura, Ritta: INSERM U846, Stem-Cell and Brain Research Institute, 18 avenue du Doyen Lepine, Bron, France, 69500, rittabaddoura@yahoo.fr
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - The four-dimensional model of empathy presented in this paper addresses human–human, human–avatar and human–robot interaction, and aims at better understanding the specificities of the empathy that humans might develop towards robots. Its first dimension is auto-empathy and refers to an empathetic relationship with oneself: how can a human directing a robot expand the various components of empathy he feels for himself to this robot? The second is direct empathy: what does a human attribute to a robot in terms of thoughts, emotions, action potentials or even altruism, on the model of what he imagines and attributes to himself? The third dimension is reciprocal empathy that consists of thinking that a robot is able to identify with me, feel or guess my emotions and thoughts, anticipate my actions and wear me assistance if necessary. Finally, the fourth dimension, intersubjective empathy, is about thinking and imagining that a robot can inform me of things—emotions, thoughts that I am likely to experience- that I do not know about myself. Each of these four dimensions includes four different components: (1) Action (empathy of action), (2) Emotion (emotional empathy), (3) Cognition (cognitive empathy) and (4) Assistance (empathy of assistance). This theoretical model of empathy in four dimensions and four components defines sixteen items whose relevance will be tested in the near future through comparative experimental research involving human-human and human-robot interaction. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Empathy
KW  - *Robotics
KW  - *Human Robot Interaction
KW  - Testing
KW  - Action Potentials
M3  - doi:10.1007/s12369-014-0268-5
DO  - 10.1007/s12369-014-0268-5
ER  -
TY  - JOUR
ID  - 2020-29671-001
T1  - How physical presence overrides emotional (coping) effects in hri: Testing the transfer of emotions and emotional coping in interaction with a humanoid social robot.
JF  - International Journal of Social Robotics
A1  - Spekman, Marloes L. C.
A1  - Konijn, Elly A.
A1  - Hoorn, Johan F.
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2020
CY  - Germany
AD  - Spekman, Marloes L. C.: mlcspekman@gmail.com
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - AbstractThe increasing pressure on healthcare systems calls for innovative solutions, such as social robots. However, healthcare situations often are highly emotional while little is known about how people’s prior emotional state may affect the perception and acceptance of such robots. Following appraisal theories of emotion, the appraisal of coping potential related to one’s emotions was found to be important in acting as mediator between emotional state and perceptions of a robot (Spekman et al. in Comput Hum Behav 85:308–318, 2018. 10.1016/j.chb.2018.03.043; in Belief in emotional coping ability affects what you see in a robot, not the emotions as such, Dissertation, Vrije Universiteit Amsterdam, Amsterdam, 2018), though this has not yet been tested in relation to actual emotional coping nor in an actual encounter with a robot. Hence, the current study focused on how actual emotional coping influences subsequent robot perceptions in two experiments. In Study 1 (N = 101) and Study 2 (N = 110) participants encountered a real humanoid robot after a manipulation to induce various emotions and coping potential. Manipulations in both studies were effective, yet the results in Study 1 were potentially confounded by a novelty effect of participants’ first encounter with a real robot that talked to them. Therefore, in Study 2, participants interacted briefly with the robot before the actual experiment. Results showed an interaction effect of prior emotions and (manipulated) coping potential on robot perceptions, but not the effects expected based on previous studies. An actual interaction with a robot thus seems to provoke different reactions to the robot, thereby overruling any emotional effects. These findings are discussed in light of the healthcare context in which these social robots might be deployed. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
M3  - doi:10.1007/s12369-020-00649-6
DO  - 10.1007/s12369-020-00649-6
ER  -
TY  - JOUR
DESCRIPTORS  - *Facial Expressions;  *Robotics;  *Schizophrenia; Affective Valence
PMID  - 27293136
ID  - 2016-29511-001
T1  - Humanoid robots versus humans: How is emotional valence of facial expressions recognized by individuals with schizophrenia? An exploratory study.
JF  - Schizophrenia Research
A1  - Raffard, Stéphane
A1  - Bortolon, Catherine
A1  - Khoramshahi, Mahdi
A1  - Salesse, Robin N.
A1  - Burca, Marianna
A1  - Marin, Ludovic
A1  - Bardy, Benoit G.
A1  - Billard, Aude
A1  - Macioce, Valérie
A1  - Capdevielle, Delphine
VL  - 176
SP  - 506
EP  - 513
Y1  - 2016
CY  - Netherlands
AD  - Raffard, Stéphane: Laboratory Epsylon, EA 4556, Montpellier University 3, 1 University Department of Adult Psychiatry, 39 Avenue Charles Flahault, Montpellier, France, 34295, Cedex 5
PB  - Elsevier Science
SN  - 1573-2509(Electronic),0920-9964(Print)
N2  - Background: The use of humanoid robots to play a therapeutic role in helping individuals with social disorders such as autism is a newly emerging field, but remains unexplored in schizophrenia. As the ability for robots to convey emotion appear of fundamental importance for human-robot interactions, we aimed to evaluate how schizophrenia patients recognize positive and negative facial emotions displayed by a humanoid robot. Methods: We included 21 schizophrenia outpatients and 17 healthy participants. In a reaction time task, they were shown photographs of human faces and of a humanoid robot (iCub) expressing either positive or negative emotions, as well as a non-social stimulus. Patients' symptomatology, mind perception, reaction time and number of correct answers were evaluated. Results: Results indicated that patients and controls recognized better and faster the emotional valence of facial expressions expressed by humans than by the robot. Participants were faster when responding to positive compared to negative human faces and inversely were faster for negative compared to positive robot faces. Importantly, participants performed worse when they perceived iCub as being capable of experiencing things (experience subscale of the mind perception questionnaire). In schizophrenia patients, negative correlations emerged between negative symptoms and both robot's and human's negative face accuracy. Conclusions: Individuals do not respond similarly to human facial emotion and to non-anthropomorphic emotional signals. Humanoid robots have the potential to convey emotions to patients with schizophrenia, but their appearance seems of major importance for human-robot interactions. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Facial Expressions
KW  - *Robotics
KW  - *Schizophrenia
KW  - Affective Valence
M3  - doi:10.1016/j.schres.2016.06.001
DO  - 10.1016/j.schres.2016.06.001
ER  -
TY  - CHAP
DESCRIPTORS  - *Artificial Intelligence;  *Cognitive Development;  *Cognitive Processes;  *Robotics;  *Systems Design; Abstraction; Creativity
ID  - 2011-27461-008
T1  - From human creative cognitive processes to adaptable artificial system design.
T2  - Attention, representation, and human performance: Integration of cognition, emotion, and motivation.
A1  - Morgavi, Giovanna
A1  - Marconi, Lucia
A1  - Morando, Mauro
A1  - Cutugno, Paola
SP  - 133
EP  - 145
Y1  - 2012
CY  - New York,  NY,  US
PB  - Psychology Press
SN  - 978-1-84872-973-5 (Hardcover)
N2  - Since the year 2000, a number of researchers have suggested a developmental perspective on artificial intelligence (AI) and robotics. One of the fundamental methodological assumptions is that cognition is embodied, which means that it arises from bodily interactions with the world and that it is continuously meshed with them. In other words, thinking emerges from real-life experiences, from sensorimotor coordinated interactions, and from exploration of the surrounding environment. Interdisciplinary theory and empirical evidence are used to inform epigenetic robotic models, and these models can be used as theoretical tools to make experimental predictions in developmental psychology and other disciplines studying cognitive development in living systems. Let us look at a metaphor as an example of abstraction in the linguistic process. It consists of a relationship among meanings that take the context from one world to another. Abstractions not only are grounded in perceptual experience, retaining something of the "perceptual character" of the experiences from which they were derived, but also are a product or reasoning or creative thought. When we speak about "a sea of troubles," we are interested only in a part of the "sea," its dimension, while all the other meanings and images are discarded. With the above in mind, our research questions are as follows: How does the process of metaphor understanding happen in nature? Which procedures allow people to bring out the understanding of the metaphor? What mechanisms are triggered? We studied the modalities through which preschool children (4-5 years old) bring out the understanding of metaphor hidden in common idiomatic sentences in their native language. We chose children of this age because of their level of cognitive development. The cognitive development of children of this age does not include the ability of abstraction, but they are able to explain the process they are thinking. We carried out this experiment in an infant school in the Genoese Municipality, Italy, which had a "Sea Laboratory" where children were accustomed to some sea animal names and some of their characteristics, but they were not in touch with the meaning of the idiomatic sentences requiring an abstract act to be understood. Forty-two phrases were proposed to about eight work groups of 9 or 10 children each; the children were asked to provide abstracted meanings for the phrases. The experimenter read a new sentence and asked for help to find its meaning. Children were allowed to talk, to draw, or to move around the classroom as they liked. The experimenter spurred on the meaning search through neutral communication. The process was recorded, and then we analyzed the answers. Collective speech was analyzed to compensate for individual differences. We collected 6,838 answers and 290 drawings. This output has been analyzed and classified by 4 people. If an answer could be associated with more than one subprocess, each involved subprocess was counted, resulting on 7,230 path instances. Only answers with unanimous classification were accepted; this involved 28 rejections, corresponding to 0.39% of the total instances. Our experiment resulted in some consideration for the architecture of a robot. As in human beings, an efficient developmental architecture shows a hierarchy of basic parallel paths for processing different aspects of knowledge, to let the growing-up phase emerge; an artificial architecture should be able to parallel process a combination of different paths in an internal representation. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Artificial Intelligence
KW  - *Cognitive Development
KW  - *Cognitive Processes
KW  - *Robotics
KW  - *Systems Design
KW  - Abstraction
KW  - Creativity
ER  -
TY  - CHAP
DESCRIPTORS  - *Emotional States;  *Robotics;  *Smiles;  *Taxonomies; Deception; Facial Expressions; Interpersonal Interaction; Messages; Social Environments
ID  - 2008-14110-003
T1  - What's in a robot's smile? The many meanings of positive facial display.
T2  - Animating expressive characters for social interaction.
T3  - Advances in consciousness research.
A1  - LaFrance, Marianne
SP  - 37
EP  - 51
Y1  - 2008
CY  - Amsterdam,  Netherlands
AD  - LaFrance, Marianne: Yale University, Department of Psychology, P.O. Box 208205, New Haven, CT, US, 06520-8205, marianne.lafrance@yale.edu
PB  - John Benjamins Publishing Company
SN  - 978-90-272-5210-4 (Hardcover)
N2  - Offers a valuable corrective to simplistic accounts of the relationship between facial expression and affective state by discussing the example of smiling. The author shows that smiles appear in a variety of forms in order to express a variety of emotions, with only one, the Duchenne smile, unambiguously associated with happiness. Smiles (and other emotion-related facial displays) are not necessarily indicators of internal states, but often act as social messages, e.g. to show others our disposition towards an interaction episode. From the perspective of smiles as volitional social messages, the problem of distinguishing "true" from "fake" smiles holds less relevance than it has traditionally been given. Instead, understanding the meaning of a smile requires understanding the social context in which that smile occurs, and this chapter examines some of the social dimensions that are related to different types of smiles. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Emotional States
KW  - *Robotics
KW  - *Smiles
KW  - *Taxonomies
KW  - Deception
KW  - Facial Expressions
KW  - Interpersonal Interaction
KW  - Messages
KW  - Social Environments
M3  - doi:10.1075/aicr.74.06laf
DO  - 10.1075/aicr.74.06laf
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Human Computer Interaction;  *Pupil Dilation; Robotics
PMID  - 29875722
ID  - 2018-25792-001
T1  - Pupillary responses to robotic and human emotions: The uncanny valley and media equation confirmed.
JF  - Frontiers in Psychology
A1  - Reuten, Anne
A1  - van Dam, Maureen
A1  - Naber, Marnix
VL  - 9
Y1  - 2018
CY  - Switzerland
AD  - Naber, Marnix: marnixnaber@gmail.com
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - Physiological responses during human–robots interaction are useful alternatives to subjective measures of uncanny feelings for nearly humanlike robots (uncanny valley) and comparable emotional responses between humans and robots (media equation). However, no studies have employed the easily accessible measure of pupillometry to confirm the uncanny valley and media equation hypotheses, evidence in favor of the existence of these hypotheses in interaction with emotional robots is scarce, and previous studies have not controlled for low level image statistics across robot appearances. We therefore recorded pupil size of 40 participants that viewed and rated pictures of robotic and human faces that expressed a variety of basic emotions. The robotic faces varied along the dimension of human likeness from cartoonish to humanlike. We strictly controlled for confounding factors by removing backgrounds, hair, and color, and by equalizing low level image statistics. After the presentation phase, participants indicated to what extent the robots appeared uncanny and humanlike, and whether they could imagine social interaction with the robots in real life situations. The results show that robots rated as nearly humanlike scored higher on uncanniness, scored lower on imagined social interaction, evoked weaker pupil dilations, and their emotional expressions were more difficult to recognize. Pupils dilated most strongly to negative expressions and the pattern of pupil responses across emotions was highly similar between robot and human stimuli. These results highlight the usefulness of pupillometry in emotion studies and robot design by confirming the uncanny valley and media equation hypotheses. (PsycINFO Database Record (c) 2020 APA, all rights reserved)
KW  - *Emotions
KW  - *Human Computer Interaction
KW  - *Pupil Dilation
KW  - Robotics
M3  - doi:10.3389/fpsyg.2018.00774
DO  - 10.3389/fpsyg.2018.00774
ER  -
TY  - JOUR
DESCRIPTORS  - *Habits;  *Mathematical Modeling;  *Perceptual Motor Processes; Simulation
PMID  - 25152724
ID  - 2014-52023-001
T1  - Modeling habits as self-sustaining patterns of sensorimotor behavior.
JF  - Frontiers in Human Neuroscience
A1  - Egbert, Matthew D.
A1  - Barandiaran, Xabier E.
VL  - 8
Y1  - 2014
CY  - Switzerland
AD  - Egbert, Matthew D.: Embodied Emotion, Cognition and (Inter-)Action Lab, School of Computer Science, University of Hertfordshire, College Lane, Hatfield, HRT, United Kingdom, AL10 9AB, mde@matthewegbert.com
PB  - Frontiers Media S.A.
SN  - 1662-5161(Electronic)
N2  - [Correction Notice: An Erratum for this article was reported in Vol 9[209] of Frontiers in Human Neuroscience (see record 2015-35773-001). In the original article, Equation 8 is incorrectly written. The correction equation is present in the erratum.] In the recent history of psychology and cognitive neuroscience, the notion of habit has been reduced to a stimulus-triggered response probability correlation. In this paper we use a computational model to present an alternative theoretical view (with some philosophical implications), where habits are seen as self-maintaining patterns of behavior that share properties in common with self-maintaining biological processes, and that inhabit a complex ecological context, including the presence and influence of other habits. Far from mechanical automatisms, this organismic and self-organizing concept of habit can overcome the dominating atomistic and statistical conceptions, and the high temporal resolution effects of situatedness, embodiment and sensorimotor loops emerge as playing a more central, subtle and complex role in the organization of behavior. The model is based on a novel “iterant deformable sensorimotor medium (IDSM),” designed such that trajectories taken through sensorimotor-space increase the likelihood that in the future, similar trajectories will be taken. We couple the IDSM to sensors and motors of a simulated robot, and show that under certain conditions, the IDSM conditions, the IDSM forms self-maintaining patterns of activity that operate across the IDSM, the robot’s body, and the environment. We present various environments and the resulting habits that form in them. The model acts as an abstraction of habits at a much needed sensorimotor “meso-scale” between microscopic neuron-based models and macroscopic descriptions of behavior. Finally, we discuss how this model and extensions of it can help us understand aspects of behavioral self-organization, historicity and autonomy that remain out of the scope of contemporary representationalist frameworks. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Habits
KW  - *Mathematical Modeling
KW  - *Perceptual Motor Processes
KW  - Simulation
M3  - doi:10.3389/fnhum.2014.00590
DO  - 10.3389/fnhum.2014.00590
ER  -
TY  - JOUR
ID  - 2020-89026-001
T1  - asynchronously embedding psychological test questions into human–robot conversations for user profiling.
JF  - International Journal of Social Robotics
A1  - Huang, Tsung-Ren
A1  - Liu, Yu-Wei
A1  - Hsu, Shin-Min
A1  - Goh, Joshua O. S.
A1  - Chang, Yu-Ling
A1  - Yeh, Su-Ling
A1  - Fu, Li-Chen
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2020
CY  - Germany
AD  - Huang, Tsung-Ren: tren@mil.psy.ntu.edu.tw
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - Psychological variables of a person (e.g., cognitive abilities, personality traits, emotional states, and preferences) are valuable information that can be utilized by social robots to offer personalized human–robot interaction. These variables are often latent and inferred indirectly from a third-person perspective based on an individual’s behavioral manifestations (e.g., facial emotion expressions), and hence the true values of inferred psychological variables remain unknown to a robot observer. Although earlier studies have employed robot-administered psychological tests to infer psychological variables based on an individual’s first-person responses, these tests were formally presented and could be tedious to some users. To leverage the validity and reliability of well-established psychological tests for user profiling with ease, the present study examined the possibility of asynchronously embedding psychological test questions into casual human–robot conversations. In our experiment using a big-five personality inventory, the verbal responses from users to these asynchronous test questions were then compared with the written responses to the same personality test. The personality measures estimated from the two approaches correlated strongly in a young adult population but only moderately in an older population. These findings demonstrate the validity of the proposed asynchronous method for psychological testing in human–agent interactions and suggest some caveats when this testing method is applied to older adults or other special populations. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
M3  - doi:10.1007/s12369-020-00716-y
DO  - 10.1007/s12369-020-00716-y
ER  -
TY  - CHAP
DESCRIPTORS  - *Human Computer Interaction;  *Robotics;  *Human Robot Interaction;  *Social Robotics; Emotions; Empathy; Simulation; Computational Modeling
ID  - 2014-43075-021
T1  - Emotion modeling for social robots.
T2  - The Oxford handbook of affective computing.
T3  - Oxford library of psychology.
A1  - Paiva, Ana
A1  - Leite, Iolanda
A1  - Ribeiro, Tiago
SP  - 296
EP  - 308
Y1  - 2015
CY  - New York,  NY,  US
PB  - Oxford University Press
SN  - 978-0-19-994223-7 (Hardcover)
N2  - This chapter describes current advances in emotion modeling for social robots. It begins by contextualizing the role of emotions in social robots, considering the concept of the affective loop. It describes a number of elements for the synthesis and expression of emotions through robotic embodiments and provides an overview of emotional adaptation and empathy in social robots. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Human Robot Interaction
KW  - *Social Robotics
KW  - Emotions
KW  - Empathy
KW  - Simulation
KW  - Computational Modeling
M3  - doi:10.1093/oxfordhb/9780199942237.013.029
DO  - 10.1093/oxfordhb/9780199942237.013.029
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotional Responses;  *Facial Expressions;  *Interspecies Interaction;  *Preschool Students;  *Well Being; Dogs; Insects; Robotics
ID  - 2011-02398-006
T1  - Does it bite? The role of stimuli characteristics on preschoolers' interactions with robots, insects and a dog.
JF  - Anthrozoös
A1  - Howard, Lorraine
A1  - Vick, Sarah-Jane
VL  - 23
SP  - 397
EP  - 413
Y1  - 2010
CY  - United Kingdom
AD  - Howard, Lorraine: School of Psychology and Sports Sciences, Northumbria University, NB155, Newcastle upon Tyne, United Kingdom, NE1 8ST, lorraine.howard@northumbria.ac.uk
PB  - Berg Publishers
SN  - 1753-0377(Electronic),0892-7936(Print)
N2  - While there is increasing interest in the impact of animal interactions upon children's wellbeing and attitudes, there has been less attention paid to the specific characteristics of the animals that attract and engage children. We used a within-subjects design to explore how differences in animal features (such as their animacy, size, and texture) impacted upon pre-school children's social and emotional responses. This study examined pre-schoolers' interactions with two animal-like robots (Teksta and Scoozie), two insect types (stick insects and hissing cockroaches) and a dog (Teasel, a West Highland Terrier). Nineteen preschool participants aged 35-57 months were videoed while interacting with the experimenter, a peer, and each stimulus (presented individually). We used both verbal and nonverbal behaviors to evaluate interactions and emotional responses to the stimuli and found that these two measures could be incongruent, highlighting the need for systematic approaches to evaluating children's interactions with animals. We categorized the content of children's dialogues in relation to psychological and biological attributes of each stimulus and their distinctions between living and non-living stimuli; the majority of comments were biological, with psychological terms largely reserved for the dog and mammal-like robot only. Comments relating to living qualities revealed ambiguity towards attributes that denote differences between living and non-living creatures. We used a range of nonverbal measures, including willingness to approach and touch stimuli, rates of self-touching, facial expressions of emotion, and touch to others. Insects (hissing cockroaches and stick insects) received the most negative verbal and nonverbal responses. The mammal-like robot (rounded, fluffy body shape, large eyes, and sympathetic sounds) was viewed much more positively than its metallic counterpart, as was the real dog. We propose that these interactions provide information on how children perceive animals and a platform for the examination of human socio-emotional and cognitive development more generally. The children engaged in social referencing to the adult experimenter rather than familiar peers when uncertain about the stimuli presented, suggesting that caregivers have a primary role in shaping children's responses to animals. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Emotional Responses
KW  - *Facial Expressions
KW  - *Interspecies Interaction
KW  - *Preschool Students
KW  - *Well Being
KW  - Dogs
KW  - Insects
KW  - Robotics
M3  - doi:10.2752/175303710X12750451259499
DO  - 10.2752/175303710X12750451259499
ER  -
TY  - JOUR
DESCRIPTORS  - *Autism Spectrum Disorders;  *Childhood Development;  *Robotics;  *Treatment Outcomes;  *Socioemotional Functioning; Social Interaction
ID  - 2020-52675-001
T1  - Socio-emotional development in high functioning children with autism spectrum disorders using a humanoid robot.
JF  - Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems
A1  - Soares, Filomena O.
A1  - Costa, Sandra C.
A1  - Santos, Cristina P.
A1  - Pereira, Ana Paula S.
A1  - Hiolle, Antoine R.
A1  - Silva, Vinícius
VL  - 20
SP  - 205
EP  - 233
Y1  - 2019
CY  - Netherlands
AD  - Soares, Filomena O.: Algoritmi Centre, University of Minho, Guimaraes, Portugal, fsoares@dei.uminho.pt
PB  - John Benjamins
SN  - 1572-0381(Electronic),1572-0373(Print)
N2  - The use of robots had already been proven to encourage the promotion of social interaction and skills lacking in children with Autism Spectrum Disorders (ASD), who typically have difficulties in recognizing facial expressions and emotions. The main goal of this research is to study the influence of a humanoid robot to develop socio-emotional skills in children with ASD. The children’s performance in game scenarios aiming to develop facial expressions recognition skills is presented. Along the sessions, children who performed the game scenarios with the robot and the experimenter had a significantly better performance than the children who performed the game scenarios without the robot. The main conclusions of this research support that a humanoid robot is a useful tool to develop socio-emotional skills in the intervention of children with ASD, due to the engagement and positive learning outcome observed. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Autism Spectrum Disorders
KW  - *Childhood Development
KW  - *Robotics
KW  - *Treatment Outcomes
KW  - *Socioemotional Functioning
KW  - Social Interaction
M3  - doi:10.1075/is.15003.cos
DO  - 10.1075/is.15003.cos
ER  -
TY  - CHAP
DESCRIPTORS  - *Emotions;  *Ethics;  *Human Machine Systems Design;  *Parkinson's Disease;  *Robotics; Assistive Technology
ID  - 2016-40474-018
T1  - Reflections on the design challenges prompted by affect-aware socially assistive robots.
T2  - Emotions and personality in personalized services: Models, evaluation and applications.
T3  - Human-computer interaction series.
A1  - Wilson, Jason R.
A1  - Scheutz, Matthias
A1  - Briggs, Gordon
SP  - 377
EP  - 395
Y1  - 2016
CY  - Cham,  Switzerland
AD  - Wilson, Jason R.: Human-Robot Interaction Laboratory, Tufts University, 200 Boston Ave., Medford, MA, US, 02155, wilson@cs.tufts.edu
PB  - Springer International Publishing
SN  - 978-3-319-31411-2 (Hardcover); 978-3-319-31413-6 (Digital (undefined format))
N2  - The rising interest in socially assistive robotics is, at least in part, stemmed by the aging population around the world. A lot of research and interest has gone into insuring the safety of these robots. However, little has been done to consider the necessary role of emotion in these robots and the potential ethical implications of having affect-aware socially assistive robots. In this chapter we address some of the considerations that need to be taken into account in the research and development of robots assisting a vulnerable population. We use two fictional scenarios involving a robot assisting a person with Parkinson's disease to discuss five ethical issues relevant to affect-aware socially assistive robots. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Emotions
KW  - *Ethics
KW  - *Human Machine Systems Design
KW  - *Parkinson's Disease
KW  - *Robotics
KW  - Assistive Technology
M3  - doi:10.1007/978-3-319-31413-6_18
DO  - 10.1007/978-3-319-31413-6_18
ER  -
TY  - CHAP
DESCRIPTORS  - *Artificial Intelligence;  *Emotions;  *Facial Expressions;  *Robotics; Theory of Mind
ID  - 2013-39571-014
T1  - "Emotional" robots and agents—Implementation of emotions in artificial entities.
T2  - Handbook of psychology of emotions (Vol 2): Recent theoretical perspectives and novel empirical findings.
T3  - Psychology of emotions, motivations and actions.
A1  - Krämer, Nicole C.
A1  - Klatt, Jennifer
A1  - Hoffmann, Laura
A1  - Rosenthal-von der Pütten, Astrid
SP  - 277
EP  - 295
Y1  - 2013
CY  - Hauppauge,  NY,  US
PB  - Nova Science Publishers
SN  - 978-1-62618-820-4 (Hardcover); 978-1-62808-131-2 (PDF)
N2  - The chapter summarizes research on emotions in the context of robot and virtual agent development. First, several motives and reasons for the implementation of emotions in artificial entities are presented. Then, a choice of robot and agent systems that model emotion based on various theories and assumptions are described. However, the common practice to implement emotions is also critically reflected against the background of theories on the relation of emotions and facial expressions. Based on this, alternative approaches are presented which implement a theory of mind module instead of emotions. In a second part, humans' emotional reactions to systems with implemented emotions and corresponding facial expressions are described. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Artificial Intelligence
KW  - *Emotions
KW  - *Facial Expressions
KW  - *Robotics
KW  - Theory of Mind
ER  -
TY  - JOUR
DESCRIPTORS  - *Childhood Development;  *Human Computer Interaction;  *Recreation;  *Robotics;  *Human Robot Interaction; Autism Spectrum Disorders; Play Therapy
ID  - 2009-20953-002
T1  - Keepon: A playful robot for research, therapy, and entertainment.
JF  - International Journal of Social Robotics
A1  - Kozima, Hideki
A1  - Michalowski, Marek P.
A1  - Nakagawa, Cocoro
VL  - 1
SP  - 3
EP  - 18
Y1  - 2009
CY  - Germany
AD  - Kozima, Hideki: School of Project Design, Miyagi University, Gakuen 1, Taiwa, Kurokawa, Miyagi, Japan, 981-3298, xkozima@myu.ac.jp
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - Keepon is a small creature-like robot designed for simple, natural, nonverbal interaction with children. The minimal design of Keepon's appearance and behavior is meant to intuitively and comfortably convey the robot's expressions of attention and emotion. For the past few years, we have been observing interactions between Keepon and children at various levels of physical, mental, and social development. With typically developing children, we have observed varying styles of play that suggest a progression in ontological understanding of the robot. With children suffering from developmental disorders such as autism, we have observed interactive behaviors that suggest Keepon's design is effective in eliciting a motivation to share mental states. Finally, in developing technology for interpersonal coordination and interactional synchrony, we have observed an important role of rhythm in establishing engagement between people and robots. This paper presents a comprehensive survey of work done with Keepon to date. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Childhood Development
KW  - *Human Computer Interaction
KW  - *Recreation
KW  - *Robotics
KW  - *Human Robot Interaction
KW  - Autism Spectrum Disorders
KW  - Play Therapy
M3  - doi:10.1007/s12369-008-0009-8
DO  - 10.1007/s12369-008-0009-8
ER  -
TY  - JOUR
DESCRIPTORS  - *Computer Assisted Instruction;  *English as Second Language;  *Pronunciation;  *Vocabulary;  *Mobile Devices; Auditory Stimulation; Pictorial Stimuli; Stereoscopic Presentation
ID  - 2019-05801-003
T1  - A holographic mobile-based application for practicing pronunciation of basic English vocabulary for Spanish speaking children.
JF  - International Journal of Human-Computer Studies
A1  - Cerezo, Rebeca
A1  - Calderón, Vicente
A1  - Romero, Cristóbal
VL  - 124
SP  - 13
EP  - 25
Y1  - 2019
CY  - Netherlands
AD  - Romero, Cristóbal: Department of Computer Sciences and Numerical Analysis, University of Cordoba, Cordoba, Spain, 14071, cromero@uco.es
PB  - Elsevier Science
SN  - 1095-9300(Electronic),1071-5819(Print)
N2  - This paper describes a holographic mobile-based application designed to help Spanish-speaking children to practice the pronunciation of basic English vocabulary words. The mastery of vocabulary is a fundamental step when learning a language but is often perceived as boring. Producing the correct pronunciation is frequently regarded as the most difficult and complex skill for new learners of English. In order to address these problems this research takes advantage of the power of multi-channel stimuli (sound, image and interaction) in a mobile-based hologram application in order to motivate students and improve their experience of practicing. We adapted the prize-winning HolograFX game and developed a new mobile application to help practice English pronunciation. A 3D holographic robot that acts as a virtual teacher interacts via voice with the children. To test the tool we carried out an experiment with 70 Spanish pre-school children divided into three classes, the control group using traditional methods such as images in books and on the blackboard, and two experimental groups using our drills and practice software. One experimental group used the mobile application without the holographic game and the other experimental group used the application with the holographic game. We performed pre-test and post-test performance assessments, a satisfaction survey and emotion analysis. The results are very promising. They show that the use of the holographic mobile-based application had a significant impact on the children's motivation. It also improved their performance compared to traditional methods used in the classroom. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Computer Assisted Instruction
KW  - *English as Second Language
KW  - *Pronunciation
KW  - *Vocabulary
KW  - *Mobile Devices
KW  - Auditory Stimulation
KW  - Pictorial Stimuli
KW  - Stereoscopic Presentation
M3  - doi:10.1016/j.ijhcs.2018.11.009
DO  - 10.1016/j.ijhcs.2018.11.009
ER  -
TY  - THES
DESCRIPTORS  - *Computer Assisted Instruction;  *Mathematics Education;  *Robotics;  *Student Engagement; Tutoring
ID  - 2018-40527-126
T1  - Ms. An (meeting students' academic needs): A socially adaptive robot tutor for student engagement in math education.
A1  - Liles, Karina
VL  - 79
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2018
CY  - US
PB  - ProQuest Information & Learning
SN  - 0419-4217(Print)
N2  - This research presents a new, socially adaptive robot tutor, Ms. An ( Meeting Students' Academic N eeds). The goal of this research was to use a decision tree model to develop a socially adaptive robot tutor that predicted and responded to student emotion and performance to actively engage students in mathematics education. The novelty of this multi-disciplinary project is the combination of the fields of HRI, AI, and education. In this study we 1) implemented a decision tree model to classify student emotion and performance for use in adaptive robot tutoring-an approach not applied to educational robotics; 2) presented an intuitive interface for seamless robot operation by novice users; and 3) applied direct human teaching methods (guided practice and progress monitoring) for a robot tutor to engage students in mathematics education. Twenty 4th and 5th grade students in rural South Carolina participated in a between subjects study with two conditions: A) with a non-adaptive robot (control group); and B) with a socially adaptive robot (adaptive group). Students engaged in two one-on-one tutoring sessions to practice multiplication per the South Carolina 4th and 5 th grade mathematics state standards. Although our decision tree models were not very predictive, the results gave answers to our current questions and clarity for future directions. Our adaptive strategies to engage students academically were effective. Further, all students enjoyed working with the robot and we did not see a difference in emotional engagement across the two groups. This study offered insight for developing a socially adaptive robot tutor to engage students academically and emotionally while practicing multiplication. Results from this study will inform the human-robot interaction (HRI) and artificial intelligence (AI) communities on best practices and techniques within the scope of this work. (PsycINFO Database Record (c) 2018 APA, all rights reserved)
KW  - *Computer Assisted Instruction
KW  - *Mathematics Education
KW  - *Robotics
KW  - *Student Engagement
KW  - Tutoring
ER  -
TY  - CHAP
DESCRIPTORS  - *Artificial Intelligence;  *Emotions; Robotics
ID  - 2020-78979-003
T1  - The evolution is now: Service robots, behavioral bias and emotions.
T2  - Emotions and service in the digital age.
T3  - Research on emotion in organizations.
A1  - Letheren, Kate
A1  - Russell-Bennett, Rebekah
A1  - Whittaker, Lucas
A1  - Whyte, Stephen
A1  - Dulleck, Uwe
SP  - 27
EP  - 48
Y1  - 2020
CY  - Bingley,  United Kingdom
PB  - Emerald Publishing
SN  - 9781839092602 (Hardcover); 978-1-83909-259-6 (Digital (undefined format)); 978-1-83909-261-9 (EPUB)
N2  - Purpose: The purpose of this chapter is to conduct a critical literature review that examines the origins and development of research on service robots in organizations, as well as the key emotional and cognitive issues between service employees, customers, and robots. This review provides a foundation for future research that leverages the emotional connection between service robots and humans. Design/Methodology/Approach: A critical literature review that examines robotics, artificial intelligence, emotions, approach/avoid behavior, and cognitive biases is conducted. Findings: This research provides six key themes that emerge from the current state of research in the field of service robotics with 14 accompanying research questions forming the basis of a research agenda. The themes presented are as follows: Theme 1: Employees have a forgotten “dual role”; Theme 2: The influence of groups is neglected; Theme 3: Opposing emotions lead to uncertain outcomes; Theme 4: We know how robots influence engagement, but not experience; Theme 5: Trust is necessary but poorly understood; and Theme 6: Bias is contagious: if the human mind is irrational...so too are robot minds. Practical Implications: Practically, this research provides guidance for researchers and practitioners alike regarding the current state of research, gaps, and future directions. Importantly for practitioners, it sheds light on themes in the use of AI and robotics in services, highlighting opportunities to consider the dual role of the employee, examines how incorporating a service robot influences all levels of the organization, addresses motivational conflicts for employees and customers, explores how service robots influence the whole customer experience and how trust is formed, and how we are (often inad- vertently) creating biased robots. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Artificial Intelligence
KW  - *Emotions
KW  - Robotics
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Language;  *Negative Transfer;  *Human Robot Interaction;  *Social Robotics; Emergency Services; Acute Stress
ID  - 2017-40848-010
T1  - Perceiving emotions in robot body language: Acute stress heightens sensitivity to negativity while attenuating sensitivity to arousal.
JF  - Computers in Human Behavior
A1  - Thimmesch-Gill, Zane
A1  - Harder, Kathleen A.
A1  - Koutstaal, Wilma
VL  - 76
SP  - 59
EP  - 67
Y1  - 2017
CY  - Netherlands
AD  - Thimmesch-Gill, Zane: Department of Psychology, University of Minnesota, 75 East River Road, S514 Elliott Hall, Minneapolis, MN, US, 55455, thimm009@umn.edu
PB  - Elsevier Science
SN  - 1873-7692(Electronic),0747-5632(Print)
N2  - Reliance on socioemotional assistive robots is projected to increase, yet little is known about how our ability to perceive their emotional expression is impacted by psychological factors. In high-risk and high-tension domains such as emergency services and healthcare, how might the cognitive and physiological stress we are experiencing influence how we read a humanoid robot's nonverbally conveyed emotions? Using a novel paradigm, we asked participants under experimentally-induced acute stress vs. low stress to evaluate a set of normed emotional body language poses conveyed by a physically-present vs. virtually-instantiated humanoid robot. Participants rated each pose for emotional valence (negativity/positivity) and arousal (calm/excited). Acute stress increased the perception of negative valence in negative high arousal poses, consistent with stress-induced hypervigilance. Surprisingly, stress diminished the perception of arousal in high arousal poses, whereas repeated presentation of the low arousal poses increased perception of arousal. Participants rated emotion similarly for the physically-present vs. virtually-present robot, although positively-valenced poses conveyed by the physical robot were perceived as more positive and more animate. We propose that perceptions of emotional arousal may be especially vulnerable to context effects and misattribution. These findings have implications for how assistive robots can best be designed for high-risk and high-tension contexts. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Emotions
KW  - *Language
KW  - *Negative Transfer
KW  - *Human Robot Interaction
KW  - *Social Robotics
KW  - Emergency Services
KW  - Acute Stress
M3  - doi:10.1016/j.chb.2017.06.036
DO  - 10.1016/j.chb.2017.06.036
ER  -
TY  - THES
DESCRIPTORS  - *Cognitive Appraisal;  *Emotions; Robotics
ID  - 2008-99040-597
T1  - Applying the appraisal theory of emotion to human-agent interaction.
A1  - Pepe, Aaron A.
VL  - 68
SP  - 5619
EP  - 5619
Y1  - 2008
CY  - US
PB  - ProQuest Information & Learning
SN  - 0419-4217(Print)
N2  - Autonomous robots are increasingly being used in everyday life; cleaning our floors, entertaining us and supplementing soldiers in the battlefield. As emotion is a key ingredient in how we interact with others, it is important that our emotional interaction with these new entities be understood. This dissertation proposes using the appraisal theory of emotion (Roseman, Scherer, Schorr, & Johnstone, 2001) to investigate how we understand and evaluate situations involving this new breed of robot. This research involves two studies; in the first study an experimental method was used in which participants interacted with a live dog, a robotic dog or a non-anthropomorphic robot to attempt to accomplish a set of tasks. The appraisals of motive consistent/motive inconsistent (the task was performed correctly/incorrectly) and high/low perceived control (the teammate was well trained/not well trained) were manipulated to show the practicality of using appraisal theory as a basis for human robot interaction studies. Robot form was investigated for its influence on emotions experienced. Finally, the influence of high and low control on the experience of positive emotions caused by another was investigated. Results show that a human - robot live interaction test bed is a valid way to influence participants' appraisals. Manipulation checks of motive consistent/motive inconsistent, high/low perceived control and the proper appraisal of cause were significant. Form was shown to influence both the positive and negative emotions experienced, the more lifelike agents were rated higher in positive emotions and lower in negative emotions. The emotion gratitude was shown to be greater during conditions of low control when the entities performed correctly, suggesting that more experiments should be conducted investigating agent caused motive-conducive events. A second study was performed with participants evaluating their reaction to a hypothetical story. In this story they were interacting with either a human, robotic dog, or robot to complete a task. These three agent types and high/low perceived control were manipulated with all stories ending successfully. Results indicated that gratitude and appreciation are sensitive to the manipulation of agent type. It is suggested that, based on the results of these studies, the emotion gratitude should be added to Roseman et al. (2001) appraisal theory to describe the emotion felt during low-control, motive-consistent, other-caused events. These studies have also shown that the appraisal theory of emotion is useful in the study of human-robot and human-animal interactions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Cognitive Appraisal
KW  - *Emotions
KW  - Robotics
ER  -
TY  - THES
DESCRIPTORS  - *Autism Spectrum Disorders;  *Pediatrics;  *Robotics; Social Skills
ID  - 2018-52508-032
T1  - Effectiveness and acceptability of a robot-based social skills intervention for children with autism spectrum disorder.
A1  - Koch, Sarah A.
VL  - 80
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2019
CY  - US
PB  - ProQuest Information & Learning
SN  - 0419-4217(Print)
N2  - This study examined the effectiveness, feasibility, and acceptability of a robot- based intervention program designed to improve social-emotional skills in school-age children with Autism Spectrum Disorder (ASD). Twenty-two children with ASD and mild-to-no cognitive impairment were randomized to intervention (n = 11) or waitlist control groups (n = 11) for eight weeks. Participants who completed the robot-based intervention displayed decreased overall engagement from baseline to post-intervention, based on an eye-tracking measure. Nonetheless, they reported high favorability ratings at post-intervention, including consistently high ratings of happiness, increased comfort ratings, and only slightly decreased ratings of desire for future interactions across time. Group comparisons indicated significant improvement in overall accuracy for identifying face drawings and photos corresponding with robotic emotional facial expressions for individuals in the intervention group. There were no group differences for amount of socially directed gaze with the robot during baseline and post-intervention sessions. Similarly, there were no group differences over time for generalized affect recognition and theory of mind skills. Taken together, results support the use of the robot-based intervention within this population as a tool for promoting an enjoyable learning environment conducive to skill development. Improved accuracy within the intervention group for matching robotic facial expressions, along with decreased visual engagement at post-intervention, suggests a shift from effortful processing to more automatic responding as a result of training. However, it is unclear whether this skill improvement resulted from learning of specific facts or the development of more generalized emotion decoding and understanding. Given strong baseline scores on robot-specific and generalized measures of emotion knowledge, results suggest that the information presented in the intervention may have been too simplistic for the sample included in the study, and future research will examine the efficacy and ultimate benefit of this tool within other subsets of children with ASD. (PsycINFO Database Record (c) 2018 APA, all rights reserved)
KW  - *Autism Spectrum Disorders
KW  - *Pediatrics
KW  - *Robotics
KW  - Social Skills
ER  -
TY  - JOUR
DESCRIPTORS  - *Human Machine Systems;  *Robotics;  *Simulation; Emotional States
ID  - 2014-54541-001
T1  - Modeling emotion, behavior and context in socially believable robots and ICT interfaces.
JF  - Cognitive Computation
A1  - Esposito, Anna
A1  - Fortunati, Leopoldina
A1  - Lugano, Giuseppe
VL  - 6
SP  - 623
EP  - 627
Y1  - 2014
CY  - Germany
AD  - Esposito, Anna: Department of Psychology and IIASS, Seconda Universita di Napoli, Caserta, Italy, anna.esposito@unina2.it
PB  - Springer
SN  - 1866-9964(Electronic),1866-9956(Print)
N2  - This article discusses about modeling emotion, behavior and context in socially believable robots. The modeling and implementation of sophisticated multimodal software/hardware interfaces is a current scientific challenge of high societal relevance. The main characteristics entailed by these interfaces are being able to interact with people, inferring social, organizational and physical contexts based on sensed data, assisting people with special needs, enhancing elderly health-care assistance, learning and rehabilitation in daily functional activities. The idea to dedicate a special issue of Cognitive Computation to cover the interdisciplinary aspects of human human and human machine interactions was prompted by the author's desire to elicit new guidance in the quest for the implementation of emotionally and socially believable robot and ICT interfaces. The author hopes that this special issue will inspire and stimulate many additional researchers to join us in exploring the implications that socially believable robots and ICT interfaces will have in future societies. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Human Machine Systems
KW  - *Robotics
KW  - *Simulation
KW  - Emotional States
M3  - doi:10.1007/s12559-014-9309-5
DO  - 10.1007/s12559-014-9309-5
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Human Computer Interaction;  *Mind;  *Personality;  *Robotics; Artificial Intelligence; Conscientiousness; Perception; Desire; Agency; Emotion Recognition
ID  - 2022-30881-001
T1  - Mind-reading machines: Distinct user responses to thought-detecting and emotion-detecting robots.
JF  - Technology, Mind, and Behavior
A1  - Grundke, Andrea
A1  - Stein, Jan-Philipp
A1  - Appel, Markus
VL  - 3
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - US
AD  - Grundke, Andrea: Psychology of Communication and New Media, Julius-Maximilians-Universität Würzburg, Oswald-Külpe- Weg 82, Würzburg, Germany, 97074, andrea.grundke@uni-wuerzburg.de
PB  - American Psychological Association
SN  - 2689-0208(Electronic)
N2  - Human-like robots and other systems with artificial intelligence are increasingly capable of recognizing and interpreting the mental processes of their human users. The present research examines how people evaluate these seemingly mind-reading machines based on the well-established distinction of human mind into agency (i.e., thoughts and plans) and experience (i.e., emotions and desires). Theory and research that applied this distinction to human–robot interaction showed that machines with experience were accepted less and were perceived to be eerier than those with agency. Considering that humans are not yet used to having their thoughts read by other entities and might feel uneasy about this notion, we proposed that thought-detecting robots are perceived to be eerier and are generally evaluated more negatively than emotion-detecting robots. Across two pre-registered experiments (N1 = 335, N2 = 536) based on text vignettes about different kinds of mind-detecting robots, we find support for our hypothesis. Furthermore, the effect remained independent of the six HEXACO personality dimensions, except for an unexpected interaction with conscientiousness. Implications and directions for future research are discussed. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Emotions
KW  - *Human Computer Interaction
KW  - *Mind
KW  - *Personality
KW  - *Robotics
KW  - Artificial Intelligence
KW  - Conscientiousness
KW  - Perception
KW  - Desire
KW  - Agency
KW  - Emotion Recognition
M3  - doi:10.1037/tmb0000053
DO  - 10.1037/tmb0000053
ER  -
TY  - JOUR
DESCRIPTORS  - *Face Perception;  *Facial Expressions;  *Happiness;  *Spatial Orientation (Perception); Anger Expression
PMID  - 35839208
ID  - 2022-84367-001
T1  - The spatio-temporal features of perceived-as-genuine and deliberate expressions.
JF  - PLoS ONE
A1  - Namba, Shushi
A1  - Nakamura, Koyo
A1  - Watanabe, Katsumi
VL  - 17
Y1  - 2022
CY  - US
AD  - Namba, Shushi: sushishushi760@gmail.com
PB  - Public Library of Science
SN  - 1932-6203(Electronic)
N2  - Reading the genuineness of facial expressions is important for increasing the credibility of information conveyed by faces. However, it remains unclear which spatio-temporal characteristics of facial movements serve as critical cues to the perceived genuineness of facial expressions. This study focused on observable spatio-temporal differences between perceived-as-genuine and deliberate expressions of happiness and anger expressions. In this experiment, 89 Japanese participants were asked to judge the perceived genuineness of faces in videos showing happiness or anger expressions. To identify diagnostic facial cues to the perceived genuineness of the facial expressions, we analyzed a total of 128 face videos using an automated facial action detection system; thereby, moment-to-moment activations in facial action units were annotated, and nonnegative matrix factorization extracted sparse and meaningful components from all action units data. The results showed that genuineness judgments reduced when more spatial patterns were observed in facial expressions. As for the temporal features, the perceived-as-deliberate expressions of happiness generally had faster onsets to the peak than the perceived-as-genuine expressions of happiness. Moreover, opening the mouth negatively contributed to the perceived-as-genuine expressions, irrespective of the type of facial expressions. These findings provide the first evidence for dynamic facial cues to the perceived genuineness of happiness and anger expressions. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Face Perception
KW  - *Facial Expressions
KW  - *Happiness
KW  - *Spatial Orientation (Perception)
KW  - Anger Expression
M3  - doi:10.1371/journal.pone.0271047
DO  - 10.1371/journal.pone.0271047
ER  -
TY  - BOOK
DESCRIPTORS  - *Achievement;  *Brain;  *Cognitive Processes;  *Mind; Strategies
ID  - 2010-06660-000
T1  - The winner's brain: Eight strategies great minds use to achieve success.
T2  - The winner's brain: Eight strategies great minds use to achieve success.
A1  - Brown, Jeff
A1  - Fenske, Mark
A2  - Neporent, Liz
SP  - viii, 226
EP  - viii, 226
Y1  - 2010
CY  - Cambridge,  MA,  US
PB  - Harvard University Press
SN  - 978-07382-1360-6 (Hardcover)
N2  - What can you learn about success from a robot? Why shouldn't you take a test while wearing red? And how can it be that people who perform poorly on a task often see themselves as being the best? In The Winner's Brain, Harvard-trained brain experts Dr. Jeff Brown and Dr. Mark Fenske explore the surprising science behind motivation, focus, and extraordinary achievement—and why the key to success really is all in your head. Contrary to popular belief, winning in life has little to do with IQ, your circumstances, your financial resources, or even luck. But it has everything to do with creating a failure-resistant brain. Every time you think a thought, feel an emotion, or execute a behavior, your neuro-circuitry changes, and the good news is you can take charge of this process. Throughout the book, dozens of Winners from all walks of life tell their stories. Many are well known, like B. B. King, Laura Linney, and motivational speaker Trisha Meili, the Central Park Jogger. Others are artists and inventors, musicians and business people, an FBI agent, a fighter pilot, even a high-altitude window washer. These insightful interviews further reveal how anyone can change their thinking to improve their life. Fascinating, accessible, and compulsively readable. The Winner's Brain shows you how to unlock your brain's hidden potential to achieve success. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Achievement
KW  - *Brain
KW  - *Cognitive Processes
KW  - *Mind
KW  - Strategies
ER  -
TY  - JOUR
DESCRIPTORS  - *Attribution;  *Emotions; Robotics
PMID  - 25551218
ID  - 2015-04572-001
T1  - Emotion attribution to a non-humanoid robot in different social situations.
JF  - PLoS ONE
A1  - Lakatos, Gabriella
A1  - Gácsi, Márta
A1  - Konok, Veronika
A1  - Brúder, Ildikó
A1  - Bereczky, Boróka
A1  - Korondi, Péter
A1  - Miklósi, Ádám
VL  - 9
Y1  - 2014
CY  - US
AD  - Lakatos, Gabriella: Hungarian Academy of Sciences, Eotvos Lorand University, Comparative Ethology Research Group, Pazmany Peter setany 1/C, Budapest, Hungary, 1117, gabriella.lakatos@gmail.com
PB  - Public Library of Science
SN  - 1932-6203(Electronic)
N2  - In the last few years there was an increasing interest in building companion robots that interact in a socially acceptable way with humans. In order to interact in a meaningful way a robot has to convey intentionality and emotions of some sort in order to increase believability. We suggest that human-robot interaction should be considered as a specific form of inter-specific interaction and that human–animal interaction can provide a useful biological model for designing social robots. Dogs can provide a promising biological model since during the domestication process dogs were able to adapt to the human environment and to participate in complex social interactions. In this observational study we propose to design emotionally expressive behaviour of robots using the behaviour of dogs as inspiration and to test these dog-inspired robots with humans in inter-specific context. In two experiments (wizard-of-oz scenarios) we examined humans’ ability to recognize two basic and a secondary emotion expressed by a robot. In Experiment 1 we provided our companion robot with two kinds of emotional behaviour ("happiness" and "fear"), and studied whether people attribute the appropriate emotion to the robot, and interact with it accordingly. In Experiment 2 we investigated whether participants tend to attribute guilty behaviour to a robot in a relevant context by examining whether relying on the robot’s greeting behaviour human participants can detect if the robot transgressed a predetermined rule. Results of Experiment 1 showed that people readily attribute emotions to a social robot and interact with it in accordance with the expressed emotional behaviour. Results of Experiment 2 showed that people are able to recognize if the robot transgressed on the basis of its greeting behaviour. In summary, our findings showed that dog-inspired behaviour is a suitable medium for making people attribute emotional states to a non-humanoid robot. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Attribution
KW  - *Emotions
KW  - Robotics
M3  - doi:10.1371/journal.pone.0114207
DO  - 10.1371/journal.pone.0114207
ER  -
TY  - CHAP
DESCRIPTORS  - *Emotions;  *Human Factors Engineering;  *Neurosciences;  *Robotics; Behavior; Cognitive Science; Human Computer Interaction; Virtual Reality
ID  - 2007-09206-018
T1  - The role of emotion-inspired abilities in relational robots.
T2  - Neuroergonomics: The brain at work.
T3  - Series in human-technology interaction.
A1  - Breazeal, Cynthia
A1  - Picard, Rosalind
SP  - 275
EP  - 292
Y1  - 2007
CY  - New York,  NY,  US
PB  - Oxford University Press
SN  - 0-19-517761-4 (Hardcover); 978-0-19-517761-9 (Hardcover)
N2  - This chapter presents our motivation and a snapshot of our work to date in building robots with social-emotional skills, inspired by findings in neuroscience, cognitive science, and human behavior. Our primary motivation for building robots with social-emotional-inspired capabilities is to develop "relational robots" and their associated applications in diverse areas such as health, education, or work productivity where the human user derives performance benefit from establishing a kind of social rapport with the robot. We describe some of the future applications for such robots, provide a brief summary of the current capabilities of state-of-the-art socially interactive robots, present recent findings in human-computer interaction, and conclude with a few challenges that we would like to see addressed in future research. Much of what we describe in this chapter cannot be done by most machines today, but we are working to bring about research breakthroughs that will make such things possible. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Emotions
KW  - *Human Factors Engineering
KW  - *Neurosciences
KW  - *Robotics
KW  - Behavior
KW  - Cognitive Science
KW  - Human Computer Interaction
KW  - Virtual Reality
ER  -
TY  - JOUR
DESCRIPTORS  - *Altruism;  *Facial Expressions;  *Human Computer Interaction;  *Robotics;  *Social Influences; Games; Human Robot Interaction
PMID  - 28588520
ID  - 2017-28068-001
T1  - Emotional expression in simple line drawings of a robot's face leads to higher offers in the ultimatum game.
JF  - Frontiers in Psychology
A1  - Terada, Kazunori
A1  - Takeuchi, Chikara
VL  - 8
Y1  - 2017
CY  - Switzerland
AD  - Terada, Kazunori: terada@gifu-u.ac.jp
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - In the present study, we investigated whether expressing emotional states using a simple line drawing to represent a robot’s face can serve to elicit altruistic behavior from humans. An experimental investigation was conducted in which human participants interacted with a humanoid robot whose facial expression was shown on an LCD monitor that was mounted as its head (Study 1). Participants were asked to play the ultimatum game, which is usually used to measure human altruistic behavior. All participants were assigned to be the proposer and were instructed to decide their offer within 1 min by controlling a slider bar. The corners of the robot’s mouth, as indicated by the line drawing, simply moved upward, or downward depending on the position of the slider bar. The results suggest that the change in the facial expression depicted by a simple line drawing of a face significantly affected the participant’s final offer in the ultimatum game. The offers were increased by 13% when subjects were shown contingent changes of facial expression. The results were compared with an experiment in a teleoperation setting in which participants interacted with another person through a computer display showing the same line drawings used in Study 1 (Study 2). The results showed that offers were 15% higher if participants were shown a contingent facial expression change. Together, Studies 1 and 2 indicate that emotional expression in simple line drawings of a robot’s face elicits the same higher offer from humans as a human telepresence does. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Altruism
KW  - *Facial Expressions
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Social Influences
KW  - Games
KW  - Human Robot Interaction
M3  - doi:10.3389/fpsyg.2017.00724
DO  - 10.3389/fpsyg.2017.00724
ER  -
TY  - THES
DESCRIPTORS  - *Decision Making;  *Semi-Structured Interview; Human Technology Interaction
ID  - 2014-99160-517
T1  - The quiet professional: An investigation of U.S. military explosive ordnance disposal personnel interactions with everyday field robots.
A1  - Carpenter, Julie
VL  - 75
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2014
CY  - US
PB  - ProQuest Information & Learning
SN  - 0419-4217(Print)
N2  - This research explores interactions between Explosive Ordnance Disposal (EOD) personnel and the robots used every day. It was designed to richly describe the nuances of these interactions, especially those related to operator emotion associated with the robots. In this study, the EOD human-robot dynamic was investigated by interviewing 23 EOD personnel, collecting demographic information, and using one-on-one semi-structured interviews. Study results suggest EOD personnel relationships among peers and team members showed distinct patterns in human-human relationships as part of a Human-Human Interaction Model (HHIM) in terms of expectations of performance, and beliefs, values, and actions, related to their work. Findings described here also suggest performance expectations and other factors of the HHIM of teamwork do not map onto EOD personnel human-robot interactions. However, in some cases there is a tendency for personnel to ascribe human traits to robots, creating nuanced human-technology relationships introduced here as the Robot Accommodation Dilemma (RAD). These findings have implications for future personnel training and the refinement of robot design considerations for EOD and other fields that rely on critical small group communication and decision-making skills. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Decision Making
KW  - *Semi-Structured Interview
KW  - Human Technology Interaction
ER  -
TY  - JOUR
DESCRIPTORS  - *Artificial Intelligence;  *Brain;  *Emotions;  *Robotics; Insight
ID  - 2007-12726-011
T1  - Review of Who needs emotions? The brain meets the robot.
JF  - Philosophical Psychology
A1  - Ledwig, Marion
VL  - 20
SP  - 551
EP  - 555
Y1  - 2007
CY  - United Kingdom
AD  - Ledwig, Marion: University of Nevada, Las Vegas, Department of Philosophy, Box 455028, 4505 Maryland Parkway, Las Vegas, NV, US, 89154-5028, marion.ledwig@unlv.edu
PB  - Taylor & Francis
SN  - 1465-394X(Electronic),0951-5089(Print)
N2  - Reviews the book, Who needs emotions? The brain meets the robot by Jean-Marc Fellous and Michael A. Arbib (see record 2005-03475-000). This book is a cutting-edge research volume. The editors have chosen 12 stimulating new essays on the intersection of brains, emotions, and robotics research, which are divided into four parts: perspectives, brains, robots, and conclusions. I think that this collection of essays is an excellent anthology in terms of cutting-edge research on the brain, and also to a lesser degree in matters of artificial intelligence, I was surprised that the book's title question failed to be sufficiently addressed. Hence, one may get the impression that because most of the book addresses how the brain works, emotions will eventually be reduced to brain functions. So, in general I was a little bit perplexed by the book, because I expected something different from the content given the title. Although the chapters are readable, some of them use medical terminology to a high degree, so that one can expect graduate students to have at least some problems understanding the content; even emotion researchers may encounter some problems in this regard. Nevertheless, I would highly recommend this book because of all the interesting insights into how the brain works with regard to the emotions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Artificial Intelligence
KW  - *Brain
KW  - *Emotions
KW  - *Robotics
KW  - Insight
ER  -
TY  - JOUR
DESCRIPTORS  - *Classroom Environment;  *Emotional Control;  *Emotionality (Personality);  *Human Machine Systems Design;  *Robotics; Facial Expressions; Motion Perception; Social Robotics
ID  - 2013-09573-001
T1  - EMYS—Emotive head of a social robot.
JF  - International Journal of Social Robotics
A1  - Kędzierski, Jan
A1  - Muszyński, Robert
A1  - Zoll, Carsten
A1  - Oleksy, Adam
A1  - Frontkiewicz, Mirela
VL  - 5
SP  - 237
EP  - 249
Y1  - 2013
CY  - Germany
AD  - Muszyński, Robert: Institute of Computer Engineering, Control and Robotics, Wroclaw University of Technology, ul. Janiszewskiego 11/17, Wroclaw, Poland, 50-372, robert.muszynski@pwr.wroc.pl
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - This paper presents the design, control, and emotion expressions capabilities of the robotic head EMYS. The concept of motion control system based on FACS theory is proposed. On the basis of this control system six basics emotions are designed for EMYS head. The proposed head shapes are verified in experiments with participation of children aged 8–12. The results of the experiments, perception of the proposed design, and control system are discussed. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Classroom Environment
KW  - *Emotional Control
KW  - *Emotionality (Personality)
KW  - *Human Machine Systems Design
KW  - *Robotics
KW  - Facial Expressions
KW  - Motion Perception
KW  - Social Robotics
M3  - doi:10.1007/s12369-013-0183-1
DO  - 10.1007/s12369-013-0183-1
ER  -
TY  - CHAP
DESCRIPTORS  - *Automated Information Processing;  *Emotions;  *Experimentation;  *Intention;  *Robotics; Electroencephalography
ID  - 2016-59877-010
T1  - The status of research into intention recognition.
T2  - Improving the quality of life for dementia patients through progressive detection, treatment, and care.
T3  - Advances in psychology, mental health, and behavioral studies (APMHBS) book series.
A1  - Wang, Luyao
A1  - Li, Chunlin
A1  - Wu, Jinglong
SP  - 201
EP  - 221
Y1  - 2017
CY  - Hershey,  PA,  US
PB  - Medical Information Science Reference/IGI Global
SN  - 978-1-522-50925-7 (Hardcover); 978-1-522-50926-4 (Digital (undefined format))
N2  - In recent years, service robots have been widely used in many fields, especially for assisting the elderly and disabled. For example, the medical care of patients with Alzheimer’s disease has become a worldwide problem. Existing service robots with some intelligence quotient can perform actions that are programmed by a human. However, the robot cannot understand human intentions or communicate with people naturally. Understanding the intent of the service object could allow the robot to provide better service. Therefore, the most critical component of human-computer interactions is intention recognition. There are currently many methods by which intention recognition can be achieved, such as EMG, EOG and EEG. In addition, emotion is one of the important factors during intention recognition, and this has been a breakthrough notion. This chapter summarizes the current status of research into intention recognition and gives a brief description of the relationship between emotion and intention. We hope to provide more ideas for optimizing human-computer interactions. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Automated Information Processing
KW  - *Emotions
KW  - *Experimentation
KW  - *Intention
KW  - *Robotics
KW  - Electroencephalography
M3  - doi:10.4018/978-1-5225-0925-7.ch010
DO  - 10.4018/978-1-5225-0925-7.ch010
ER  -
TY  - JOUR
DESCRIPTORS  - *Communication;  *Emotional States;  *Emotions;  *Social Interaction; Speech Development
ID  - 2008-04806-006
T1  - Private emotions versus social interaction: A data-driven approach towards analysing emotion in speech.
JF  - User Modeling and User-Adapted Interaction
A1  - Batliner, Anton
A1  - Steidl, Stefan
A1  - Hacker, Christian
A1  - Nöth, Elmar
VL  - 18
SP  - 175
EP  - 206
Y1  - 2008
CY  - Germany
AD  - Batliner, Anton: Lehrstuhl fur Mustererkennung, FAU Erlangen-Nurnberg, Martensstr. 3, Erlangen, Germany, 91058, batliner@informatik.uni-erlangen.de
PB  - Springer
SN  - 1573-1391(Electronic),0924-1868(Print)
N2  - The 'traditional' first two dimensions in emotion research are VALENCE and AROUSAL. Normally, they are obtained by using elicited, acted data. In this paper, we use realistic, spontaneous speech data from our 'AIBO' corpus (human-robot communication, children interacting with Sony's AIBO robot). The recordings were done in a Wizard-of-Oz scenario: the children believed that AIBO obeys their commands; in fact, AIBO followed a fixed script and often disobeyed. Five labellers annotated each word as belonging to one of eleven emotion-related states; seven of these states which occurred frequently enough are dealt with in this paper. The confusion matrices of these labels were used in a Non-Metrical Multi-dimensional Scaling to display two dimensions; the first we interpret as VALENCE, the second, however, not as AROUSAL but as INTERACTION, i.e., addressing oneself (angry, joyful) or the communication partner (motherese, reprimanding). We show that it depends on the specificity of the scenario and on the subjects' conceptualizations whether this new dimension can be observed, and discuss impacts on the practice of labelling and processing emotional data. Two-dimensional solutions based on acoustic and linguistic features that were used for automatic classification of these emotional states are interpreted along the same lines. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Communication
KW  - *Emotional States
KW  - *Emotions
KW  - *Social Interaction
KW  - Speech Development
M3  - doi:10.1007/s11257-007-9039-4
DO  - 10.1007/s11257-007-9039-4
ER  -
TY  - JOUR
DESCRIPTORS  - *Computer Attitudes;  *Robotics;  *Sciences; Emotions; Engineering Psychology
ID  - 2010-01354-007
T1  - 'Heart Robot', a public engagement project.
JF  - Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems
A1  - Rocks, Claire
A1  - Jenkins, Sarah
A1  - Studley, Matthew
A1  - McGoran, David
VL  - 10
SP  - 427
EP  - 452
Y1  - 2009
CY  - Netherlands
AD  - Rocks, Claire: University of the West of England, Science Communication Unit, Faculty of Health and Life Sciences, Frenchay Campus, Coldharbour Lane, Bristol, United Kingdom, BS16 1QY, Claire.Rocks@uwe.ac.uk
PB  - John Benjamins
SN  - 1572-0381(Electronic),1572-0373(Print)
N2  - Heart Robot was a public engagement project funded by the Engineering and Physical Sciences Research Council (EPSRC). The aim of the project was to challenge cultural perceptions of robots, and to stimulate thought and debate in members of the general public around research in the field of social and emotional robotics. Fusing the traditions of Bunraku puppetry, the technology of animatronics and the field of artificial emotion and social intelligence, Heart Robot presented a series of entertaining, thought-provoking, and moving performances at fourteen events in the south-west region of the UK between May and December 2008. This paper presents a summary of the independent evaluation of the project. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Computer Attitudes
KW  - *Robotics
KW  - *Sciences
KW  - Emotions
KW  - Engineering Psychology
M3  - doi:10.1075/is.10.3.07roc
DO  - 10.1075/is.10.3.07roc
ER  -
TY  - JOUR
PMID  - 35358017
ID  - 2022-51382-001
T1  - The mystery remains: Breadth of attention in flanker and navon tasks unaffected by affective states induced by an appraisal manipulation.
JF  - Cognition and Emotion
A1  - Kolnes, Martin
A1  - Gentsch, Kornelia
A1  - van Steenbergen, Henk
A1  - Uusberg, Andero
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - United Kingdom
AD  - Kolnes, Martin: martin.kolnes@ut.ee
PB  - Taylor & Francis
SN  - 1464-0600(Electronic),0269-9931(Print)
N2  -  Affective effects on breadth of attention have been related to aspects of different components of affective states such as the arousal and valence of affective experience and the motivational intensity of action tendency. As none of these explanations fully aligns with existing evidence, we hypothesised that affective effects on breadth of attention may arise from the appraisal component of affective states. Based on this reconceptualisation, we tested the effects of conduciveness and power appraisals on two measures of breadth of attention. In two web-based experiments, we manipulated these appraisals in a 2 × 2 design using a game-like arithmetic task where participants could (1) gain or lose rewards (goal conducive vs. obstructive) based on (2) either their action or the actions of a “robot” (high vs. low power). Breadth of attention was assessed using the flanker task (Experiment 1; n = 236) and the Navon task (Experiment 2; n = 215). We found that appraisals did not directly influence breadth of attention even though high power appraisal significantly improved the overall performance in both experiments indicating successful appraisal manipulation. We discuss ways in which these findings inform future efforts to explain the origins of affective effects on attentional breadth. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
M3  - doi:10.1080/02699931.2022.2056580
DO  - 10.1080/02699931.2022.2056580
ER  -
TY  - CHAP
DESCRIPTORS  - *Emotions;  *Neurosciences;  *Robotics;  *Social Cognition;  *Social Neuroscience; Cognitive Neuroscience
ID  - 2005-03475-002
T1  - Could a Robot Have Emotions? Theoretical Perspectives from Social Cognitive Neuroscience.
T2  - Who needs emotions?: The brain meets the robot.
T3  - Series in affective science.
A1  - Adolphs, Ralph
SP  - 9
EP  - 25
Y1  - 2005
CY  - New York,  NY,  US
AD  - Adolphs, Ralph: Division of Humanities and Social Sciences, California Institute of Technology, Pasadena, CA, US, 91125, radolphs@hss.caltech.edu
PB  - Oxford University Press
SN  - 0-19-516619-1 (Hardcover)
N2  - Could a robot have emotions? I begin by dissecting the initial question, and propose that we should attribute emotions and feelings to a system only if it satisfies criteria in addition to mere behavioral duplication. Those criteria require in turn a theory of what emotions and feelings are. Some aspects of emotion depend only on how humans react to observing behavior, some depend additionally on a scientific account of adaptive behavior, and some depend also on how that behavior is internally generated. Roughly, these three aspects correspond to the social communicative, the adaptive/regulatory, and the experiential aspects of emotion. I summarize these aspects in subsequent sections. I conclude with the speculation that robots could certainly interact socially with humans within a restricted domain (they already do), but that correctly attributing emotions and feelings to them would require that robots are situated in the world and constituted internally in respects that are relevantly similar to humans. In particular, if robotics is to be a science that can actually tell us something new about what emotions are, we need to engineer an internal processing architecture that goes beyond merely fooling humans into judging that the robot has emotions. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Emotions
KW  - *Neurosciences
KW  - *Robotics
KW  - *Social Cognition
KW  - *Social Neuroscience
KW  - Cognitive Neuroscience
M3  - doi:10.1093/acprof:oso/9780195166194.001.0001
DO  - 10.1093/acprof:oso/9780195166194.001.0001
ER  -
TY  - CHAP
DESCRIPTORS  - *Animal Models;  *Emotions;  *Motivation; Robotics
ID  - 2005-03475-009
T1  - Moving Up the Food Chain: Motivation and Emotion in Behavior-Based Robots.
T2  - Who needs emotions?: The brain meets the robot.
T3  - Series in affective science.
A1  - Arkin, Ronald C.
SP  - 245
EP  - 269
Y1  - 2005
CY  - New York,  NY,  US
AD  - Arkin, Ronald C.: Mobile Robot Laboratory, College of Computing, Institute of Technology, Atlanta, GA, US, 30332-0280, arkin@cc.gatech.edu
PB  - Oxford University Press
SN  - 0-19-516619-1 (Hardcover)
N2  - This article investigates the relationship between motivations and emotions as evidenced by a broad range of animal models, including humans. Emotions constitute a subset of motivations that provide support for an agent's survival in a complex world. Both motivations and emotions affect behavioral performance, but motivation can additionally lead to the formulation of concrete goal-achieving behavior, whereas emotions are concerned with modulating existing behaviors in support of current activity. My focus is placed on how these models can have utility within the context of working robotic systems. Behavior-based control serves as the primary vehicle through which emotions and motivations are integrated into robots ranging from hexapods to wheeled robots to humanoids. In this framework, motivations and emotions dynamically affect the underlying control of a cybernetic system by altering its underlying behavioral parameters. I review actual robotic examples that have, each in their own way, provided useful environments where questions about emotions and motivations can be addressed. I start with a description of models of the sowbug that provided the first testbed for asking questions about the use of parallel streams of sensory information, goal-oriented behaviors, motivation and emotions, and developmental growth. I then move on in some detail to a model of the praying mantis, in which explicit motivational state variables such as fear, hunger, and sex affect the selection of motivated behaviors. Moving on to more-complex systems, I review the progress made in using attachment theory as a basis for robot exploration. I then describe the attempts at using canine ethology to design doglike robots that use their emotional and motivational states to bond with their human counterparts. Finally, I describe an ongoing modeling effort to address the issue of time varying affect-related phenomena such as personality traits, attitudes, moods, and emotions. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Animal Models
KW  - *Emotions
KW  - *Motivation
KW  - Robotics
M3  - doi:10.1093/acprof:oso/9780195166194.003.0009
DO  - 10.1093/acprof:oso/9780195166194.003.0009
ER  -
TY  - CHAP
DESCRIPTORS  - *Cognitive Processes;  *Emotions;  *Robotics;  *Social Cognition; Artificial Intelligence; Interpersonal Communication
ID  - 2005-03475-010
T1  - Robot emotion: A functional perspective.
T2  - Who needs emotions?: The brain meets the robot.
T3  - Series in affective science.
A1  - Breazeal, Cynthia
A1  - Brooks, Rodney
SP  - 271
EP  - 310
Y1  - 2005
CY  - New York,  NY,  US
AD  - Breazeal, Cynthia: MIT Media Laboratory, 20 Ames Street, E1S-449, Cambridge, MA, US, 02139, cynthia@media.mit.edu
PB  - Oxford University Press
SN  - 0-19-516619-1 (Hardcover)
N2  - Robots are becoming more and more ubiquitous in human environments. The time has come when their ability to intelligently and effectively interact with us needs to match the level of technological sophistication they have already achieved, whether these robots are tools, avatars (human surrogates), partners (as in a team) or cyborg extensions (prostheses). Emotion-inspired mechanisms can improve the way autonomous robots operate in a human environment with people, and can improve the ability of these robots to effectively achieve their own goals. Such goals may be related to accomplishing tasks or satisfying motivations, and they may be achieved either autonomously or in cooperation with a person. In order to do this in a way that is natural for humans, the robot needs to be designed with a social model in mind. We illustrate this concept by describing in detail the design of Kismet, an anthropomorphic robot that interacts with a human in a social way, focusing on its facial and vocal expressions and gaze direction. Kismet's architecture includes a cognitive system that is tightly coupled to a separate emotive system. Each is designed as interacting networks of "specialists" that are activated when specific conditions are met. The cognitive component is responsible for perceiving and interpreting events, and for selecting among a hierarchy of goal-achieving behaviors, in accordance with its current motivational drives. It is primarily concerned with homeostasis and "well being." The emotive system implements eight basic emotions that are proposed to exist across species. It detects those internal and external events that have affective value, and motivates either task-based or communicative behavior to pursue beneficial interactions and to avoid those that are not beneficial by modulating the operation of the cognitive component. When placed in a realistic social setting, these two systems interact to achieve lifelike attention bias, flexible decision making, goal prioritization and persistence, and effective communication where the robot interacts in a natural and intuitive way with the person to achieve its goal (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Cognitive Processes
KW  - *Emotions
KW  - *Robotics
KW  - *Social Cognition
KW  - Artificial Intelligence
KW  - Interpersonal Communication
M3  - doi:10.1093/acprof:oso/9780195166194.003.0010
DO  - 10.1093/acprof:oso/9780195166194.003.0010
ER  -
TY  - JOUR
DESCRIPTORS  - *Attitudes;  *Coping Behavior;  *Emotions;  *Robotics;  *Telemedicine; Evaluation
ID  - 2018-24910-032
T1  - Perceptions of healthcare robots as a function of emotion-based coping: The importance of coping appraisals and coping strategies.
JF  - Computers in Human Behavior
A1  - Spekman, Marloes L. C.
A1  - Konijn, Elly A.
A1  - Hoorn, Johan F.
VL  - 85
SP  - 308
EP  - 318
Y1  - 2018
CY  - Netherlands
AD  - Spekman, Marloes L. C.: De Boelelaan 1105, Amsterdam, Netherlands, 1081 HV, m.spekman@vu.nl
PB  - Elsevier Science
SN  - 1873-7692(Electronic),0747-5632(Print)
N2  - The urgent pressure on healthcare increases the need for understanding how new technology such as social robots may offer solutions. Many healthcare situations are emotionally charged, which likely affects people's perceptions of such robots in healthcare contexts. Thus far however, little attention has been paid to how people's prior emotions may influence their perceptions of the robot. Based on emotional appraisal theories and prior research, we assume that particularly emotional coping appraisals would influence healthcare-robot perceptions. Additionally, we tested effects of actual coping through the use of emotion-focused and problem-focused coping strategies. Hypotheses were tested in a 2 (sad vs. angry) × 2 (hard-to-cope-with vs. easy-to-cope-with) between-subjects experiment, also including a control group. Results (N = 132; age range 18–36) showed that manipulated coping potential indirectly affected perceptions of a healthcare robot via the appraisal of coping potential. Furthermore, positive emotion-focused coping affected perceptions of a healthcare robot positively. Thus, people's healthcare-robot perceptions were affected by how they cope or how they think they can cope with their emotions, rather than by the emotions as such. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Attitudes
KW  - *Coping Behavior
KW  - *Emotions
KW  - *Robotics
KW  - *Telemedicine
KW  - Evaluation
M3  - doi:10.1016/j.chb.2018.03.043
DO  - 10.1016/j.chb.2018.03.043
ER  -
TY  - JOUR
DESCRIPTORS  - *Human Computer Interaction;  *Robotics;  *Anthropomorphism; Emotions; Mind; Outsourcing
PMID  - 24708509
ID  - 2014-12471-006
T1  - Botsourcing and outsourcing: Robot, British, Chinese, and German workers are for thinking—not feeling—jobs.
JF  - Emotion
A1  - Waytz, Adam
A1  - Norton, Michael I.
VL  - 14
SP  - 434
EP  - 444
Y1  - 2014
CY  - US
AD  - Waytz, Adam: Northwestern University, 2001 Sheridan Road, Evanston, IL, US, 60208, a-waytz@kellogg.northwestern.edu
PB  - American Psychological Association
SN  - 1931-1516(Electronic),1528-3542(Print)
N2  - Technological innovations have produced robots capable of jobs that, until recently, only humans could perform. The present research explores the psychology of “botsourcing”—the replacement of human jobs by robots—while examining how understanding botsourcing can inform the psychology of outsourcing—the replacement of jobs in one country by humans from other countries. We test four related hypotheses across six experiments: (1) Given people’s lay theories about the capacities for cognition and emotion for robots and humans, workers will express more discomfort with botsourcing when they consider losing jobs that require emotion versus cognition; (2) people will express more comfort with botsourcing when jobs are framed as requiring cognition versus emotion; (3) people will express more comfort with botsourcing for jobs that do require emotion if robots appear to convey more emotion; and (4) people prefer to outsource cognition- versus emotion-oriented jobs to other humans who are perceived as more versus less robotic. These results have theoretical implications for understanding social cognition about both humans and nonhumans and practical implications for the increasingly botsourced and outsourced economy. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Anthropomorphism
KW  - Emotions
KW  - Mind
KW  - Outsourcing
M3  - doi:10.1037/a0036054
DO  - 10.1037/a0036054
ER  -
TY  - CHAP
DESCRIPTORS  - *Aesthetics;  *Cross Cultural Differences;  *Emotions;  *Robotics;  *Social Robotics; Behavior; Disgust; Language; Morality
ID  - 2016-27240-007
T1  - Physical and moral disgust in socially believable behaving systems in different cultures.
T2  - Toward robotic socially believable behaving systems: Modeling emotions, Vol. I
T3  - Intelligent systems reference library.
A1  - Lewandowska-Tomaszczyk, Barbara
A1  - Wilson, Paul A.
SP  - 105
EP  - 132
Y1  - 2016
CY  - Cham,  Switzerland
AD  - Lewandowska-Tomaszczyk, Barbara: State University of Applied Sciences in Konin, Konin, Poland, blt@uni.lodz.pl
PB  - Springer International Publishing AG
SN  - 978-3-319-31055-8 (Hardcover); 978-3-319-31056-5 (Digital (undefined format))
N2  - The aim of the present study is to use the GRID, online emotions sorting and corpus methodologies to illuminate different types of disgust that an emotion-sensitive socially interacting robot would need to encode and decode in order to competently produce and recognise these and other types of physical, moral and aesthetic types of complex emotions in social settings. We argue that emotions in general, and different types of disgust as an instance of these, differ with respect to the amount of cognitive grounding they need in order to arise and social robots will successfully use such emotions provided they do not only recognise and produce physical, bodily manifestations of emotions, but also have access to large knowledge bases and are able to process situational context clues. The different types of disgust are identified and compared cross-culturally to provide an evaluation of their relative salience. The study also underscores the conceptual viewpoint of emotions as clusters of emotions rather than solitary, individual representations. We argue that such clustering should be at the heart of emotions modelling in social robots. In order to successfully use the emotion of disgust in their interactions with humans, robots need to be sensitive to possible within-culture and cross-culture differences pertaining to such emotions, exemplified by British English and Polish in the present study. Given the centrality of values to the emotion of disgust, robots need to have the capacity to update from a knowledge base and learn from the situational context the set of values for each significant human that they interact with. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Aesthetics
KW  - *Cross Cultural Differences
KW  - *Emotions
KW  - *Robotics
KW  - *Social Robotics
KW  - Behavior
KW  - Disgust
KW  - Language
KW  - Morality
M3  - doi:10.1007/978-3-319-31056-5_7
DO  - 10.1007/978-3-319-31056-5_7
ER  -
TY  - JOUR
DESCRIPTORS  - *Human Computer Interaction;  *Robotics;  *Human Robot Interaction; Constant Time Delay
ID  - 2017-21035-001
T1  - The emotional, cognitive, physiological, and performance effects of variable time delay in robotic teleoperation.
JF  - International Journal of Social Robotics
A1  - Yang, Euijung
A1  - Dorneich, Michael C.
VL  - 9
SP  - 491
EP  - 508
Y1  - 2017
CY  - Germany
AD  - Dorneich, Michael C.: Industrial and Manufacturing Systems Department, Iowa State University, 3004 Black Engineering Building, Ames, IA, US, 50011-2164, dorneich@iastate.edu
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - The effects of intermittent and variable time delay were investigated to understand the cognitive and physical consequences of gaps between an input from an operator and the corresponding feedback response from the system. Time delay has been shown to disrupt task performance in various areas including psychology and telerobotics. Previous research in multiple domains has focused on the performance effects of time delay and overcoming technological limitations that cause time delay. However, robotics researchers have yet to study the effects of variable time delay on specific operator emotions, usability, and physiological activation in teleoperations. This study investigates the influence of variable time delay not only on task performance, but also operator emotions, physiological arousal, cognitive workload, and usability in teleoperation. Time delay was manipulated by introducing lag into the system feedback. Participants were asked to navigate a remote-control robot vehicle through mazes of differing levels of task complexity in a remote location and simultaneously identify targets. Results showed that operator frustration, anger, and workload increased while usability and task performance decreased when intermittent and variable feedback lag was introduced to a robotic navigation task. The effect of the variable time delay was greater than the effect of task complexity. Furthermore, results suggest that the effects are of time delay and task complexity are additive. A better understanding of the emotional experiences of human operators and the corresponding physiological signals is of crucial importance to designing affect-aware robotic systems that have the ability to appropriately mitigate negative operator emotional states. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Human Robot Interaction
KW  - Constant Time Delay
M3  - doi:10.1007/s12369-017-0407-x
DO  - 10.1007/s12369-017-0407-x
ER  -
TY  - JOUR
ID  - 2022-23529-001
T1  - Development of a comprehensive design guideline to evaluate the user experiences of meal-assistance robots considering human-machine social interactions.
JF  - International Journal of Human-Computer Interaction
A1  - Kim, Hyun K.
A1  - Jeong, Heejin
A1  - Park, Jangwoon
A1  - Park, Jaehyun
A1  - Kim, Won-Seok
A1  - Kim, Nahyeong
A1  - Park, Subin
A1  - Paik, Nam-Jong
SP  - No Pagination Specified
EP  - No Pagination Specified
Y1  - 2022
CY  - United Kingdom
AD  - Park, Jaehyun: jaehpark@inu.ac.kr
PB  - Taylor & Francis
SN  - 1532-7590(Electronic),1044-7318(Print)
N2  -  Meal-assistance robots (MARs) help feed meals to users with disabilities or who need help consuming their meals. Although such MARs have been introduced in various fields, guidelines for evaluating MARs are limited. This study aims to develop comprehensive guidelines to assess the user experience (UX) of MAR designs considering its social interaction characteristics between humans and robots. Participants from three groups (patients, doctors, and caregivers) with different perspectives on MARs were recruited and a focus group interview was conducted to collect their UXs with MARs. The three groups showed different UXs with MARs in user interface design, robot arm motion, and safety and mobility. In addition, based on the literature review, eight UX features (usability, emotion, value, naturalness, assistance, acceptance, personality, and culture) are proposed to evaluate MAR interfaces. The proposed comprehensive design guideline will be particularly useful in evaluating and designing the UX of MARs. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
M3  - doi:10.1080/10447318.2021.2009672
DO  - 10.1080/10447318.2021.2009672
ER  -
TY  - JOUR
DESCRIPTORS  - *Consumer Attitudes;  *Human Computer Interaction;  *Human Robot Interaction; Business; Education; Health Care Services; Robotics
PMID  - 27648986
ID  - 2017-01278-025
T1  - Interactions with robots: The truths we reveal about ourselves.
JF  - Annual Review of Psychology
A1  - Broadbent, Elizabeth
VL  - 68
SP  - 627
EP  - 652
Y1  - 2017
CY  - US
AD  - Broadbent, Elizabeth: Department of Psychological Medicine, Faculty of Medical and Health Sciences, University of Auckland, Auckland, New Zealand, 1142, e.broadbent@auckland.ac.nz
PB  - Annual Reviews
SN  - 1545-2085(Electronic),0066-4308(Print)
N2  - In movies, robots are often extremely humanlike. Although these robots are not yet reality, robots are currently being used in healthcare, education, and business. Robots provide benefits such as relieving loneliness and enabling communication. Engineers are trying to build robots that look and behave like humans and thus need comprehensive knowledge not only of technology but also of human cognition, emotion, and behavior. This need is driving engineers to study human behavior toward other humans and toward robots, leading to greater understanding of how humans think, feel, and behave in these contexts, including our tendencies for mindless social behaviors, anthropomorphism, uncanny feelings toward robots, and the formation of emotional attachments. However, in considering the increased use of robots, many people have concerns about deception, privacy, job loss, safety, and the loss of human relationships. Human–robot interaction is a fascinating field and one in which psychologists have much to contribute, both to the development of robots and to the study of human behavior. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Consumer Attitudes
KW  - *Human Computer Interaction
KW  - *Human Robot Interaction
KW  - Business
KW  - Education
KW  - Health Care Services
KW  - Robotics
M3  - doi:10.1146/annurev-psych-010416-043958
DO  - 10.1146/annurev-psych-010416-043958
ER  -
TY  - JOUR
DESCRIPTORS  - *Autism Spectrum Disorders;  *Human Computer Interaction;  *Robotics;  *Emotion Recognition; Human Robot Interaction; Social Robotics
ID  - 2017-28207-001
T1  - A feasibility study evaluating the emotionally expressive robot SAM.
JF  - International Journal of Social Robotics
A1  - Koch, Sarah A.
A1  - Stevens, Carl E.
A1  - Clesi, Christian D.
A1  - Lebersfeld, Jenna B.
A1  - Sellers, Alyssa G.
A1  - McNew, Myriah E.
A1  - Biasini, Fred J.
A1  - Amthor, Franklin R.
A1  - Hopkins, Maria I.
VL  - 9
SP  - 601
EP  - 613
Y1  - 2017
CY  - Germany
AD  - Koch, Sarah A.: Department of Psychology, University of Alabama at Birmingham, Campbell Hall, Suite 415, 1720 2nd Avenue South, Birmingham, AL, US, 35294, sakoch@uab.edu
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - This two-part feasibility study evaluated the functionality and acceptability of Socially Animated Machine (SAM), a humanoid robotic monkey developed to elicit social interaction in children with Autism Spectrum Disorder (ASD). Socially Animated Machine was designed with an approachable, animal-like appearance, while preserving the essential features of a human face. The intent was to design a robot that would be interesting and engaging to children with ASD, yet maintain the capability to model facial expressions that convey emotional subtlety. Study 1 evaluated the accuracy of SAM’s emotional facial expressions. Typically developing children (N = 35 ) labeled and matched SAM’s expressions to photos of human expressions with moderate-to-substantial levels of agreement. Study 2 compared children’s level of social engagement across an interaction with SAM and an interaction with an adult experimenter. Children with ASD (N = 13) spent significantly more time attending to the partner’s face while interacting with SAM. When asked to rate their interaction with SAM, children with ASD reported high levels of happiness and comfort and requested additional interactions. These results suggest that SAM may serve as a useful tool in interventions to improve social skills, including emotion recognition, in children with ASD. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Autism Spectrum Disorders
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Emotion Recognition
KW  - Human Robot Interaction
KW  - Social Robotics
M3  - doi:10.1007/s12369-017-0419-6
DO  - 10.1007/s12369-017-0419-6
ER  -
TY  - JOUR
DESCRIPTORS  - *Autism Spectrum Disorders;  *Childhood Play Behavior;  *Early Intervention;  *Robotics;  *Group Intervention; Drama; Preschool Students; Role Playing
PMID  - 31655965
ID  - 2019-64935-001
T1  - A robot-based play-drama intervention may improve the joint attention and functional play behaviors of Chinese-speaking preschoolers with autism spectrum disorder: A pilot study.
JF  - Journal of Autism and Developmental Disorders
A1  - So, Wing-Chee
A1  - Cheng, Chun-Ho
A1  - Lam, Wan-Yi
A1  - Huang, Ying
A1  - Ng, Ka-Ching
A1  - Tung, Hiu-Ching
A1  - Wong, Wing
VL  - 50
SP  - 467
EP  - 481
Y1  - 2020
CY  - Germany
AD  - So, Wing-Chee: wingchee@cuhk.edu.hk
PB  - Springer
SN  - 1573-3432(Electronic),0162-3257(Print)
N2  - Children with autism spectrum disorder (ASD) have deficits in joint attention and play behaviors. We examined whether a robot-based play-drama intervention would promote these skills. Chinese-speaking preschool children were randomly assigned to an intervention group (N = 12) and a waitlist control group (N = 11). Children in the intervention group watched three robot dramas and engaged in role-plays with both robots and human experimenters over the course of 9 weeks. There were significant improvements in joint attention initiations and functional play behaviors in the intervention group. Parents of this group of children also reported less severe social impairments. It was therefore concluded that a robot-based play-drama intervention can enhance the joint attention and play behaviors of children with ASD. (PsycINFO Database Record (c) 2020 APA, all rights reserved)
KW  - *Autism Spectrum Disorders
KW  - *Childhood Play Behavior
KW  - *Early Intervention
KW  - *Robotics
KW  - *Group Intervention
KW  - Drama
KW  - Preschool Students
KW  - Role Playing
M3  - doi:10.1007/s10803-019-04270-z
DO  - 10.1007/s10803-019-04270-z
ER  -
TY  - JOUR
DESCRIPTORS  - *Economics;  *Robotics;  *Social Interaction; Mind
PMID  - 30072938
ID  - 2018-36920-001
T1  - Mind perception of robots varies with their economic versus social function.
JF  - Frontiers in Psychology
A1  - Wang, Xijing
A1  - Krumhuber, Eva G.
VL  - 9
Y1  - 2018
CY  - Switzerland
AD  - Wang, Xijing: xijing.wang.13@ucl.ac.uk
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - While robots were traditionally built to achieve economic efficiency and financial profits, their roles are likely to change in the future with the aim to provide social support and companionship. In this research, we examined whether the robot’s proposed function (social vs. economic) impacts judgments of mind and moral treatment. Studies 1a and 1b demonstrated that robots with social function were perceived to possess greater ability for emotional experience, but not cognition, compared to those with economic function and whose function was not mentioned explicitly. Study 2 replicated this finding and further showed that low economic value reduced ascriptions of cognitive capacity, whereas high social value resulted in increased emotion perception. In Study 3, robots with high social value were more likely to be afforded protection from harm, and such effect was related to levels of ascribed emotional experience. Together, the findings demonstrate a dissociation between function type (social vs. economic) and ascribed mind (emotion vs. cognition). In addition, the two types of functions exert asymmetric influences on the moral treatment of robots. Theoretical and practical implications for the field of social psychology and human-computer interaction are discussed. (PsycINFO Database Record (c) 2020 APA, all rights reserved)
KW  - *Economics
KW  - *Robotics
KW  - *Social Interaction
KW  - Mind
M3  - doi:10.3389/fpsyg.2018.01230
DO  - 10.3389/fpsyg.2018.01230
ER  -
TY  - JOUR
DESCRIPTORS  - *Adult Attitudes;  *Emotional Regulation;  *Human Computer Interaction;  *Robotics;  *Anthropomorphism; Human Robot Interaction; Social Robotics
PMID  - 28912736
ID  - 2017-39500-001
T1  - Understanding the uncanny: Both atypical features and category ambiguity provoke aversion toward humanlike robots.
JF  - Frontiers in Psychology
A1  - Strait, Megan K.
A1  - Floerke, Victoria A.
A1  - Ju, Wendy
A1  - Maddox, Keith
A1  - Remedios, Jessica D.
A1  - Jung, Malte F.
A1  - Urry, Heather L.
VL  - 8
Y1  - 2017
CY  - Switzerland
AD  - Strait, Megan K.: megan.strait@utrgv.edu
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - Robots intended for social contexts are often designed with explicit humanlike attributes in order to facilitate their reception by (and communication with) people. However, observation of an “uncanny valley”—a phenomenon in which highly humanlike entities provoke aversion in human observers—has lead some to caution against this practice. Both of these contrasting perspectives on the anthropomorphic design of social robots find some support in empirical investigations to date. Yet, owing to outstanding empirical limitations and theoretical disputes, the uncanny valley and its implications for human-robot interaction remains poorly understood. We thus explored the relationship between human similarity and people's aversion toward humanlike robots via manipulation of the agents' appearances. To that end, we employed a picture-viewing task (Nagents = 60) to conduct an experimental test (Nparticipants = 72) of the uncanny valley's existence and the visual features that cause certain humanlike robots to be unnerving. Across the levels of human similarity, we further manipulated agent appearance on two dimensions, typicality (prototypic, atypical, and ambiguous) and agent identity (robot, person), and measured participants' aversion using both subjective and behavioral indices. Our findings were as follows: (1) Further substantiating its existence, the data show a clear and consistent uncanny valley in the current design space of humanoid robots. (2) Both category ambiguity, and more so, atypicalities provoke aversive responding, thus shedding light on the visual factors that drive people's discomfort. (3) Use of the Negative Attitudes toward Robots Scale did not reveal any significant relationships between people's pre-existing attitudes toward humanlike robots and their aversive responding—suggesting positive exposure and/or additional experience with robots is unlikely to affect the occurrence of an uncanny valley effect in humanoid robotics. This work furthers our understanding of both the uncanny valley, as well as the visual factors that contribute to an agent's uncanniness. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Adult Attitudes
KW  - *Emotional Regulation
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Anthropomorphism
KW  - Human Robot Interaction
KW  - Social Robotics
M3  - doi:10.3389/fpsyg.2017.01366
DO  - 10.3389/fpsyg.2017.01366
ER  -
TY  - JOUR
DESCRIPTORS  - *Individual Differences;  *Mind;  *Robotics; Autism Spectrum Disorders
ID  - 2016-00627-002
T1  - The eyes are the window to the uncanny valley: Mind perception, autism and missing souls.
JF  - Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems
A1  - Schein, Chelsea
A1  - Gray, Kurt
VL  - 16
SP  - 173
EP  - 179
Y1  - 2015
CY  - Netherlands
AD  - Gray, Kurt: Department of Psychology, University of North Carolina, Chapel Hill, Chapel Hill, NC, US, 27599, kurtgray@unc.edu
PB  - John Benjamins
SN  - 1572-0381(Electronic),1572-0373(Print)
N2  - Horror movies have discovered an easy recipe for making people creepy: alter their eyes. Instead of normal eyes, zombies’ eyes are vacantly white, vampires’ eyes glow with the color of blood, and those possessed by demons are cavernously black. In the Academy Award winning Pan’s Labyrinth, director Guillermo del Toro created the creepiest of all creatures by entirely removing its eyes from its face, placing them instead in the palms of its hands. The unease induced by altering eyes may help to explain the uncanny valley, which is the eeriness of robots that are almost—but not quite—human (Mori, 1970). Much research has explored the uncanny valley, including the research reported by MacDorman & Entezari (in press), which focuses on individual differences that might predict the eeriness of humanlike robots. In their paper, they suggest that a full understanding of this phenomenon needs to synthesize individual differences with features of the robot. One theory that links these two concepts is mind perception, which past research highlights as essential to the uncanny valley (Gray & Wegner, 2012). Mind perception is linked to both individual differences—autism—and to features of the robot—the eyes—and can provide a deeper understanding of this arresting phenomenon. In this paper, we present original data that links uncanniness to the eyes through aberrant perceptions of mind. (PsycINFO Database Record (c) 2016 APA, all rights reserved)
KW  - *Individual Differences
KW  - *Mind
KW  - *Robotics
KW  - Autism Spectrum Disorders
M3  - doi:10.1075/is.16.2.02sch
DO  - 10.1075/is.16.2.02sch
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Robotics;  *Social Psychology;  *Surveys; Social Robotics
ID  - 2020-49444-001
T1  - From motions to emotions: Can the fundamental emotions be expressed in a robot swarm?
JF  - International Journal of Social Robotics
A1  - Santos, María
A1  - Egerstedt, Magnus
VL  - 13
SP  - 751
EP  - 764
Y1  - 2021
CY  - Germany
AD  - Santos, María: maria.santos@gatech.edu
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - This paper explores the expressive capabilities of a swarm of miniature mobile robots within the context of inter-robot interactions and their mapping to the so-called fundamental emotions. In particular, we investigate how motion and shape descriptors that are psychologically associated with different emotions can be incorporated into different swarm behaviors for the purpose of artistic expositions. Based on these characterizations from social psychology, a set of swarm behaviors is created, where each behavior corresponds to a fundamental emotion. The effectiveness of these behaviors is evaluated in a survey in which the participants are asked to associate different swarm behaviors with the fundamental emotions. The results of the survey show that most of the research participants assigned to each video the emotion intended to be portrayed by design. These results confirm that abstract descriptors associated with the different fundamental emotions in social psychology provide useful motion characterizations that can be effectively transformed into expressive behaviors for a swarm of simple ground mobile robots. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Emotions
KW  - *Robotics
KW  - *Social Psychology
KW  - *Surveys
KW  - Social Robotics
M3  - doi:10.1007/s12369-020-00665-6
DO  - 10.1007/s12369-020-00665-6
ER  -
TY  - JOUR
DESCRIPTORS  - *Behavior Therapy;  *Dementia;  *Intervention;  *Treatment Outcomes;  *Social Robotics; Robotics; Sciences; Technology; Tracking
PMID  - 33361589
ID  - 2021-41878-025
T1  - Social robot interventions for people with dementia: A systematic review on effects and quality of reporting.
JF  - Journal of Alzheimer's Disease
A1  - Hirt, Julian
A1  - Ballhausen, Nicola
A1  - Hering, Alexandra
A1  - Kliegel, Matthias
A1  - Beer, Thomas
A1  - Meyer, Gabriele
VL  - 79
SP  - 773
EP  - 792
Y1  - 2021
CY  - Netherlands
AD  - Hirt, Julian: Center for Dementia Care, Institute of Applied Nursing Sciences, Department of Health, University of Applied Sciences FHS St. Gallen, Rosenbergstrasse 59, St. Gallen, Switzerland, 9000, julian.hirt@ost.ch
PB  - IOS Press
SN  - 1875-8908(Electronic),1387-2877(Print)
N2  - Background: Using non-pharmacological interventions is a current approach in dementia care to manage responsive behaviors, to maintain functional capacity, and to reduce emotional stress. Novel technologies such as social robot interventions might be useful to engage people with dementia in activities and interactions as well as to improve their cognitive, emotional, and physical status. Objective: Assessing the effects and the quality of reporting of social robot interventions for people with dementia. Methods: In our systematic review, we included quasi-experimental and experimental studies published in English, French, or German, irrespective of publication year. Searching CINAHL, Cochrane Library, MEDLINE, PsycINFO, and Web of Science Core Collection was supplemented by citation tracking and free web searching. To assess the methodological quality of included studies, we used tools provided by the Joanna Briggs Institute. To assess the reporting of the interventions, we applied CReDECI 2 and TIDieR. Results: We identified sixteen studies published between 2012 and 2018, including two to 415 participants with mostly non-defined type of dementia. Eight studies had an experimental design. The predominant robot types were pet robots (i.e., PARO). Most studies addressed behavioral, emotion-related, and functional outcomes with beneficial, non-beneficial, and mixed results. Predominantly, cognitive outcomes were not improved. Overall, studies were of moderate methodological quality. Conclusion: Heterogeneous populations, intervention characteristics, and measured outcomes make it difficult to generalize the results with regard to clinical practice. The impact of social robot interventions on behavioral, emotion-related, and functional outcomes should therefore be assessed considering the severity of dementia and intervention characteristics. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Behavior Therapy
KW  - *Dementia
KW  - *Intervention
KW  - *Treatment Outcomes
KW  - *Social Robotics
KW  - Robotics
KW  - Sciences
KW  - Technology
KW  - Tracking
M3  - doi:10.3233/JAD-200347
DO  - 10.3233/JAD-200347
ER  -
TY  - JOUR
DESCRIPTORS  - *Language Development;  *Robotics;  *Storytelling;  *Social Robotics; Emotions; Narratives; Preschool Students
PMID  - 28638330
ID  - 2017-27793-001
T1  - Flat vs. expressive storytelling: Young children’s learning and retention of a social robot’s narrative.
JF  - Frontiers in Human Neuroscience
A1  - Kory Westlund, Jacqueline M.
A1  - Jeong, Sooyeon
A1  - Park, Hae W.
A1  - Ronfard, Samuel
A1  - Adhikari, Aradhana
A1  - Harris, Paul L.
A1  - DeSteno, David
A1  - Breazeal, Cynthia L.
VL  - 11
Y1  - 2017
CY  - Switzerland
AD  - Kory Westlund, Jacqueline M.: jakory@media.mit.edu
PB  - Frontiers Media S.A.
SN  - 1662-5161(Electronic)
N2  - Prior research with preschool children has established that dialogic or active book reading is an effective method for expanding young children’s vocabulary. In this exploratory study, we asked whether similar benefits are observed when a robot engages in dialogic reading with preschoolers. Given the established effectiveness of active reading, we also asked whether this effectiveness was critically dependent on the expressive characteristics of the robot. For approximately half the children, the robot’s active reading was expressive; the robot’s voice included a wide range of intonation and emotion (Expressive). For the remaining children, the robot read and conversed with a flat voice, which sounded similar to a classic text-to-speech engine and had little dynamic range (Flat). The robot’s movements were kept constant across conditions. We performed a verification study using Amazon Mechanical Turk (AMT) to confirm that the Expressive robot was viewed as significantly more expressive, more emotional, and less passive than the Flat robot. We invited 45 preschoolers with an average age of 5 years who were either English Language Learners (ELL), bilingual, or native English speakers to engage in the reading task with the robot. The robot narrated a story from a picture book, using active reading techniques and including a set of target vocabulary words in the narration. Children were post-tested on the vocabulary words and were also asked to retell the story to a puppet. A subset of 34 children performed a second story retelling 4–6 weeks later. Children reported liking and learning from the robot a similar amount in the Expressive and Flat conditions. However, as compared to children in the Flat condition, children in the Expressive condition were more concentrated and engaged as indexed by their facial expressions; they emulated the robot’s story more in their story retells; and they told longer stories during their delayed retelling. Furthermore, children who responded to the robot’s active reading questions were more likely to correctly identify the target vocabulary words in the Expressive condition than in the Flat condition. Taken together, these results suggest that children may benefit more from the expressive robot than from the flat robot. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Language Development
KW  - *Robotics
KW  - *Storytelling
KW  - *Social Robotics
KW  - Emotions
KW  - Narratives
KW  - Preschool Students
M3  - doi:10.3389/fnhum.2017.00295
DO  - 10.3389/fnhum.2017.00295
ER  -
TY  - JOUR
DESCRIPTORS  - *Evaluation;  *Impression Management;  *Psychosocial Development;  *Self-Perception;  *Social Cognition; Attention; Audiences; Early Childhood Development; Experimenters; Perceptual Development; Test Construction; Values
ID  - 2018-41343-012
T1  - Sensitivity to the evaluation of others emerges by 24 months.
JF  - Developmental Psychology
A1  - Botto, Sara Valencia
A1  - Rochat, Philippe
VL  - 54
SP  - 1723
EP  - 1734
Y1  - 2018
CY  - US
AD  - Botto, Sara Valencia: Department of Psychology, Emory University, 36 Eagle Row, Atlanta, GA, US, 30322, sara.botto@emory.edu
PB  - American Psychological Association
SN  - 1939-0599(Electronic),0012-1649(Print)
N2  - Although the human proclivity to engage in impression management and care for reputation is ubiquitous, the question of its developmental outset remains open. In 4 studies, we demonstrate that the sensitivity to the evaluation of others (i.e., evaluative audience perception) is manifest by 24 months. In a first study, 14- to 24-month-old children (N = 49) were tested in situations in which the attention of an audience was systematically manipulated. Results showed that when the experimenter was inattentive, as opposed to attentive, children were more likely to explore an attractive toy. A second study (N = 31) explored whether same-aged children would consider not only the attention of the experimenter but also the values the experimenter expressed for two different outcomes when exploring a toy. We found that children reproduced outcomes that were positively valued by the experimenter significantly more when the experimenter was attentive but were more likely to reproduce negatively valued outcomes when the experimenter was inattentive. A third control study (N = 30) showed that the significant effect of Study 2 disappeared in the absence of different values. Lastly, Study 4 (N = 34) replicated and extended the phenomenon by showing toddler’s propensity to modify their behavior in the presence of 2 different experimenters, depending on both the experimenter’s evaluation of an outcome and their attention. Overall, these data provide the first convergent demonstration of evaluative audience perception in young children that precedes the full-fledged normative, mentalizing, and strong conformity psychology documented in 4- to 5-year-old children. (PsycINFO Database Record (c) 2018 APA, all rights reserved)
KW  - *Evaluation
KW  - *Impression Management
KW  - *Psychosocial Development
KW  - *Self-Perception
KW  - *Social Cognition
KW  - Attention
KW  - Audiences
KW  - Early Childhood Development
KW  - Experimenters
KW  - Perceptual Development
KW  - Test Construction
KW  - Values
M3  - doi:10.1037/dev0000548
DO  - 10.1037/dev0000548
ER  -
TY  - JOUR
DESCRIPTORS  - *Judgment;  *Likability;  *Robotics; Occupations
ID  - 2011-13542-006
T1  - Effects of appearance and functions on likability and perceived occupational suitability of robots.
JF  - Journal of Cognitive Engineering and Decision Making
A1  - Lee, Sau-lai
A1  - Lau, Ivy Yee-man
A1  - Hong, Ying-yi
VL  - 5
SP  - 232
EP  - 250
Y1  - 2011
CY  - US
AD  - Lee, Sau-lai: Division of Psychology, Nanyang Technological University, 14 Nanyang Drive, Singapore, Singapore, 637332, slleeh@ntu.edu.sg
PB  - Sage Publications
SN  - 2169-5032(Electronic),1555-3434(Print)
N2  - This article reports three experiments that examined the association between (a) appearances and perceived capabilities of robots, (b) appearance and capabilities of robots and liking for the robots, and (c) perceived capabilities of robots and judgments concerning their suitability for different occupations. In Experiment 1, the authors found that participants perceived human- and animal-like robots to have relatively more warmth-related (e.g., emotion) capabilities than machinelike robots have. In Experiment 2, the authors found that liking for robots was not affected by their human likeness or their having warmth or competence capabilities. In Experiment 3, participants generally thought that robots should have information-processing and communication capabilities more than sensory and emotion capabilities. More interestingly, participants considered robots with different capabilities to be suitable for different occupations, preferring robots with emotion capabilities more in occupations that require frequent interactions with humans than in occupations that do not. (PsycInfo Database Record (c) 2022 APA, all rights reserved)
KW  - *Judgment
KW  - *Likability
KW  - *Robotics
KW  - Occupations
M3  - doi:10.1177/1555343411409829
DO  - 10.1177/1555343411409829
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Meaning;  *Music Perception;  *Sexual Attitudes;  *Tactual Perception; Human Courtship; Intention; Music; Agency
PMID  - 28846006
ID  - 2017-36462-003
T1  - Blame it on the bossa nova: Transfer of perceived sexiness from music to touch.
JF  - Journal of Experimental Psychology: General
A1  - Fritz, Thomas Hans
A1  - Brummerloh, Berit
A1  - Urquijo, Maria
A1  - Wegner, Katharina
A1  - Reimer, Enrico
A1  - Gutekunst, Sven
A1  - Schneider, Lydia
A1  - Smallwood, Jonathan
A1  - Villringer, Arno
VL  - 146
SP  - 1360
EP  - 1365
Y1  - 2017
CY  - US
AD  - Fritz, Thomas Hans: Max Planck Institute for Human Cognitive and Brain Sciences, Stephanstrasse 1A, Leipzig, Germany, 04103, fritz@cbs.mpg.de
PB  - American Psychological Association
SN  - 1939-2222(Electronic),0096-3445(Print)
N2  - Emotion elicited through music transfers to subsequent processing of facial expressions. Music may accordingly function as a social technology by promoting social bonding. Here, we investigated whether music would cross-modally influence the perception of sensual touch, a behavior related to mating. A robot applied precisely controlled gentle touch to a group of healthy participants while they listened to music that varied with respect to its perceived sexiness. As the perceived sexiness of the music increased, so did the subjective sexiness of the touch stimulations. In short, the perception of sexiness transferred from music to touch. Because sensual touch is key to mating behavior and relates to procreation, this association has implications for the universality and evolutionary significance of music. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Emotions
KW  - *Meaning
KW  - *Music Perception
KW  - *Sexual Attitudes
KW  - *Tactual Perception
KW  - Human Courtship
KW  - Intention
KW  - Music
KW  - Agency
M3  - doi:10.1037/xge0000329
DO  - 10.1037/xge0000329
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotions;  *Anthropomorphism;  *Human Robot Interaction;  *Social Robotics;  *Cognitive Computing; Attribution; Physical Comfort; Robotics; Implicit Attitudes; Online Surveys; Implicit Measures
ID  - 2021-71085-001
T1  - Ascribing emotions to robots: Explicit and implicit attribution of emotions and perceived robot anthropomorphism.
JF  - Computers in Human Behavior
A1  - Spatola, Nicolas
A1  - Wudarczyk, Olga A.
VL  - 124
Y1  - 2021
CY  - Netherlands
AD  - Spatola, Nicolas: Istituto Italiano di Tecnologia, Center for Human Technologies, Via Morego, 30, Genova, Italy, 16163, nicolas.spatola@iit.it
PB  - Elsevier Science
SN  - 1873-7692(Electronic),0747-5632(Print)
N2  - Despite growing literature on various aspects of robot perception by humans, little is still known about how robots' anthropomorphism is perceived at various degrees of conscious perception. In the current study, in two experiments, we assessed whether explicit and implicit attributions of primary and secondary emotions towards robots predict participants' perception of robots' anthropomorphism. In Experiment 1, participants explicitly evaluated whether robots were likely to experience different primary and secondary emotions, followed by the assessment of the level of attributed anthropomorphism towards robots. In Experiment 2, participants completed an adapted version of the Implicit Association Test (IAT), which aimed at implicit evaluation of participants' attribution of different primary and secondary emotions to robots, followed by the assessment of the level of attributed robot anthropomorphism. At the explicit level, attribution of secondary emotions to robots was linked to higher perception of robots' warmth and competence. At the implicit level, participants’ perception of conceptual similarity between robots and humans (i.e. lower difference between attribution of primary and secondary emotions to humans and robots), predicted more anthropomorphic warmth perception and less discomfort towards robots. The current results reveal that implicit and explicit attribution of primary/secondary emotions towards robots predict specific aspects of robot anthropomorphism, with the warmth dimension consistently being predicted across both levels of evaluation. These results shed light on a novel approach to predict various aspects of robot anthropomorphism, which in the future might be useful for evaluations of social robots for their suitability in human-robot interactions. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Emotions
KW  - *Anthropomorphism
KW  - *Human Robot Interaction
KW  - *Social Robotics
KW  - *Cognitive Computing
KW  - Attribution
KW  - Physical Comfort
KW  - Robotics
KW  - Implicit Attitudes
KW  - Online Surveys
KW  - Implicit Measures
M3  - doi:10.1016/j.chb.2021.106934
DO  - 10.1016/j.chb.2021.106934
ER  -
TY  - JOUR
DESCRIPTORS  - *Emotional States;  *Learning;  *Reinforcement;  *Affective Valence;  *Affective Computing; Distress; Fear; Happiness; Hope
ID  - 2015-45612-002
T1  - A reinforcement learning model of joy, distress, hope and fear.
JF  - Connection Science
A1  - Broekens, Joost
A1  - Jacobs, Elmer
A1  - Jonker, Catholijn M.
VL  - 27
SP  - 215
EP  - 233
Y1  - 2015
CY  - United Kingdom
AD  - Broekens, Joost: joost.broekens@gmail.com
PB  - Taylor & Francis
SN  - 1360-0494(Electronic),0954-0091(Print)
N2  - In this paper we computationally study the relation between adaptive behaviour and emotion. Using the reinforcement learning framework, we propose that learned state utility, V(s), models fear (negative) and hope (positive) based on the fact that both signals are about anticipation of loss or gain. Further, we propose that joy/distress is a signal similar to the error signal. We present agent-based simulation experiments that show that this model replicates psychological and behavioural dynamics of emotion. This work distinguishes itself by assessing the dynamics of emotion in an adaptive agent framework—coupling it to the literature on habituation, development, extinction and hope theory. Our results support the idea that the function of emotion is to provide a complex feedback signal for an organism to adapt its behaviour. Our work is relevant for understanding the relation between emotion and adaptation in animals, as well as for human–robot interaction, in particular how emotional signals can be used to communicate between adaptive agents and humans. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Emotional States
KW  - *Learning
KW  - *Reinforcement
KW  - *Affective Valence
KW  - *Affective Computing
KW  - Distress
KW  - Fear
KW  - Happiness
KW  - Hope
M3  - doi:10.1080/09540091.2015.1031081
DO  - 10.1080/09540091.2015.1031081
ER  -
TY  - JOUR
DESCRIPTORS  - *Conflict;  *Emotionality (Personality);  *Robotics;  *Social Integration;  *Voice; Attitudes; Social Acceptance; Emotion Recognition
ID  - 2019-06836-001
T1  - Multimodal integration of emotional signals from voice, body, and context: Effects of (in)congruence on emotion recognition and attitudes towards robots.
JF  - International Journal of Social Robotics
A1  - Tsiourti, Christiana
A1  - Weiss, Astrid
A1  - Wac, Katarzyna
A1  - Vincze, Markus
VL  - 11
SP  - 555
EP  - 573
Y1  - 2019
CY  - Germany
AD  - Tsiourti, Christiana: Automation and Control Institute (ACIN), Vision4Robotics Group, TU Wien, Guhausstrae 27, Vienna, Austria, 1040, christiana.tsiourti@tuwien.ac.at
PB  - Springer
SN  - 1875-4805(Electronic),1875-4791(Print)
N2  - Humanoid social robots have an increasingly prominent place in today’s world. Their acceptance in social and emotional human–robot interaction (HRI) scenarios depends on their ability to convey well recognized and believable emotional expressions to their human users. In this article, we incorporate recent findings from psychology, neuroscience, human–computer interaction, and HRI, to examine how people recognize and respond to emotions displayed by the body and voice of humanoid robots, with a particular emphasis on the effects of incongruence. In a social HRI laboratory experiment, we investigated contextual incongruence (i.e., the conflict situation where a robot’s reaction is incongrous with the socio-emotional context of the interaction) and cross-modal incongruence (i.e., the conflict situation where an observer receives incongruous emotional information across the auditory (vocal prosody) and visual (whole-body expressions) modalities). Results showed that both contextual incongruence and cross-modal incongruence confused observers and decreased the likelihood that they accurately recognized the emotional expressions of the robot. This, in turn, gives the impression that the robot is unintelligent or unable to express “empathic” behaviour and leads to profoundly harmful effects on likability and believability. Our findings reinforce the need of proper design of emotional expressions for robots that use several channels to communicate their emotional states in a clear and effective way. We offer recommendations regarding design choices and discuss future research areas in the direction of multimodal HRI. (PsycInfo Database Record (c) 2021 APA, all rights reserved)
KW  - *Conflict
KW  - *Emotionality (Personality)
KW  - *Robotics
KW  - *Social Integration
KW  - *Voice
KW  - Attitudes
KW  - Social Acceptance
KW  - Emotion Recognition
M3  - doi:10.1007/s12369-019-00524-z
DO  - 10.1007/s12369-019-00524-z
ER  -
TY  - JOUR
DESCRIPTORS  - *Cerebellum;  *Emotions;  *Syndromes;  *Executive Function;  *Sequelae; Oral Communication; Topography; Visuospatial Ability
ID  - 2019-56218-001
T1  - The cerebellar cognitive affective/schmahmann syndrome: A task force paper.
JF  - The Cerebellum
A1  - Argyropoulos, Georgios P. D.
A1  - van Dun, Kim
A1  - Adamaszek, Michael
A1  - Leggio, Maria
A1  - Manto, Mario
A1  - Masciullo, Marcella
A1  - Molinari, Marco
A1  - Stoodley, Catherine J.
A1  - Van Overwalle, Frank
A1  - Ivry, Richard B.
A1  - Schmahmann, Jeremy D.
VL  - 19
SP  - 102
EP  - 125
Y1  - 2020
CY  - Germany
AD  - Argyropoulos, Georgios P. D.: georgios.argyropoulos@ndcn.ox.ac.uk
PB  - Springer
SN  - 1473-4230(Electronic),1473-4222(Print)
N2  - Sporadically advocated over the last two centuries, a cerebellar role in cognition and affect has been rigorously established in the past few decades. In the clinical domain, such progress is epitomized by the “cerebellar cognitive affective syndrome” (“CCAS”) or “Schmahmann syndrome.” Introduced in the late 1990s, CCAS reflects a constellation of cerebellar-induced sequelae, comprising deficits in executive function, visuospatial cognition, emotion–affect, and language, over and above speech. The CCAS thus offers excellent grounds to investigate the functional topography of the cerebellum, and, ultimately, illustrate the precise mechanisms by which the cerebellum modulates cognition and affect. The primary objective of this task force paper is thus to stimulate further research in this area. After providing an up-to-date overview of the fundamental findings on cerebellar neurocognition, the paper substantiates the concept of CCAS with recent evidence from different scientific angles, promotes awareness of the CCAS as a clinical entity, and examines our current insight into the therapeutic options available. The paper finally identifies topics of divergence and outstanding questions for further research. (PsycINFO Database Record (c) 2020 APA, all rights reserved)
KW  - *Cerebellum
KW  - *Emotions
KW  - *Syndromes
KW  - *Executive Function
KW  - *Sequelae
KW  - Oral Communication
KW  - Topography
KW  - Visuospatial Ability
M3  - doi:10.1007/s12311-019-01068-8
DO  - 10.1007/s12311-019-01068-8
ER  -
TY  - JOUR
DESCRIPTORS  - *Cognitive Assessment;  *Emotional Responses;  *Human Computer Interaction;  *Robotics; Human Robot Interaction; Social Robotics
ID  - 2018-40500-001
T1  - Emotional processes in human-robot interaction during brief cognitive testing.
JF  - Computers in Human Behavior
A1  - Desideri, Lorenzo
A1  - Ottaviani, Cristina
A1  - Malavasi, Massimiliano
A1  - di Marzio, Roberto
A1  - Bonifacci, Paola
VL  - 90
SP  - 331
EP  - 342
Y1  - 2019
CY  - Netherlands
AD  - Desideri, Lorenzo: Via Sant’Isaia, 90, Bologna, Italy, 40123, lorenzo.desideri2@unibo.it
PB  - Elsevier Science
SN  - 1873-7692(Electronic),0747-5632(Print)
N2  - With the rapid rise in robot presence in a variety of life domains, understanding how robots influence people's emotions during human-robot interactions is important for ensuring their acceptance in society. Mental health care, in particular, is considered the field in which robotics technology will bring the most dramatic changes in the near future. In this context, the present study sought to determine whether a brief cognitive assessment conducted by a robot elicited different interaction-related emotional processes than a traditional assessment conducted by an expert clinician. A non-clinical sample of 29 young adults (17 females; M = 24.5, SD = 2.3 years) were asked to complete two cognitive tasks twice, in counterbalanced order, once administered by an expert clinician and once by an autonomous humanoid robot. Self-reported measures of affective states and assessment of physiological arousal did not reveal any difference in emotional processes between human-human and human-robot interactions. Similarly, cognitive performances and workload did not differ across conditions. Analysis of non-verbal behaviour, however, showed that participants spent more time looking at the robot (d = 1.3) and made fewer gaze aversions (d = 1.3) in interacting with the robot than with the human examiner. We argue that, far from being a trivial ‘cosmetic change’, using a social robot in place of traditional testing could be a potential way to open up the development of a new generation of tests for brief cognitive assessment. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Cognitive Assessment
KW  - *Emotional Responses
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - Human Robot Interaction
KW  - Social Robotics
M3  - doi:10.1016/j.chb.2018.08.013
DO  - 10.1016/j.chb.2018.08.013
ER  -
TY  - JOUR
DESCRIPTORS  - *Computers;  *Decision Making;  *Human Computer Interaction;  *Robotics;  *Trust (Social Behavior); Compliance; Experience Level; Test Construction
PMID  - 30702316
ID  - 2019-04354-001
T1  - Good advice is beyond all price, but what if it comes from a machine?
JF  - Journal of Experimental Psychology: Applied
A1  - Hertz, Nicholas
A1  - Wiese, Eva
VL  - 25
SP  - 386
EP  - 395
Y1  - 2019
CY  - US
AD  - Hertz, Nicholas: Psychology Department, George Mason University, 4400 University Drive, Fairfax, VA, US, nhertz@gmu.edu
PB  - American Psychological Association
SN  - 1939-2192(Electronic),1076-898X(Print)
N2  - As nonhuman agents are integrated into the workforce, the question becomes to what extent advice seeking in technology-infused environments depends on the perceived fit between agent and task and whether humans are willing to consider advice from nonhuman agents. In this experiment, participants sought advice from human, robot, or computer agents when performing a social or analytical task, with the task being either known or unknown when selecting an agent. In the agent-1st condition, participants 1st chose an adviser and then got their task assignment; in the task-1st condition, participants 1st received the task assignment and then chose an adviser. In the agent-1st condition, we expected participants to prefer human to nonhuman advisers and to subsequently comply more with their advice when they were assigned the social as opposed to the analytical task. In the task-1st condition, we expected advice seeking and compliance to be guided by stereotypical assumptions regarding an agent’s task expertise. The findings indicate that the human was chosen more often than were the nonhuman agents in the agent-1st condition, whereas adviser choices were calibrated based on perceived agent–task fit in the task-1st condition. Compliance rates were not generally calibrated based on agent–task fit. (PsycINFO Database Record (c) 2019 APA, all rights reserved)
KW  - *Computers
KW  - *Decision Making
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Trust (Social Behavior)
KW  - Compliance
KW  - Experience Level
KW  - Test Construction
M3  - doi:10.1037/xap0000205
DO  - 10.1037/xap0000205
ER  -
TY  - JOUR
DESCRIPTORS  - *Cognitive Processes;  *Emotions;  *Human Computer Interaction;  *Robotics;  *Cognitive Control; Classification (Cognitive Process); Decision Making; Judgment
PMID  - 28125254
ID  - 2017-03602-001
T1  - Is that a human? Categorization (dis)fluency drives evaluations of agents ambiguous on human-likeness.
JF  - Journal of Experimental Psychology: Human Perception and Performance
A1  - Carr, Evan W.
A1  - Hofree, Galit
A1  - Sheldon, Kayla
A1  - Saygin, Ayse P.
A1  - Winkielman, Piotr
VL  - 43
SP  - 651
EP  - 666
Y1  - 2017
CY  - US
AD  - Carr, Evan W.: Columbia Business School, 3022 Broadway, 7L Uris, New York, NY, US, 10027, ewcarr@ucsd.edu
PB  - American Psychological Association
SN  - 1939-1277(Electronic),0096-1523(Print)
N2  - A fundamental and seemingly unbridgeable psychological boundary divides humans and nonhumans. Essentialism theories suggest that mixing these categories violates “natural kinds.” Perceptual theories propose that such mixing creates incompatible cues. Most theories suggest that mixed agents, with both human and nonhuman features, obligatorily elicit discomfort. In contrast, we demonstrate top-down, cognitive control of these effects—such that the discomfort with mixed agents is partially driven by disfluent categorization of ambiguous features that are pertinent to the agent. Three experiments tested this idea. Participants classified 3 different agents (humans, androids, and robots) either on the human-likeness or control dimension and then evaluated them. Classifying on the human-likeness dimensions made the mixed agent (android) more disfluent, and in turn, more disliked. Disfluency also mediated the negative affective reaction. Critically, devaluation only resulted from disfluency on human-likeness—and not from an equally disfluent color dimension. We argue that negative consequences on evaluations of mixed agents arise from integral disfluency (on features that are relevant to the judgment at-hand, like ambiguous human-likeness). In contrast, no negative effects stem from incidental disfluency (on features that do not bear on the current judgment, like ambiguous color backgrounds). Overall, these findings support a top-down account of why, when, and how mixed agents elicit conflict and discomfort. (PsycINFO Database Record (c) 2017 APA, all rights reserved)
KW  - *Cognitive Processes
KW  - *Emotions
KW  - *Human Computer Interaction
KW  - *Robotics
KW  - *Cognitive Control
KW  - Classification (Cognitive Process)
KW  - Decision Making
KW  - Judgment
M3  - doi:10.1037/xhp0000304
DO  - 10.1037/xhp0000304
ER  -
TY  - JOUR
DESCRIPTORS  - *Cross Cultural Differences;  *Emotions;  *Robotics; Physical Attractiveness
PMID  - 25762967
ID  - 2016-24225-001
T1  - Walking in the uncanny valley: Importance of the attractiveness on the acceptance of a robot as a working partner.
JF  - Frontiers in Psychology
A1  - Destephe, Matthieu
A1  - Brandao, Martim
A1  - Kishi, Tatsuhiro
A1  - Zecca, Massimiliano
A1  - Hashimoto, Kenji
A1  - Takanishi, Atsuo
VL  - 6
Y1  - 2015
CY  - Switzerland
AD  - Destephe, Matthieu: Department of Modern Mechanical Engineering, Waseda University, Kikuicho Campus 41-5-3F-03/4, 17 Kikuicho, Shinjuku, Tokyo, Japan, matthieu@takanishi.mech.waseda.ac.jp
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - The Uncanny valley hypothesis, which tells us that almost-human characteristics in a robot or a device could cause uneasiness in human observers, is an important research theme in the Human Robot Interaction (HRI) field. Yet, that phenomenon is still not well-understood. Many have investigated the external design of humanoid robot faces and bodies but only a few studies have focused on the influence of robot movements on our perception and feelings of the Uncanny valley. Moreover, no research has investigated the possible relation between our uneasiness feeling and whether or not we would accept robots having a job in an office, a hospital or elsewhere. To better understand the Uncanny valley, we explore several factors which might have an influence on our perception of robots, be it related to the subjects, such as culture or attitude toward robots, or related to the robot such as emotions and emotional intensity displayed in its motion. We asked 69 subjects (N = 69) to rate the motions of a humanoid robot (Perceived Humanity, Eeriness, and Attractiveness) and state where they would rather see the robot performing a task. Our results suggest that, among the factors we chose to test, the attitude toward robots is the main influence on the perception of the robot related to the Uncanny valley. Robot occupation acceptability was affected only by Attractiveness, mitigating any Uncanny valley effect. We discuss the implications of these findings for the Uncanny valley and the acceptability of a robotic worker in our society. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Cross Cultural Differences
KW  - *Emotions
KW  - *Robotics
KW  - Physical Attractiveness
M3  - doi:10.3389/fpsyg.2015.00204
DO  - 10.3389/fpsyg.2015.00204
ER  -
TY  - JOUR
DESCRIPTORS  - *Cognitive Dissonance;  *Cognitive Processes;  *Emotional Responses;  *Perceptual Stimulation;  *Visual Perception; Conflict
PMID  - 25821439
ID  - 2015-34052-001
T1  - Stimulus-category competition, inhibition, and affective devaluation: A novel account of the uncanny valley.
JF  - Frontiers in Psychology
A1  - Ferrey, Anne E.
A1  - Burleigh, Tyler J.
A1  - Fenske, Mark J.
VL  - 6
Y1  - 2015
CY  - Switzerland
AD  - Fenske, Mark J.: Department of Psychology, University of Guelph, Guelph, ON, Canada, N1G 2W1, mfenske@uoguelph.ca
PB  - Frontiers Media S.A.
SN  - 1664-1078(Electronic)
N2  - Stimuli that resemble humans, but are not perfectly human-like, are disliked compared to distinctly human and non-human stimuli. Accounts of this “Uncanny Valley” effect often focus on how changes in human resemblance can evoke different emotional responses. We present an alternate account based on the novel hypothesis that the Uncanny Valley is not directly related to ‘human-likeness’ per se, but instead reflects a more general form of stimulus devaluation that occurs when inhibition is triggered to resolve conflict between competing stimulus-related representations. We consider existing support for this inhibitory-devaluation hypothesis and further assess its feasibility through tests of two corresponding predictions that arise from the link between conflict-resolving inhibition and aversive response: (1) that the pronounced disliking of Uncanny-type stimuli will occur for any image that strongly activates multiple competing stimulus representations, even in the absence of any human-likeness, and (2) that the negative peak of an ‘Uncanny Valley’ should occur at the point of greatest stimulus-related conflict and not (in the presence of human-likeness) always closer to the ‘human’ end of a perceptual continuum. We measured affective responses to a set of line drawings representing non-human animal–animal morphs, in which each continuum midpoint was a bistable image (Experiment 1), as well as to sets of human-robot and human-animal computer-generated morphs (Experiment 2). Affective trends depicting classic Uncanny Valley functions occurred for all continua, including the nonhuman stimuli. Images at continua midpoints elicited significantly more negative affect than images at endpoints, even when the continua included a human endpoint. This illustrates the feasibility of the inhibitory-devaluation hypothesis and the need for further research into the possibility that the strong dislike of Uncanny-type stimuli reflects the negative affective consequences of cognitive inhibition. (PsycInfo Database Record (c) 2020 APA, all rights reserved)
KW  - *Cognitive Dissonance
KW  - *Cognitive Processes
KW  - *Emotional Responses
KW  - *Perceptual Stimulation
KW  - *Visual Perception
KW  - Conflict
M3  - doi:10.3389/fpsyg.2015.00249
DO  - 10.3389/fpsyg.2015.00249
ER  -